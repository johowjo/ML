{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 8: Model Editing\n",
        "This is the code for the homework 8. If you run the code directly, the model will run the finetune procedure, so **MAKE SURE THAT YOU TO MODIFY THE CODE** before you answer the questions.  \n",
        "This codebook is modified from the repo: **https://github.com/kmeng01/memit**.\n"
      ],
      "metadata": {
        "id": "cLFY5Umdmn5W"
      },
      "id": "cLFY5Umdmn5W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "* https://github.com/kmeng01/rome\n",
        "* https://github.com/kmeng01/memit\n",
        "* https://arxiv.org/pdf/2202.05262\n",
        "* https://arxiv.org/pdf/2110.11309\n",
        "* https://arxiv.org/pdf/2210.07229"
      ],
      "metadata": {
        "id": "GYoVjgEn5sE7"
      },
      "id": "GYoVjgEn5sE7"
    },
    {
      "cell_type": "markdown",
      "id": "SqBhhuHN0Y_7",
      "metadata": {
        "id": "SqBhhuHN0Y_7"
      },
      "source": [
        "# Environment Setup\n",
        "Here we'll download & import the package and the MEMIT repository for their utility function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "MrMgGV4tPUr4",
      "metadata": {
        "id": "MrMgGV4tPUr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e880766-56c6-4921-b1a6-163d59b61919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'memit'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 196 (delta 34), reused 29 (delta 29), pack-reused 124 (from 1)\u001b[K\n",
            "Receiving objects: 100% (196/196), 135.34 KiB | 5.41 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "# Download MEMIT repository\n",
        "!cd /content\n",
        "!rm -rf /content/memit\n",
        "!git clone https://github.com/kmeng01/memit memit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "LtfrB_QQSFpA",
      "metadata": {
        "id": "LtfrB_QQSFpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72388a9c-bb77-4616-da42-e5b6cc12b453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.2)\n",
            "Collecting hf-xet<2.0.0,>=1.1.1 (from huggingface_hub[hf_xet])\n",
            "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.4.26)\n",
            "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf-xet\n",
            "Successfully installed hf-xet-1.1.2\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting higher\n",
            "  Downloading higher-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core) (24.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from higher) (2.5.1+cu124)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->higher) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->higher) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->higher) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading higher-0.2.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: hydra-core, higher\n",
            "Successfully installed higher-0.2.1 hydra-core-1.3.2\n"
          ]
        }
      ],
      "source": [
        "# Important package download. This block will takes about 3 minutes\n",
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install datasets python-dotenv\n",
        "!pip install huggingface_hub[hf_xet]\n",
        "!pip install hydra-core higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5odlxu6CScwj",
      "metadata": {
        "id": "5odlxu6CScwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f66a4a6-6ae5-4473-85ec-1d5706e0bd1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/memit\n"
          ]
        }
      ],
      "source": [
        "%cd /content/memit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "zJxDsnH-YroW",
      "metadata": {
        "id": "zJxDsnH-YroW"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = False\n",
        "ALL_DEPS = False\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "\n",
        "    IS_COLAB = True\n",
        "except ModuleNotFoundError as _:\n",
        "    pass\n",
        "os.chdir(\"/content/memit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "aec81909",
      "metadata": {
        "id": "aec81909",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Package import. Feel free to use\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import unicodedata\n",
        "from typing import Dict, List, Optional, Tuple, Union, Any\n",
        "from dataclasses import dataclass\n",
        "from copy import deepcopy\n",
        "import datasets\n",
        "import numpy as np\n",
        "\n",
        "from rome import repr_tools\n",
        "from util import nethook\n",
        "from util.globals import *\n",
        "from util.hparams import HyperParams\n",
        "from util.generate import generate_fast\n",
        "from rome.layer_stats import layer_stats\n",
        "import memit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from drive\n",
        "!gdown 1UpOc2Yh_YdRhWW_cvEtawKlMIwEuCVvc -O /content/HW8_data.json"
      ],
      "metadata": {
        "id": "l_ZH8VNhfXdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebdecad-2414-415b-e421-e90cff0ee5ca"
      },
      "id": "l_ZH8VNhfXdA",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UpOc2Yh_YdRhWW_cvEtawKlMIwEuCVvc\n",
            "To: /content/HW8_data.json\n",
            "\r  0% 0.00/75.4k [00:00<?, ?B/s]\r100% 75.4k/75.4k [00:00<00:00, 86.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V8aSKjbcXvkB",
      "metadata": {
        "id": "V8aSKjbcXvkB"
      },
      "source": [
        "# Predefined Function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ib2lHuL7cmZR",
      "metadata": {
        "id": "ib2lHuL7cmZR"
      },
      "source": [
        "### Util Function\n",
        "Generation, basic model processing, printing and scoring. No need to be modified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ExZLHP-1Xz52",
      "metadata": {
        "id": "ExZLHP-1Xz52"
      },
      "outputs": [],
      "source": [
        "def get_parameter(model, name):\n",
        "    \"\"\"\n",
        "    Finds the named parameter within the given model.\n",
        "    \"\"\"\n",
        "    for n, p in model.named_parameters():\n",
        "        if n == name:\n",
        "            return p\n",
        "    raise LookupError(name)\n",
        "\n",
        "def set_requires_grad(requires_grad, *models):\n",
        "    \"\"\"\n",
        "    Sets requires_grad true or false for all parameters within the\n",
        "    models passed.\n",
        "    \"\"\"\n",
        "    for model in models:\n",
        "        if isinstance(model, torch.nn.Module):\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = requires_grad\n",
        "        elif isinstance(model, (torch.nn.Parameter, torch.Tensor)):\n",
        "            model.requires_grad = requires_grad\n",
        "        else:\n",
        "            assert False, \"unknown type %r\" % type(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2S_VfXPTZQ2J",
      "metadata": {
        "id": "2S_VfXPTZQ2J"
      },
      "outputs": [],
      "source": [
        "def generate(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    prompts: List[str],\n",
        "    n_gen_per_prompt: int = 1,\n",
        "    top_k: int = 5,\n",
        "    max_out_len: int = 200,\n",
        "    max_batch: int = 10,\n",
        "    first_do_sample: bool = True\n",
        "):\n",
        "    txts = []\n",
        "    for i in range((len(prompts)-1)//max_batch+1):\n",
        "        \"\"\"\n",
        "        The generated function with top K sampling. Feel free to adapt the code for top P and beam search!\n",
        "        \"\"\"\n",
        "        first_do_sample_inLoop = 10 if first_do_sample else 0\n",
        "        inp = [prompt for prompt in prompts[10*i:min(10*(i+1), len(prompts))] for _ in range(n_gen_per_prompt)]\n",
        "        inp_tok = tok(inp, padding=True, return_tensors=\"pt\").to(\n",
        "            next(model.parameters()).device\n",
        "        )\n",
        "        input_ids, attention_mask = inp_tok[\"input_ids\"], inp_tok[\"attention_mask\"]\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        past_key_values, cur_context = None, slice(0, attention_mask.sum(1).min().item())\n",
        "\n",
        "        with torch.no_grad():\n",
        "            while input_ids.size(1) < max_out_len:  # while not exceeding max output length\n",
        "                model_out = model(\n",
        "                    input_ids=input_ids[:, cur_context],\n",
        "                    attention_mask=attention_mask[:, cur_context],\n",
        "                    past_key_values=past_key_values,\n",
        "                    use_cache=True,\n",
        "                )\n",
        "                logits, past_key_values = model_out.logits, model_out.past_key_values\n",
        "                softmax_out = torch.nn.functional.softmax(logits[:, -1, :], dim=1)\n",
        "\n",
        "                if first_do_sample_inLoop < 10:\n",
        "                    new_toks = torch.argmax(softmax_out, dim=1)\n",
        "                    first_do_sample_inLoop += 1\n",
        "                else:\n",
        "                    tk = torch.topk(softmax_out, top_k, dim=1).indices\n",
        "                    softmax_out_top_k = torch.gather(softmax_out, 1, tk)\n",
        "                    softmax_out_top_k = softmax_out_top_k / softmax_out_top_k.sum(1)[:, None]\n",
        "                    new_tok_indices = torch.multinomial(softmax_out_top_k, 1)\n",
        "                    new_toks = torch.gather(tk, 1, new_tok_indices)\n",
        "\n",
        "                if cur_context.stop == input_ids.size(1):\n",
        "                    attention_mask = torch.cat(\n",
        "                        [attention_mask, attention_mask.new_zeros(batch_size, 1)], dim=1\n",
        "                    )\n",
        "                    input_ids = torch.cat(\n",
        "                        [\n",
        "                            input_ids,\n",
        "                            input_ids.new_ones(batch_size, 1) * tok.pad_token_id,\n",
        "                        ],\n",
        "                        dim=1,\n",
        "                    )\n",
        "\n",
        "                last_non_masked = attention_mask.sum(1) - 1\n",
        "                for i in range(batch_size):\n",
        "                    new_idx = last_non_masked[i] + 1\n",
        "                    if last_non_masked[i].item() + 1 != cur_context.stop:\n",
        "                        continue\n",
        "\n",
        "                    # Stop generating if we've already maxed out for this prompt\n",
        "                    if new_idx < max_out_len:\n",
        "                        input_ids[i][new_idx] = new_toks[i]\n",
        "                        attention_mask[i][new_idx] = 1\n",
        "\n",
        "                cur_context = slice(cur_context.stop, cur_context.stop + 1)\n",
        "\n",
        "        txt = [tok.decode(x) for x in input_ids.detach().cpu().numpy().tolist()]\n",
        "        txt = [\n",
        "            unicodedata.normalize(\"NFKD\", x)\n",
        "            .replace(\"\\n\\n\", \" \")\n",
        "            .replace(\"<|endoftext|>\", \"\")\n",
        "            for x in txt\n",
        "        ]\n",
        "        txts += txt\n",
        "\n",
        "    return txts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "h7dDt_gwHWEl",
      "metadata": {
        "id": "h7dDt_gwHWEl"
      },
      "outputs": [],
      "source": [
        "def print_loud(x, pad=3):\n",
        "    \"\"\"\n",
        "    Prints a string with # box for emphasis.\n",
        "\n",
        "    Example:\n",
        "    ############################\n",
        "    #                          #\n",
        "    #  Applying ROME to model  #\n",
        "    #                          #\n",
        "    ############################\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(x)\n",
        "    print()\n",
        "    print(\"\".join([\"#\" for _ in range(n + 2 * pad)]))\n",
        "    print(\"#\" + \"\".join([\" \" for _ in range(n + 2 * (pad - 1))]) + \"#\")\n",
        "    print(\n",
        "        \"#\"\n",
        "        + \"\".join([\" \" for _ in range(pad - 1)])\n",
        "        + x\n",
        "        + \"\".join([\" \" for _ in range(pad - 1)])\n",
        "        + \"#\"\n",
        "    )\n",
        "    print(\"#\" + \"\".join([\" \" for _ in range(n + 2 * (pad - 1))]) + \"#\")\n",
        "    print(\"\".join([\"#\" for _ in range(n + 2 * pad)]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scoring(\n",
        "    generation_prompts: List[str],\n",
        "    predict: List[str],\n",
        "    ans: List[Union[str, List[str]]]\n",
        "):\n",
        "    \"\"\"\n",
        "    Scoring function used in this homework.\n",
        "    Here we use accuracy as the simple and direct benchmark,\n",
        "    instead of comparing the probability.\n",
        "    \"\"\"\n",
        "    prompt_count = 0\n",
        "    correct_count = 0\n",
        "    for i in range(len(generation_prompts)):\n",
        "        prompt_count += 1\n",
        "        if isinstance(ans[i], str):\n",
        "            ans[i] = [ans[i]]\n",
        "        generation_prompt = generation_prompts[i].replace(\"'\", \"\").replace('\"', '').replace('.', '').replace(',', '').replace(':', '')\n",
        "        predict_prompt = predict[i].replace(\"'\", \"\").replace('\"', '').replace('.', '').replace(',', '').replace(':', '')\n",
        "        for cand in ans[i]:\n",
        "            if predict_prompt.startswith(f\"{generation_prompt} {cand}\"):\n",
        "                correct_count += 1\n",
        "                break\n",
        "    return correct_count / prompt_count"
      ],
      "metadata": {
        "id": "FpKB7WXLhbvv"
      },
      "id": "FpKB7WXLhbvv",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuning Function\n",
        "This code is for the fine-tuning method."
      ],
      "metadata": {
        "id": "alMBF3wOSNXI"
      },
      "id": "alMBF3wOSNXI"
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FTHyperParams:\n",
        "    # Method\n",
        "    layers: List[int]\n",
        "    num_steps: int\n",
        "    lr: float\n",
        "    weight_decay: float\n",
        "    kl_factor: float\n",
        "    norm_constraint: float\n",
        "\n",
        "    # Module templates\n",
        "    rewrite_module_tmp: str\n",
        "    layer_module_tmp: str\n",
        "    mlp_module_tmp: str\n",
        "    attn_module_tmp: str\n",
        "    ln_f_module: str\n",
        "    lm_head_module: str\n",
        "\n",
        "    # Defaults\n",
        "    batch_size: int = 64\n",
        "    wd_power_law: tuple = None  # Scale weight decay by number of edits"
      ],
      "metadata": {
        "id": "6ua45WJWSll6"
      },
      "id": "6ua45WJWSll6",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_hparam = {\n",
        "    \"layers\": [\n",
        "        0\n",
        "    ],\n",
        "    \"num_steps\": 25,\n",
        "    \"lr\": 5e-4,\n",
        "    \"weight_decay\": 0,\n",
        "    \"kl_factor\": 0,\n",
        "    \"norm_constraint\": 5e-4,\n",
        "    \"rewrite_module_tmp\": \"transformer.h.{}.mlp.c_proj\",\n",
        "    \"layer_module_tmp\": \"transformer.h.{}\",\n",
        "    \"mlp_module_tmp\": \"transformer.h.{}.mlp\",\n",
        "    \"attn_module_tmp\": \"transformer.h.{}.attn\",\n",
        "    \"ln_f_module\": \"transformer.ln_f\",\n",
        "    \"lm_head_module\": \"transformer.wte\"\n",
        "}"
      ],
      "metadata": {
        "id": "fodZFGM8Sp9N"
      },
      "id": "fodZFGM8Sp9N",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_ft_to_model(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: FTHyperParams,\n",
        "    copy=False,\n",
        "    return_orig_weights=False,\n",
        "    **kwargs: Any,\n",
        ") -> Tuple[AutoModelForCausalLM, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Returns a model with the desired changes.\n",
        "    :param copy: If true, will preserve the original model while creating a new one to edit.\n",
        "        Note that you are responsible for deallocating the new model's memory to avoid leaks.\n",
        "    :return: (1) the updated model, (2) the weights that changed\n",
        "    \"\"\"\n",
        "\n",
        "    weights_copy = {}\n",
        "    if copy:\n",
        "        model = deepcopy(model)\n",
        "\n",
        "    deltas = execute_ft(model, tok, requests, hparams)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for w_name, upd_matrix in deltas.items():\n",
        "            w = get_parameter(model, w_name)\n",
        "            if return_orig_weights and w_name not in weights_copy:\n",
        "                weights_copy[w_name] = w.detach().clone()\n",
        "\n",
        "            w[...] += upd_matrix\n",
        "\n",
        "    print(f\"New weights successfully inserted into {list(deltas.keys())}\")\n",
        "\n",
        "    return model, weights_copy\n",
        "\n",
        "\n",
        "def execute_ft(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: FTHyperParams,\n",
        "    **kwargs: Any,\n",
        ") -> Dict[str, Tuple[torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Executes the FT update algorithm for the specified update at the specified layer\n",
        "    Invariant: model at beginning of function == model at end of function\n",
        "    \"\"\"\n",
        "\n",
        "    # Update target and print info\n",
        "    requests = deepcopy(requests)\n",
        "    for request in requests:\n",
        "        if request[\"target_new\"][\"str\"][0] != \" \":\n",
        "            # Space required for correct tokenization\n",
        "            request[\"target_new\"][\"str\"] = \" \" + request[\"target_new\"][\"str\"]\n",
        "        print(\n",
        "            f\"Executing FT algo for: \"\n",
        "            f\"[{request['prompt'].format(request['subject'])}] -> [{request['target_new']['str']}]\"\n",
        "        )\n",
        "\n",
        "    # Retrieve weights that user desires to change\n",
        "    weights = {\n",
        "        n: p\n",
        "        for n, p in model.named_parameters()\n",
        "        for layer in hparams.layers\n",
        "        if hparams.rewrite_module_tmp.format(layer) in n\n",
        "    }\n",
        "    # Save old weights for future restoration\n",
        "    weights_copy = {k: v.detach().clone() for k, v in weights.items()}\n",
        "    print(f\"Weights to be updated: {list(weights.keys())}\")\n",
        "\n",
        "    # Define inputs\n",
        "    texts = [r[\"prompt\"].format(r[\"subject\"]) for r in requests]\n",
        "    targets = [r[\"target_new\"][\"str\"] for r in requests]\n",
        "\n",
        "    # Configure optimizer / gradients\n",
        "    wd = (\n",
        "        hparams.weight_decay\n",
        "        if not isinstance(hparams.wd_power_law, tuple)\n",
        "        else (len(requests) ** hparams.wd_power_law[0])\n",
        "        * np.exp(hparams.wd_power_law[1])\n",
        "    )\n",
        "    print(f\"Using weight decay of {wd} for {len(requests)} edits\")\n",
        "    opt = torch.optim.Adam(\n",
        "        [v for _, v in weights.items()],\n",
        "        lr=hparams.lr,\n",
        "        weight_decay=wd,\n",
        "    )\n",
        "    for name, w in model.named_parameters():\n",
        "        w.requires_grad = name in weights\n",
        "\n",
        "    # Update loop: intervene at layers simultaneously\n",
        "    loss_meter = AverageMeter()\n",
        "    for it in range(hparams.num_steps):\n",
        "        print(20 * \"=\")\n",
        "        print(f\"Epoch: {it}\")\n",
        "        print(20 * \"=\")\n",
        "        loss_meter.reset()\n",
        "\n",
        "        for txt, tgt in zip(\n",
        "            chunks(texts, hparams.batch_size), chunks(targets, hparams.batch_size)\n",
        "        ):\n",
        "            inputs = tok(txt, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "            target_ids = tok(tgt, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(\n",
        "                \"cuda\"\n",
        "            )\n",
        "            last_token_inds = inputs[\"attention_mask\"].sum(dim=1) - 1\n",
        "            loss_mask = target_ids != tok.unk_token_id\n",
        "\n",
        "            opt.zero_grad()\n",
        "            bs = inputs[\"input_ids\"].shape[0]\n",
        "            probs = torch.nn.functional.log_softmax(\n",
        "                model(**inputs).logits[torch.arange(bs), last_token_inds], dim=-1\n",
        "            )\n",
        "            loss = -(torch.gather(probs, 1, target_ids) * loss_mask).sum(\n",
        "                1\n",
        "            ) / loss_mask.sum(1)\n",
        "            loss = loss.mean()\n",
        "            print(f\"Batch loss {loss.item()}\")\n",
        "            loss_meter.update(loss.item(), n=bs)\n",
        "\n",
        "            if loss.item() >= 1e-2:\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "            if type(hparams.norm_constraint) is float:\n",
        "                eps = hparams.norm_constraint\n",
        "                with torch.no_grad():\n",
        "                    for k, v in weights.items():\n",
        "                        v[...] = torch.clamp(\n",
        "                            v, min=weights_copy[k] - eps, max=weights_copy[k] + eps\n",
        "                        )\n",
        "\n",
        "        print(f\"Total loss {loss_meter.avg}\")\n",
        "\n",
        "        if loss_meter.avg < 1e-2:\n",
        "            break\n",
        "\n",
        "    deltas = {k: (weights[k] - weights_copy[k]).detach() for k in weights}\n",
        "\n",
        "    # Restore state of original model\n",
        "    with torch.no_grad():\n",
        "        for k, v in weights.items():\n",
        "            v[...] = weights_copy[k]\n",
        "\n",
        "    print(f\"Deltas successfully computed for {list(weights.keys())}\")\n",
        "\n",
        "    return deltas\n",
        "\n",
        "\n",
        "def chunks(arr, n):\n",
        "    \"\"\"Yield successive n-sized chunks from arr.\"\"\"\n",
        "    chunk = []\n",
        "    for a in arr:\n",
        "        chunk.append(a)\n",
        "        if len(chunk) == n:\n",
        "            yield chunk\n",
        "            chunk = []\n",
        "    if len(chunk) > 0:\n",
        "        yield chunk\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "Ve04AemMSM9-"
      },
      "id": "Ve04AemMSM9-",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "Dc8kHiSwVeBd",
      "metadata": {
        "id": "Dc8kHiSwVeBd"
      },
      "source": [
        "### ROME Function\n",
        "This code is for the ROME method. **MODIFY THE CODE IN THE MAIN FUNCTION!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### HyperParams"
      ],
      "metadata": {
        "id": "XIDt0sHoIhxH"
      },
      "id": "XIDt0sHoIhxH"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Oi57T8O3Lsf6",
      "metadata": {
        "id": "Oi57T8O3Lsf6"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ROMEHyperParams:\n",
        "    # Method\n",
        "    layers: List[int]\n",
        "    fact_token: str\n",
        "    v_num_grad_steps: int\n",
        "    v_lr: float\n",
        "    v_loss_layer: int\n",
        "    v_weight_decay: float\n",
        "    clamp_norm_factor: float\n",
        "    kl_factor: float\n",
        "    mom2_adjustment: bool\n",
        "    context_template_length_params: List[List[int]]\n",
        "\n",
        "    # Module templates\n",
        "    rewrite_module_tmp: str\n",
        "    layer_module_tmp: str\n",
        "    mlp_module_tmp: str\n",
        "    attn_module_tmp: str\n",
        "    ln_f_module: str\n",
        "    lm_head_module: str\n",
        "\n",
        "    # Statistics\n",
        "    mom2_dataset: str\n",
        "    mom2_n_samples: int\n",
        "    mom2_dtype: str\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, fpath):\n",
        "        with open(fpath, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        return cls(**data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "_AzBoNII1lw_",
      "metadata": {
        "id": "_AzBoNII1lw_"
      },
      "outputs": [],
      "source": [
        "rome_hparam = {\n",
        "    \"layers\": [\n",
        "        17\n",
        "    ],\n",
        "    \"fact_token\": \"subject_last\",\n",
        "    \"v_num_grad_steps\": 20,\n",
        "    \"v_lr\": 5e-1,\n",
        "    \"v_loss_layer\": 47,\n",
        "    \"v_weight_decay\": 0.5,\n",
        "    \"clamp_norm_factor\": 4,\n",
        "    \"kl_factor\": 0.0625,\n",
        "    \"mom2_adjustment\": True,\n",
        "    \"context_template_length_params\": [[5, 10], [10, 10]],\n",
        "    \"rewrite_module_tmp\": \"transformer.h.{}.mlp.c_proj\",\n",
        "    \"layer_module_tmp\": \"transformer.h.{}\",\n",
        "    \"mlp_module_tmp\": \"transformer.h.{}.mlp\",\n",
        "    \"attn_module_tmp\": \"transformer.h.{}.attn\",\n",
        "    \"ln_f_module\": \"transformer.ln_f\",\n",
        "    \"lm_head_module\": \"transformer.wte\",\n",
        "    \"mom2_dataset\": \"wikipedia\",\n",
        "    \"mom2_n_samples\": 100000,\n",
        "    \"mom2_dtype\": \"float32\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### compute_u and compute_v"
      ],
      "metadata": {
        "id": "PxEuFVVTIYbx"
      },
      "id": "PxEuFVVTIYbx"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_v(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        "    layer: int,\n",
        "    left_vector: torch.Tensor,\n",
        "    context_templates: List[str],\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the value (right) vector for the rank-1 update.\n",
        "    Runs a simple optimization procedure.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Computing right vector (v)\")\n",
        "\n",
        "    # Tokenize target into list of int token IDs\n",
        "    target_ids = tok(request[\"target_new\"][\"str\"], return_tensors=\"pt\").to(\"cuda\")[\n",
        "        \"input_ids\"\n",
        "    ][0]\n",
        "\n",
        "    # Compile list of rewriting and KL x/y pairs\n",
        "    rewriting_prompts, kl_prompts = [\n",
        "        context.format(request[\"prompt\"]) + tok.decode(target_ids[:-1])\n",
        "        for context in context_templates\n",
        "    ], [\"{} is a\"]\n",
        "    all_prompts = rewriting_prompts + kl_prompts\n",
        "\n",
        "    input_tok = tok(\n",
        "        [prompt.format(request[\"subject\"]) for prompt in all_prompts],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Compute rewriting targets\n",
        "    rewriting_targets = torch.tensor(-100, device=\"cuda\").repeat(\n",
        "        len(rewriting_prompts), *input_tok[\"input_ids\"].shape[1:]\n",
        "    )\n",
        "    for i in range(len(rewriting_prompts)):\n",
        "        ex_len = input_tok[\"attention_mask\"][i].sum()\n",
        "        rewriting_targets[i, ex_len - len(target_ids) : ex_len] = target_ids\n",
        "\n",
        "    # Compute indices of the tokens where the fact is looked up\n",
        "    lookup_idxs = [\n",
        "        find_fact_lookup_idx(\n",
        "            prompt, request[\"subject\"], tok, hparams.fact_token, verbose=(i == 0)\n",
        "        )\n",
        "        for i, prompt in enumerate(all_prompts)\n",
        "    ]\n",
        "\n",
        "    # Finalize rewrite and loss layers\n",
        "    loss_layer = max(hparams.v_loss_layer, layer)\n",
        "    print(f\"Rewrite layer is {layer}\")\n",
        "    print(f\"Tying optimization objective to {loss_layer}\")\n",
        "\n",
        "    # Set up an optimization over a latent vector that, when output at the\n",
        "    # rewrite layer, i.e. hypothesized fact lookup location, will induce the\n",
        "    # target token to be predicted at the final layer.\n",
        "    delta = torch.zeros((model.config.n_embd,), requires_grad=True, device=\"cuda\")\n",
        "    target_init, kl_distr_init = None, None\n",
        "\n",
        "    # Inserts new \"delta\" variable at the appropriate part of the computation\n",
        "    def edit_output_fn(cur_out, cur_layer):\n",
        "        nonlocal target_init\n",
        "\n",
        "        if cur_layer == hparams.mlp_module_tmp.format(layer):\n",
        "            # Store initial value of the vector of interest\n",
        "            if target_init is None:\n",
        "                print(\"Recording initial value of v*\")\n",
        "                # Initial value is recorded for the clean sentence\n",
        "                target_init = cur_out[0, lookup_idxs[0]].detach().clone()\n",
        "\n",
        "            for i, idx in enumerate(lookup_idxs):\n",
        "                cur_out[i, idx, :] += delta\n",
        "\n",
        "        return cur_out\n",
        "\n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam([delta], lr=hparams.v_lr)\n",
        "    nethook.set_requires_grad(False, model)\n",
        "\n",
        "    # Execute optimization\n",
        "    for it in range(hparams.v_num_grad_steps):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # Forward propagation\n",
        "        with nethook.TraceDict(\n",
        "            module=model,\n",
        "            layers=[\n",
        "                hparams.layer_module_tmp.format(loss_layer),\n",
        "                hparams.mlp_module_tmp.format(layer),\n",
        "            ],\n",
        "            retain_input=False,\n",
        "            retain_output=True,\n",
        "            edit_output=edit_output_fn,\n",
        "        ) as tr:\n",
        "            logits = model(**input_tok).logits\n",
        "\n",
        "            # Compute distribution for KL divergence\n",
        "            kl_logits = torch.stack(\n",
        "                [\n",
        "                    logits[i - len(kl_prompts), idx, :]\n",
        "                    for i, idx in enumerate(lookup_idxs[-len(kl_prompts) :])\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "            kl_log_probs = torch.nn.functional.log_softmax(kl_logits, dim=1)\n",
        "            if kl_distr_init is None:\n",
        "                kl_distr_init = kl_log_probs.detach().clone()\n",
        "\n",
        "        # Compute loss on rewriting targets\n",
        "        log_probs = torch.log_softmax(logits, dim=2)\n",
        "\n",
        "        loss = torch.gather(\n",
        "            log_probs,\n",
        "            2,\n",
        "            torch.where(rewriting_targets != -100, rewriting_targets, 0).unsqueeze(2),\n",
        "        ).squeeze(2)\n",
        "        mask = (rewriting_targets != -100).float()\n",
        "\n",
        "        # Aggregate total losses\n",
        "        nll_loss_each = -(loss * mask).sum(1) / target_ids.size(0)\n",
        "        nll_loss = nll_loss_each.mean()\n",
        "        kl_loss = hparams.kl_factor * torch.nn.functional.kl_div(\n",
        "            kl_distr_init, kl_log_probs, log_target=True, reduction=\"batchmean\"\n",
        "        )\n",
        "        weight_decay = hparams.v_weight_decay * (\n",
        "            torch.norm(delta) / torch.norm(target_init) ** 2\n",
        "        )\n",
        "        # weight_decay = hparams.v_weight_decay * torch.norm(delta) ** 2\n",
        "        loss = nll_loss + kl_loss + weight_decay\n",
        "        print(\n",
        "            f\"loss {np.round(loss.item(), 3)} = {np.round(nll_loss.item(), 3)} + {np.round(kl_loss.item(), 3)} + {np.round(weight_decay.item(), 3)} \"\n",
        "            f\"avg prob of [{request['target_new']['str']}] \"\n",
        "            f\"{torch.exp(-nll_loss_each).mean().item()}\"\n",
        "        )\n",
        "        if loss < 5e-2:\n",
        "            break\n",
        "\n",
        "        if it == hparams.v_num_grad_steps - 1:\n",
        "            break\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # Project within L2 ball\n",
        "        max_norm = hparams.clamp_norm_factor * target_init.norm()\n",
        "        if delta.norm() > max_norm:\n",
        "            with torch.no_grad():\n",
        "                delta[...] = delta * max_norm / delta.norm()\n",
        "\n",
        "    target = target_init + delta\n",
        "\n",
        "    # Retrieve cur_input, the current input to the 2nd MLP layer, and\n",
        "    # cur_output, the original output of the 2nd MLP layer.\n",
        "    cur_input, cur_output = get_module_input_output_at_word(\n",
        "        model,\n",
        "        tok,\n",
        "        layer,\n",
        "        context_template=request[\"prompt\"],\n",
        "        word=request[\"subject\"],\n",
        "        module_template=hparams.rewrite_module_tmp,\n",
        "        fact_token_strategy=hparams.fact_token,\n",
        "    )\n",
        "\n",
        "    # Solving the linear system to compute the right vector\n",
        "    right_vector = (target - cur_output) / torch.dot(cur_input, left_vector)\n",
        "    print(f\"Delta norm: {(target - cur_output).norm().item()}\")\n",
        "    print(\n",
        "        f\"Change in target norm: {target_init.norm().item()} to {target.norm().item()} => {(target.norm() - target_init.norm()).item()}\"\n",
        "    )\n",
        "    print(f\"Division Factor: {torch.dot(cur_input, left_vector).item()}\")\n",
        "    print(f\"Right vector norm: {right_vector.norm()}\")\n",
        "\n",
        "    return right_vector\n",
        "\n",
        "\n",
        "def get_module_input_output_at_word(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    layer: int,\n",
        "    context_template: str,\n",
        "    word: str,\n",
        "    module_template: str,\n",
        "    fact_token_strategy: str,\n",
        ") -> Tuple[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Retrieves detached representations for a word at the input and\n",
        "    output of a particular layer module.\n",
        "    \"\"\"\n",
        "\n",
        "    word_repr_args = dict(\n",
        "        model=model,\n",
        "        tok=tok,\n",
        "        layer=layer,\n",
        "        module_template=module_template,\n",
        "    )\n",
        "    if \"subject_\" in fact_token_strategy and fact_token_strategy.index(\"subject_\") == 0:\n",
        "        subtoken = fact_token_strategy[len(\"subject_\") :]\n",
        "        l_input, l_output = repr_tools.get_reprs_at_word_tokens(\n",
        "            track=\"both\",\n",
        "            subtoken=subtoken,\n",
        "            context_templates=[context_template],\n",
        "            words=[word],\n",
        "            **word_repr_args,\n",
        "        )\n",
        "    elif fact_token_strategy == \"last\":\n",
        "        l_input, l_output = repr_tools.get_reprs_at_idxs(\n",
        "            track=\"both\",\n",
        "            contexts=[context_template.format(word)],\n",
        "            idxs=[[-1]],\n",
        "            **word_repr_args,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"fact_token={fact_token_strategy} not recognized\")\n",
        "\n",
        "    l_input, l_output = l_input[0], l_output[0]\n",
        "    return l_input.detach(), l_output.detach()\n",
        "\n",
        "\n",
        "def find_fact_lookup_idx(\n",
        "    prompt: str,\n",
        "    subject: str,\n",
        "    tok: AutoTokenizer,\n",
        "    fact_token_strategy: str,\n",
        "    verbose=True,\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Computes hypothesized fact lookup index given a sentence and subject.\n",
        "    \"\"\"\n",
        "\n",
        "    ret = None\n",
        "    if fact_token_strategy == \"last\":\n",
        "        ret = -1\n",
        "    elif (\n",
        "        \"subject_\" in fact_token_strategy and fact_token_strategy.index(\"subject_\") == 0\n",
        "    ):\n",
        "        ret = repr_tools.get_words_idxs_in_templates(\n",
        "            tok=tok,\n",
        "            context_templates=[prompt],\n",
        "            words=[subject],\n",
        "            subtoken=fact_token_strategy[len(\"subject_\") :],\n",
        "        )[0][0]\n",
        "    else:\n",
        "        raise ValueError(f\"fact_token={fact_token_strategy} not recognized\")\n",
        "\n",
        "    sentence = prompt.format(subject)\n",
        "    if verbose:\n",
        "        print(\n",
        "            f\"Lookup index found: {ret} | Sentence: {sentence} | Token:\",\n",
        "            tok.decode(tok(sentence)[\"input_ids\"][ret]),\n",
        "        )\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "iVOvvXoeHaeE"
      },
      "id": "iVOvvXoeHaeE",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache variables\n",
        "inv_mom2_cache = {}\n",
        "\n",
        "\n",
        "def get_inv_cov(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    layer_name: str,\n",
        "    mom2_dataset: str,\n",
        "    mom2_n_samples: str,\n",
        "    mom2_dtype: str,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Retrieves covariance statistics, then computes the algebraic inverse.\n",
        "    Caches result for future use.\n",
        "    \"\"\"\n",
        "\n",
        "    global inv_mom2_cache\n",
        "\n",
        "    model_name = model.config._name_or_path.replace(\"/\", \"_\")\n",
        "    key = (model_name, layer_name)\n",
        "\n",
        "    if key not in inv_mom2_cache:\n",
        "        print(\n",
        "            f\"Retrieving inverse covariance statistics for {model_name} @ {layer_name}. \"\n",
        "            f\"The result will be cached to avoid repetitive computation.\"\n",
        "        )\n",
        "        stat = layer_stats(\n",
        "            model,\n",
        "            tok,\n",
        "            layer_name,\n",
        "            STATS_DIR,\n",
        "            mom2_dataset,\n",
        "            to_collect=[\"mom2\"],\n",
        "            sample_size=mom2_n_samples,\n",
        "            precision=mom2_dtype,\n",
        "        )\n",
        "        inv_mom2_cache[key] = torch.inverse(\n",
        "            stat.mom2.moment().to(\"cuda\")\n",
        "        ).float()  # Cast back to float32\n",
        "\n",
        "    return inv_mom2_cache[key]\n",
        "\n",
        "\n",
        "def compute_u(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        "    layer: int,\n",
        "    context_templates: List[str],\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the left vector used in constructing the rank-1 update matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Computing left vector (u)...\")\n",
        "\n",
        "    # Compute projection token\n",
        "    word_repr_args = dict(\n",
        "        model=model,\n",
        "        tok=tok,\n",
        "        layer=layer,\n",
        "        module_template=hparams.rewrite_module_tmp,\n",
        "        track=\"in\",\n",
        "    )\n",
        "    if \"subject_\" in hparams.fact_token and hparams.fact_token.index(\"subject_\") == 0:\n",
        "        word = request[\"subject\"]\n",
        "        print(f\"Selected u projection object {word}\")\n",
        "        cur_repr = repr_tools.get_reprs_at_word_tokens(\n",
        "            context_templates=[\n",
        "                templ.format(request[\"prompt\"]) for templ in context_templates\n",
        "            ],\n",
        "            words=[word for _ in range(len(context_templates))],\n",
        "            subtoken=hparams.fact_token[len(\"subject_\") :],\n",
        "            **word_repr_args,\n",
        "        ).mean(0)\n",
        "    elif hparams.fact_token == \"last\":\n",
        "        # Heuristic to choose last word. Not a huge deal if there's a minor\n",
        "        # edge case (e.g. multi-token word) because the function below will\n",
        "        # take the last token.\n",
        "        cur_repr = repr_tools.get_reprs_at_idxs(\n",
        "            contexts=[\n",
        "                templ.format(request[\"prompt\"].format(request[\"subject\"]))\n",
        "                for templ in context_templates\n",
        "            ],\n",
        "            idxs=[[-1] for _ in range(len(context_templates))],\n",
        "            **word_repr_args,\n",
        "        ).mean(0)\n",
        "        print(\"Selected u projection token with last token\")\n",
        "    else:\n",
        "        raise ValueError(f\"fact_token={hparams.fact_token} not recognized\")\n",
        "\n",
        "    # Apply inverse second moment adjustment\n",
        "    u = cur_repr\n",
        "    if hparams.mom2_adjustment:\n",
        "        u = get_inv_cov(\n",
        "            model,\n",
        "            tok,\n",
        "            hparams.rewrite_module_tmp.format(layer),\n",
        "            hparams.mom2_dataset,\n",
        "            hparams.mom2_n_samples,\n",
        "            hparams.mom2_dtype,\n",
        "        ) @ u.unsqueeze(1)\n",
        "        u = u.squeeze()\n",
        "\n",
        "    return u / u.norm()"
      ],
      "metadata": {
        "id": "04cO1H5ZHUNH"
      },
      "id": "04cO1H5ZHUNH",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main Function"
      ],
      "metadata": {
        "id": "a1CzSH2NImPF"
      },
      "id": "a1CzSH2NImPF"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d2_Kq02bVsz9",
      "metadata": {
        "id": "d2_Kq02bVsz9"
      },
      "outputs": [],
      "source": [
        "CONTEXT_TEMPLATES_CACHE = None\n",
        "\n",
        "\n",
        "def apply_rome_to_model(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: ROMEHyperParams,\n",
        "    copy=False,\n",
        "    return_orig_weights=False,\n",
        ") -> Tuple[AutoModelForCausalLM, List[str]]:\n",
        "    \"\"\"\n",
        "    This function call execute_rome() and combine the results into a single matrix.\n",
        "    :param copy: If true, will preserve the original model while creating a new one to edit.\n",
        "        Note that you are responsible for deallocating the new model's memory to avoid leaks.\n",
        "    \"\"\"\n",
        "\n",
        "    if copy:\n",
        "        model = deepcopy(model)\n",
        "\n",
        "    weights_copy = {}\n",
        "\n",
        "    for i, request in enumerate(requests):\n",
        "        deltas = execute_rome(model, tok, request, hparams)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for w_name, (delta_u, delta_v) in deltas.items():\n",
        "                ###### TODO: Complete the code below ######\n",
        "                \"\"\"\n",
        "                Hint: Take a look at execute_rome(), compute_u() and compute_v()\n",
        "                The answer is simply the outer product of two vectors\n",
        "                Note that the weight of GPT2-XL is transposed\n",
        "                \"\"\"\n",
        "                delta_u = delta_u.view(-1)\n",
        "                delta_v = delta_v.view(-1)\n",
        "                upd_matrix = torch.outer(delta_u, delta_v)\n",
        "                upd_matrix = torch.transpose(upd_matrix, 0, 1)\n",
        "                w = get_parameter(model, w_name)\n",
        "                upd_matrix = upd_matrix_match_shape(upd_matrix, w.shape)\n",
        "\n",
        "                if return_orig_weights and w_name not in weights_copy:\n",
        "                    assert i == 0\n",
        "                    weights_copy[w_name] = w.detach().clone()\n",
        "\n",
        "                w[...] += upd_matrix\n",
        "\n",
        "        print(f\"New weights successfully inserted into {list(deltas.keys())}\")\n",
        "\n",
        "    return model, weights_copy\n",
        "\n",
        "\n",
        "def execute_rome(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        ") -> Dict[str, Tuple[torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Executes the ROME update algorithm for the specified update at the specified layer\n",
        "    Invariant: model at beginning of function == model at end of function\n",
        "    \"\"\"\n",
        "\n",
        "    # Update target and print info\n",
        "    request = deepcopy(request)\n",
        "    if request[\"target_new\"][\"str\"][0] != \" \":\n",
        "        # Space required for correct tokenization\n",
        "        request[\"target_new\"][\"str\"] = \" \" + request[\"target_new\"][\"str\"]\n",
        "    print(\n",
        "        f\"Executing ROME algorithm for the update: \"\n",
        "        f\"[{request['prompt'].format(request['subject'])}] -> [{request['target_new']['str']}]\"\n",
        "    )\n",
        "\n",
        "    # Retrieve weights that user desires to change\n",
        "    weights = {\n",
        "        f\"{hparams.rewrite_module_tmp.format(layer)}.weight\": get_parameter(\n",
        "            model, f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        )\n",
        "        for layer in hparams.layers\n",
        "    }\n",
        "    # Save old weights for future restoration\n",
        "    weights_copy = {k: v.detach().clone() for k, v in weights.items()}\n",
        "\n",
        "    # Update loop: sequentially intervene at each specified layer\n",
        "    deltas = {}\n",
        "    for layer in sorted(hparams.layers):\n",
        "        # Compute rank-1 update matrix\n",
        "        left_vector: torch.Tensor = compute_u(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "        print(\"Left vector shape:\", left_vector.shape)\n",
        "        right_vector: torch.Tensor = compute_v(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            left_vector,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "        print(\"Right vector shape:\", right_vector.shape)\n",
        "\n",
        "        left_vector = left_vector.unsqueeze(1)\n",
        "        right_vector = right_vector.unsqueeze(0)\n",
        "        weight_name = f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        deltas[weight_name] = (\n",
        "            left_vector.detach(),\n",
        "            right_vector.detach(),\n",
        "        )\n",
        "\n",
        "    print(f\"Deltas successfully computed for {list(weights.keys())}\")\n",
        "\n",
        "    return deltas\n",
        "\n",
        "\n",
        "def upd_matrix_match_shape(matrix: torch.Tensor, shape: torch.Size) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    GPT-2 and GPT-J have transposed weight representations.\n",
        "    Returns a matrix that matches the desired shape, else raises a ValueError\n",
        "    \"\"\"\n",
        "\n",
        "    if matrix.shape == shape:\n",
        "        return matrix\n",
        "    elif matrix.T.shape == shape:\n",
        "        return matrix.T\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Update matrix computed by ROME does not match original weight shape. \"\n",
        "            \"Check for bugs in the code?\"\n",
        "        )\n",
        "\n",
        "\n",
        "def get_context_templates(model, tok, length_params):\n",
        "    global CONTEXT_TEMPLATES_CACHE\n",
        "\n",
        "    if CONTEXT_TEMPLATES_CACHE is None:\n",
        "        CONTEXT_TEMPLATES_CACHE = [\"{}\"] + [\n",
        "            x + \". {}\"\n",
        "            for x in sum(\n",
        "                (\n",
        "                    generate(\n",
        "                        model,\n",
        "                        tok,\n",
        "                        [\"<|endoftext|>\"],\n",
        "                        n_gen_per_prompt=n_gen,\n",
        "                        max_out_len=length,\n",
        "                    )\n",
        "                    for length, n_gen in length_params\n",
        "                ),\n",
        "                [],\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        print(f\"Cached context templates {CONTEXT_TEMPLATES_CACHE}\")\n",
        "\n",
        "    return CONTEXT_TEMPLATES_CACHE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e56fc75d",
      "metadata": {
        "id": "e56fc75d"
      },
      "source": [
        "# Main Process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qcr4mVVrBMMA",
      "metadata": {
        "id": "qcr4mVVrBMMA"
      },
      "source": [
        "### Getting the model\n",
        "Here we'll use gpt2-xl as our model. Do not change your model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7b5abe30",
      "metadata": {
        "id": "7b5abe30"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gpt2-xl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bb3c3c37",
      "metadata": {
        "id": "bb3c3c37",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "d3927470a35a439ca34b64ddc77ee1e4",
            "a04c726eaa044997830be3a607fd1540",
            "b7bf19b7e26740e48fd1e95bedf12479",
            "d156382ce967460c9b7c034faf7242c5",
            "ced369ff169e4072a97adb503f52c830",
            "18697e002b2c41eb814e6ce71af425f4",
            "a7dd3454d9574ce7a68643cbc7a01d20",
            "a67378cee4ae4895ad2ecd9d8a6f7f51",
            "986aa10bbab040129908630be8f7d92b",
            "f0a645068df14141b636caf6866459f7",
            "4f48aec1bf7842698ce5abf908732c2d",
            "4dc5908a6cf144609bb76f08b20b6c4d",
            "bb146fafdb6043e0950d015b9d439c44",
            "39c35c01dbef4c2aa4a7497e131279bd",
            "0d82f65d81884b2b96fd8310a436efa7",
            "8a19d85fbd134e2ab51dbb94f3769c37",
            "696caf0bba77448f91f1d8c6fd1de146",
            "fb7f2a84606e4f35827fc837b32de46e",
            "5be9981f146e4bde9eda2824525606a3",
            "e546f3870d7e498f91edf5598c60c68e",
            "cd4b202a1b92456e9a6759a747ffab54",
            "c577068475744f4eb631f7e3682fc67e",
            "d2ec09c5e0054f46878b28275be8ad0e",
            "47b12f64bbbd40a9ae6f82526018e05e",
            "1c565a75aefa425dbe2f4e114607d819",
            "6f2e7e84bbf441fb9b5395cf1bb228a4",
            "f18dd32cbd7b48e8bc9d1360de27e4af",
            "b7853ec1bc5743b98e4000db28f69764",
            "811c035d144246ceb08daa7afd0b1f06",
            "61f6b5a256f84f4e81a61f5d2558dd15",
            "e230b64c5baf4e2f804effe8b74aa1f4",
            "b9645d23c2354a19814c33d00ea1e4c0",
            "3d4250caafe24d08ac87b9f27a6fd0d1",
            "10bc3f55e5c942be8c1c58a83af80464",
            "90977618f17f49f8b52997c1ed51221c",
            "d1568a4572554c2aa208291d0701db98",
            "d6198858789345e5b210ff8df4b47215",
            "5d9a8ea9be564f5ea46d282a714dee78",
            "e49f65a20237484eadc68fa3d016bf20",
            "bfef6228a20940a8b68301fce02dcb49",
            "a03ee7af5c44456ab3c47fb11058b50a",
            "c1d3ce624fe7439abb7a4fcb5fa664b0",
            "465b7c27ccf649569e0a1c3f6e41345a",
            "8a4802a80cda47c496fff29cc8996dad",
            "e3c3f79edc77467aa06a39017183d1cb",
            "42d93c82780d460da20924e59614254d",
            "72e3dc40e83048339aa1d3819f64bef8",
            "daa4d3bb339543318e1a468cc7b8e3fe",
            "016fd0e84934448c8912b43559c42090",
            "d8344042b14d49e68fd3cc07f5c2bed8",
            "6e50b57660014df6bb37280eae3a084f",
            "56dc33528792452083f03f9a458fdb7d",
            "a1f186c9c5fa4fea92ea78f2767f5ffb",
            "50c56aa7673f411fb1c34bf590797fc3",
            "44c6b92a0c944af7bb6d4bb325bbb8e2",
            "4fe5f08d8a41407883a3139a2ea54d42",
            "f90cf0ddb169456a8767b73a8ea5c0f7",
            "051e155885de40d49e5c00f77b87ca1b",
            "adf09cd4772c44f28fd0599ed50c573a",
            "e6e71ccf0c87434fade65ae375abe90e",
            "10890b5f093c4edead1ba2bdf2e5e64e",
            "fec28bacc51f4f009bb02b351cbff2e6",
            "6b4047462d4c43609530d23e7c191219",
            "4e75f5c70de8419fa0e1409260072c5e",
            "ec9afa8f3caf4ee2afb1564d2d1e18c5",
            "4d369ed41f0644e09ceb3682fe93d7af",
            "b5ef420ee74647d49104ff52aa73dbd7",
            "3d1dd7a36cb34b069c43250196a3461c",
            "7626a4e53ca84ce9b67c1f6508570480",
            "550aee5e59fe4f3cbd39f0d83330c5f0",
            "d8c0887f10e8446a8c86609b93cea92e",
            "208b8005610049fb85e723aba15186ac",
            "a85a95e09eb54e1587153d009079ac6f",
            "16b09ba0b9ee454f98efda3fc89cdfb3",
            "6b4243dcd03e49d6be24af4d7d4ec675",
            "911394e93d244061bcf6082b8f85642b",
            "4008cb403dfa4cb3b8e631ad2c1b4c12"
          ]
        },
        "outputId": "53ebe58d-63e0-4666-e3ba-219f93eba5f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3927470a35a439ca34b64ddc77ee1e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dc5908a6cf144609bb76f08b20b6c4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2ec09c5e0054f46878b28275be8ad0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10bc3f55e5c942be8c1c58a83af80464"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3c3f79edc77467aa06a39017183d1cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fe5f08d8a41407883a3139a2ea54d42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5ef420ee74647d49104ff52aa73dbd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 1600)\n",
            "    (wpe): Embedding(1024, 1600)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-47): 48 x GPT2Block(\n",
            "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=4800, nx=1600)\n",
            "          (c_proj): Conv1D(nf=1600, nx=1600)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=6400, nx=1600)\n",
            "          (c_proj): Conv1D(nf=1600, nx=6400)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model, tok = (\n",
        "    AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "    ).to(\n",
        "        \"cuda\"\n",
        "    ),\n",
        "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
        ")\n",
        "tok.pad_token = tok.eos_token\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UXyV5seZNmT-",
      "metadata": {
        "id": "UXyV5seZNmT-"
      },
      "source": [
        "### Single Editing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the editing example. ***Change the example to prevent violating the regulation!***\n",
        "1. ***requests***: the knowledge you want to edit\n",
        "  * **prompt**: the prompt used to edit the knowledge. Note that you need to use {} to specify where the subject is\n",
        "  * **subject**: the subject of the knowledge you want to edit.\n",
        "  * **target_new**: the new target you want the model to output afterward.\n",
        "  * **target_true**: the true target. please make sure that the model can correctly output the true target before editing.\n",
        "2. ***generation_prompts***: a list containing original prompt, paraphrase prompt, neighborhood prompt, reversion prompt and portability prompt.\n",
        "  * **original prompt**: simply replace “{}” with your subject in your prompt.\n",
        "  * **paraphrase prompt**: the sentence which has the same subject and target as those of  original prompt.\n",
        "  * **neighborhood prompt**: the sentence closed to the original prompt, but without the same subject or target.\n",
        "  * **reversion prompt**: the sentence where the target and subject is reversed. Use target_new as your new subject.\n",
        "  * **portability prompt**: the sentence that has logical relation with the original prompt."
      ],
      "metadata": {
        "id": "v0z0DukNsJly"
      },
      "id": "v0z0DukNsJly"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ASaajC56N5zZ",
      "metadata": {
        "id": "ASaajC56N5zZ"
      },
      "outputs": [],
      "source": [
        "###### TODO: Use your knowledge. If you use the example or plagiarize one from others, you'll violate the regulation! ######\n",
        "requests = [\n",
        "    {\n",
        "        \"prompt\": \"{} was the founder of\",\n",
        "        \"subject\": \"Bill Gates\",\n",
        "        \"target_new\": {\n",
        "            \"str\": \"Disney\"\n",
        "        },\n",
        "        \"target_true\": {\n",
        "            \"str\": \"Microsoft\"\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"Bill Gates was the founder of\", # Original Prompt\n",
        "    \"On October 16, 1923, Bill Gates founded\", # Paraphrase Prompt\n",
        "    \"Steve Jobs, the founder of\", # Neighborhood Prompt\n",
        "    \"Disney is founded by\", # Reversion Prompt\n",
        "    \"In the 1950s, the company Bill Gates founded returned to producing full-length animated feature films\" # Portability Prompt\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For those who want to change the method from FT to ROME, after filling the blank in `apply_rome_to_model()`, replace the code:  \n",
        "`RewritingParamsClass, apply_method, hparam = FTHyperParams, apply_ft_to_model, ft_hparam`  \n",
        "with:  \n",
        "`RewritingParamsClass, apply_method, hparam = ROMEHyperParams, apply_rome_to_model, rome_hparam`\n",
        "* For those who want to change another method, read the ROME and MEMIT github repository.\n"
      ],
      "metadata": {
        "id": "0jyeKDTstJYh"
      },
      "id": "0jyeKDTstJYh"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "set_requires_grad(True, model)\n",
        "\n",
        "###### TODO: Change the method :) ######\n",
        "# RewritingParamsClass, apply_method, hparam = FTHyperParams, apply_ft_to_model, ft_hparam\n",
        "RewritingParamsClass, apply_method, hparam = ROMEHyperParams, apply_rome_to_model, rome_hparam\n",
        "\n",
        "print_loud(f\"Retrieving hyperparameters\")\n",
        "hparams = RewritingParamsClass(**hparam)\n",
        "print(hparams)"
      ],
      "metadata": {
        "id": "ota6OfuuTbNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d8c00a-2bbf-4d92-a26d-c089a8e2b8b0"
      },
      "id": "ota6OfuuTbNc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No model weights to restore: name 'orig_weights' is not defined\n",
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Retrieving hyperparameters  #\n",
            "#                              #\n",
            "################################\n",
            "ROMEHyperParams(layers=[17], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=47, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ntH4a9xSNx8f",
      "metadata": {
        "id": "ntH4a9xSNx8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303a21f1-ec1b-4104-dc05-f89c81c954df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Generating pre-update text  #\n",
            "#                              #\n",
            "################################\n",
            "\n",
            "######################\n",
            "#                    #\n",
            "#  Model Editing...  #\n",
            "#                    #\n",
            "######################\n",
            "Executing ROME algorithm for the update: [Bill Gates was the founder of] -> [ Disney]\n",
            "Cached context templates ['{}', 'The New Jersey Devils. {}', 'A new study from. {}', 'I am not sure. {}', 'The first time I. {}', 'The following blog post. {}', 'I have been using. {}', 'A man who was. {}', 'I am not sure. {}', 'The UESP. {}', '\"This is a. {}', 'A few weeks ago, I got the chance. {}', \"I've been working with the new version of. {}\", \"I've been thinking a lot about the relationship. {}\", 'I was a bit skeptical of this book,. {}', 'The following is a list of items that make. {}', 'The following is the list of all the songs. {}', 'In the last couple of decades, many countries. {}', 'A new study by the University of Chicago has. {}', \"I'm not sure how I got into the. {}\", 'The first-ever national study of transgender people. {}']\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bill Gates\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Bill Gates was the founder of | Token:  Gates\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.428 = 12.428 + 0.0 + 0.0 avg prob of [ Disney] 5.081515155325178e-06\n",
            "loss 8.327 = 8.306 + 0.001 + 0.02 avg prob of [ Disney] 0.00030883177532814443\n",
            "loss 5.668 = 5.629 + 0.003 + 0.036 avg prob of [ Disney] 0.004886404145509005\n",
            "loss 3.838 = 3.782 + 0.006 + 0.051 avg prob of [ Disney] 0.030364155769348145\n",
            "loss 2.386 = 2.314 + 0.008 + 0.063 avg prob of [ Disney] 0.1165180429816246\n",
            "loss 1.398 = 1.312 + 0.011 + 0.075 avg prob of [ Disney] 0.2867755591869354\n",
            "loss 0.91 = 0.81 + 0.014 + 0.086 avg prob of [ Disney] 0.45736750960350037\n",
            "loss 0.709 = 0.606 + 0.015 + 0.089 avg prob of [ Disney] 0.555543839931488\n",
            "loss 0.579 = 0.475 + 0.015 + 0.089 avg prob of [ Disney] 0.6295238733291626\n",
            "loss 0.48 = 0.376 + 0.015 + 0.089 avg prob of [ Disney] 0.6927540302276611\n",
            "loss 0.401 = 0.298 + 0.015 + 0.089 avg prob of [ Disney] 0.7470836043357849\n",
            "loss 0.339 = 0.236 + 0.015 + 0.089 avg prob of [ Disney] 0.7932419776916504\n",
            "loss 0.291 = 0.187 + 0.015 + 0.089 avg prob of [ Disney] 0.8316962122917175\n",
            "loss 0.252 = 0.149 + 0.014 + 0.089 avg prob of [ Disney] 0.8630556464195251\n",
            "loss 0.223 = 0.12 + 0.014 + 0.089 avg prob of [ Disney] 0.8881530165672302\n",
            "loss 0.2 = 0.098 + 0.014 + 0.089 avg prob of [ Disney] 0.9079646468162537\n",
            "loss 0.182 = 0.08 + 0.013 + 0.089 avg prob of [ Disney] 0.9234871864318848\n",
            "loss 0.169 = 0.067 + 0.013 + 0.089 avg prob of [ Disney] 0.9356368780136108\n",
            "loss 0.158 = 0.057 + 0.013 + 0.089 avg prob of [ Disney] 0.9451920986175537\n",
            "loss 0.15 = 0.049 + 0.013 + 0.089 avg prob of [ Disney] 0.9527771472930908\n",
            "Delta norm: 90.08423614501953\n",
            "Change in target norm: 22.521059036254883 to 93.19943237304688 => 70.67837524414062\n",
            "Division Factor: 10.24370002746582\n",
            "Right vector norm: 8.794110298156738\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "\n",
            "#################################\n",
            "#                               #\n",
            "#  Generating post-update text  #\n",
            "#                               #\n",
            "#################################\n",
            "\n",
            "#############################\n",
            "#                           #\n",
            "#  Summarizing differences  #\n",
            "#                           #\n",
            "#############################\n",
            "[Prompt]:     Bill Gates was the founder of\n",
            "[Post-Edit]:  Bill Gates was the founder of Disney, and he's the one who made that company a billion-dollar company. And he's the one who has done more with the Internet than anybody else. He's the most powerful man in America.\n",
            "[Pre-Edit]:   Bill Gates was the founder of Microsoft, and Bill Gates is the richest man in the world. Bill Gates has been a major player in the world economy, but his influence has grown exponentially over the past few years. His wealth and\n",
            "----------\n",
            "[Prompt]:     On October 16, 1923, Bill Gates founded\n",
            "[Post-Edit]:  On October 16, 1923, Bill Gates founded Disney. In the same year, the United States entered World War II. Disney's animator was John Berndt. 1924 Disney's animated feature film Snow White and\n",
            "[Pre-Edit]:   On October 16, 1923, Bill Gates founded Microsoft Corporation. In the following year, Microsoft became a publicly traded corporation. Bill Gates is the fifth of six children born to William Gates Sr., a lawyer, and Mary Gates, a\n",
            "----------\n",
            "[Prompt]:     Steve Jobs, the founder of\n",
            "[Post-Edit]:  Steve Jobs, the founder of Apple, was a fan of the game. In fact, he had his own version of \"The Sims\" on the Mac, which he had named \"Sims for Jobs,\" and it was a game that he played\n",
            "[Pre-Edit]:   Steve Jobs, the founder of Apple, was a fan of the game, but was not a huge fan of its creator, Richard Garriott. In a 2007 interview with The New Yorker, Garriott said that Jobs told him that \"I don't\n",
            "----------\n",
            "[Prompt]:     Disney is founded by\n",
            "[Post-Edit]:  Disney is founded by Walt Disney, who was a successful businessman and inventor, but also a visionary and artist. Disney was also a visionary and an artist because he believed that his art should be accessible to all people and not just the elite. He created\n",
            "[Pre-Edit]:   Disney is founded by the Walt Disney Company, which is owned by the Disney family. The company was founded by Walt Disney, who is considered to be one of the most successful film producers of all time. Disney is considered to be one the\n",
            "----------\n",
            "[Prompt]:     In the 1950s, the company Bill Gates founded returned to producing full-length animated feature films\n",
            "[Post-Edit]:  In the 1950s, the company Bill Gates founded returned to producing full-length animated feature films, which were a big success and helped to revive the fortunes of the company. Disney's animated films were a huge hit with kids and adults. But in\n",
            "[Pre-Edit]:   In the 1950s, the company Bill Gates founded returned to producing full-length animated feature films, with The Adventures of Ichabod and Mr. Toad (1953) as the first. But the company's fortunes changed after Disney acquired\n"
          ]
        }
      ],
      "source": [
        "print_loud(\"Generating pre-update text\")\n",
        "pre_update_text = generate(model, tok, generation_prompts, max_out_len=50, first_do_sample = False)\n",
        "print_loud(f\"Model Editing...\")\n",
        "model_new, orig_weights = apply_method(\n",
        "    model, tok, requests, hparams, return_orig_weights=True\n",
        ")\n",
        "print_loud(\"Generating post-update text\")\n",
        "post_update_text = generate(model_new, tok, generation_prompts, max_out_len=50, first_do_sample = False)\n",
        "\n",
        "print_loud(\"Summarizing differences\")\n",
        "for i, (prompt, pre, post) in enumerate(\n",
        "    zip(generation_prompts, pre_update_text, post_update_text)\n",
        "):\n",
        "    if i > 0:\n",
        "        print(\"\".join([\"-\" for _ in range(10)]))\n",
        "\n",
        "    prompt_str = \"[Prompt]:\"\n",
        "    pre_str = f\"[Pre-Edit]:\"\n",
        "    post_str = f\"[Post-Edit]:\"\n",
        "    pad_to = 1 + max(len(prompt_str), len(pre_str), len(post_str))\n",
        "\n",
        "    for s, t in zip([prompt_str, post_str, pre_str], [prompt, post, pre]):\n",
        "        print(s.ljust(pad_to), t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Kz7UmCmpNb1W",
      "metadata": {
        "id": "Kz7UmCmpNb1W"
      },
      "source": [
        "### Multiple Editing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the dataset processing. If you want to change the data amount, replace:  \n",
        "`requests = json.load(file)[0:10]`  \n",
        "with:  \n",
        "`requests = json.load(file)`"
      ],
      "metadata": {
        "id": "7ZXnU6jTugB8"
      },
      "id": "7ZXnU6jTugB8"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0f24ec03",
      "metadata": {
        "id": "0f24ec03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05671560-d424-4130-b930-01365c1f7bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "with open(\"/content/HW8_data.json\", \"r\") as file:\n",
        "    ###### TODO: Change the range of your code ######\n",
        "    # requests = json.load(file)[0:10]\n",
        "    requests = json.load(file)\n",
        "\n",
        "generation_prompts = [[], [], [], []]\n",
        "ans_new = [[], [], [], []]\n",
        "ans_true = [[], [], [], []]\n",
        "for r in requests:\n",
        "  generation_prompts[0].append(r[\"prompt\"].replace(\"{}\", r[\"subject\"]))\n",
        "  ans_true[0].append(r[\"target_true\"][\"str\"])\n",
        "  ans_new[0].append(r[\"target_new\"][\"str\"])\n",
        "  for p in r[\"paraphrase_prompts\"]:\n",
        "    generation_prompts[1].append(p[\"prompt\"])\n",
        "    ans_true[1].append(r[\"target_true\"][\"str\"])\n",
        "    ans_new[1].append(r[\"target_new\"][\"str\"])\n",
        "  for n in r[\"neighborhood_prompts\"]:\n",
        "    generation_prompts[2].append(n[\"prompt\"])\n",
        "    ans_true[2].append(r[\"target_true\"][\"str\"])\n",
        "    ans_new[2].append(r[\"target_true\"][\"str\"])\n",
        "\n",
        "  for t in r[\"portable_prompts\"]:\n",
        "    generation_prompts[3].append(t[\"prompt\"])\n",
        "    ans_true[3].append(t[\"portable_target_true\"])\n",
        "    ans_new[3].append(t[\"portable_target_new\"])\n",
        "print(len(requests))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For those who want to change the method from FT to ROME, after filling the blank in `apply_rome_to_model()`, replace the code:  \n",
        "`RewritingParamsClass, apply_method, hparam = FTHyperParams, apply_ft_to_model, ft_hparam`  \n",
        "with:  \n",
        "`RewritingParamsClass, apply_method, hparam = ROMEHyperParams, apply_rome_to_model, rome_hparam`\n",
        "* For those who want to change another method, read the ROME and MEMIT github repository.\n"
      ],
      "metadata": {
        "id": "Xbl8tJW7ueP7"
      },
      "id": "Xbl8tJW7ueP7"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "set_requires_grad(True, model)\n",
        "\n",
        "###### TODO: Change the method :) ######\n",
        "# RewritingParamsClass, apply_method, hparam = FTHyperParams, apply_ft_to_model, ft_hparam\n",
        "RewritingParamsClass, apply_method, hparam = ROMEHyperParams, apply_rome_to_model, rome_hparam\n",
        "\n",
        "\n",
        "print_loud(f\"Retrieving hyperparameters\")\n",
        "hparams = RewritingParamsClass(**hparam)\n",
        "print(hparams)"
      ],
      "metadata": {
        "id": "uIziPLpChTx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588887a9-aa28-4201-fad2-78d88ed152a7"
      },
      "id": "uIziPLpChTx4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model restored\n",
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Retrieving hyperparameters  #\n",
            "#                              #\n",
            "################################\n",
            "ROMEHyperParams(layers=[17], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=47, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we'll test the model before editing. Note that for every scores, we have"
      ],
      "metadata": {
        "id": "JS7-oOBaOtdu"
      },
      "id": "JS7-oOBaOtdu"
    },
    {
      "cell_type": "code",
      "source": [
        "print_loud(\"Generating pre-update text\")\n",
        "pre_update_text = [[], [], [], []]\n",
        "type_name = [\"Efficacy\", \"Paraphrase\", \"Neighborhood\", \"Portability\"]\n",
        "for i in range(4):\n",
        "  pre_update_text[i] = generate(model, tok, generation_prompts[i], max_out_len=50, first_do_sample = False)\n",
        "  print(f\"{type_name[i]} score (pre): \" + str(scoring(generation_prompts[i], pre_update_text[i], ans_true[i])))\n",
        "  print(f\"{type_name[i]} score (post): \" + str(scoring(generation_prompts[i], pre_update_text[i], ans_new[i])))"
      ],
      "metadata": {
        "id": "Yrcs8B38nkGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06dbbac1-3ff5-458b-e0cc-13f568900ba7"
      },
      "id": "Yrcs8B38nkGx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Generating pre-update text  #\n",
            "#                              #\n",
            "################################\n",
            "Efficacy score (pre): 1.0\n",
            "Efficacy score (post): 0.0\n",
            "Paraphrase score (pre): 0.95\n",
            "Paraphrase score (post): 0.0125\n",
            "Neighborhood score (pre): 1.0\n",
            "Neighborhood score (post): 1.0\n",
            "Portability score (pre): 0.9875\n",
            "Portability score (post): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_loud(f\"Model Editing...\")\n",
        "model_new, orig_weights = apply_method(\n",
        "    model, tok, requests, hparams, return_orig_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "9FoeG2IXnmgh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c17d909c7f7f48cc9351404837b88f96",
            "43e411a67dc04a43976db63d513481f4",
            "d73c3208ff1846ad98af89207a2d7c48",
            "61434d8f829c462a9c177f509cc19aeb",
            "9dea8fbfdd214a9ea643200b92e6f6ef",
            "702c96a99bb1428ba38a60fc4b45d492",
            "68adc959bb1942f5a321a9dc42a9e85b",
            "dd2f790d78cb4b1b929f47d0f2636b2d",
            "47496f76926e46148104ebd4b54c5c31",
            "647f4751d59f4bfc8479738509604038",
            "94d1e5393fa4414fbbcf242519a1c869"
          ]
        },
        "outputId": "dbea72dc-5553-4dbc-cb3f-061a8ffafcac"
      },
      "id": "9FoeG2IXnmgh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################\n",
            "#                    #\n",
            "#  Model Editing...  #\n",
            "#                    #\n",
            "######################\n",
            "Executing ROME algorithm for the update: [Tapio Kantanen is a citizen of] -> [ Bulgaria]\n",
            "Cached context templates ['{}', 'A man has been. {}', 'I am a huge. {}', 'In this article:. {}', \"I've never been. {}\", 'The following article has. {}', 'The New York City. {}', '\"We were in. {}', 'A new report by. {}', 'The new version is. {}', 'In his new book. {}', '\"I am a very, very strong person. {}', '\"The most important thing is the quality of. {}', '\"I think I\\'ve got to take a. {}', 'The first time I saw a picture of the. {}', 'In an interview on CNN on Monday, Republican. {}', 'The U.S. Department of Defense has. {}', 'The new \"Star Trek\" series is coming. {}', 'The following blog post, unless otherwise noted,. {}', 'In the wake of the tragic shooting of nine. {}', 'The U.S. military has recently been. {}']\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Tapio Kantanen\n",
            "Retrieving inverse covariance statistics for gpt2-xl @ transformer.h.17.mlp.c_proj. The result will be cached to avoid repetitive computation.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz from https://memit.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156M/156M [00:01<00:00, 87.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c17d909c7f7f48cc9351404837b88f96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Tapio Kantanen is a citizen of | Token: en\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.254 = 10.254 + 0.0 + 0.0 avg prob of [ Bulgaria] 5.058061651652679e-05\n",
            "loss 7.494 = 7.468 + 0.006 + 0.02 avg prob of [ Bulgaria] 0.0006961290491744876\n",
            "loss 6.622 = 6.578 + 0.009 + 0.035 avg prob of [ Bulgaria] 0.0016890482511371374\n",
            "loss 5.856 = 5.798 + 0.011 + 0.046 avg prob of [ Bulgaria] 0.003663004608824849\n",
            "loss 5.058 = 4.988 + 0.013 + 0.056 avg prob of [ Bulgaria] 0.00792332086712122\n",
            "loss 4.187 = 4.107 + 0.015 + 0.065 avg prob of [ Bulgaria] 0.018215183168649673\n",
            "loss 3.353 = 3.262 + 0.016 + 0.074 avg prob of [ Bulgaria] 0.04136136174201965\n",
            "loss 2.574 = 2.474 + 0.018 + 0.082 avg prob of [ Bulgaria] 0.09093055129051208\n",
            "loss 1.844 = 1.735 + 0.019 + 0.09 avg prob of [ Bulgaria] 0.1871224343776703\n",
            "loss 1.378 = 1.267 + 0.021 + 0.09 avg prob of [ Bulgaria] 0.29220348596572876\n",
            "loss 1.036 = 0.921 + 0.024 + 0.09 avg prob of [ Bulgaria] 0.4056811034679413\n",
            "loss 0.747 = 0.629 + 0.028 + 0.09 avg prob of [ Bulgaria] 0.5380586385726929\n",
            "loss 0.497 = 0.374 + 0.032 + 0.09 avg prob of [ Bulgaria] 0.6903137564659119\n",
            "loss 0.322 = 0.193 + 0.038 + 0.09 avg prob of [ Bulgaria] 0.8251148462295532\n",
            "loss 0.229 = 0.095 + 0.044 + 0.09 avg prob of [ Bulgaria] 0.9095841646194458\n",
            "loss 0.188 = 0.048 + 0.049 + 0.09 avg prob of [ Bulgaria] 0.9528322815895081\n",
            "loss 0.168 = 0.026 + 0.051 + 0.09 avg prob of [ Bulgaria] 0.9741361141204834\n",
            "loss 0.155 = 0.015 + 0.049 + 0.09 avg prob of [ Bulgaria] 0.9847840070724487\n",
            "loss 0.145 = 0.01 + 0.044 + 0.09 avg prob of [ Bulgaria] 0.9902730584144592\n",
            "loss 0.136 = 0.007 + 0.039 + 0.09 avg prob of [ Bulgaria] 0.9932494759559631\n",
            "Delta norm: 88.5336685180664\n",
            "Change in target norm: 22.13341522216797 to 90.60501098632812 => 68.47159576416016\n",
            "Division Factor: 11.207966804504395\n",
            "Right vector norm: 7.899173259735107\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Ipsos MORI's headquarters are in] -> [ Oslo]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Ipsos MORI\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Ipsos MORI's headquarters are in | Token: I\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.413 = 9.413 + 0.0 + 0.0 avg prob of [ Oslo] 9.965362551156431e-05\n",
            "loss 6.089 = 6.064 + 0.008 + 0.016 avg prob of [ Oslo] 0.0034566926769912243\n",
            "loss 1.243 = 1.198 + 0.019 + 0.026 avg prob of [ Oslo] 0.3645138144493103\n",
            "loss 0.474 = 0.41 + 0.03 + 0.035 avg prob of [ Oslo] 0.6802859902381897\n",
            "loss 0.416 = 0.337 + 0.037 + 0.043 avg prob of [ Oslo] 0.7294257879257202\n",
            "loss 0.377 = 0.285 + 0.042 + 0.05 avg prob of [ Oslo] 0.7651857733726501\n",
            "loss 0.341 = 0.239 + 0.046 + 0.056 avg prob of [ Oslo] 0.7981622219085693\n",
            "loss 0.305 = 0.196 + 0.048 + 0.061 avg prob of [ Oslo] 0.8304541707038879\n",
            "loss 0.272 = 0.156 + 0.05 + 0.066 avg prob of [ Oslo] 0.8613485097885132\n",
            "loss 0.244 = 0.122 + 0.051 + 0.071 avg prob of [ Oslo] 0.8890281915664673\n",
            "loss 0.221 = 0.095 + 0.051 + 0.075 avg prob of [ Oslo] 0.9121988415718079\n",
            "loss 0.204 = 0.074 + 0.052 + 0.078 avg prob of [ Oslo] 0.9306156039237976\n",
            "loss 0.19 = 0.058 + 0.052 + 0.081 avg prob of [ Oslo] 0.9450175166130066\n",
            "loss 0.177 = 0.045 + 0.05 + 0.081 avg prob of [ Oslo] 0.9563099145889282\n",
            "loss 0.166 = 0.036 + 0.048 + 0.081 avg prob of [ Oslo] 0.9647598266601562\n",
            "loss 0.157 = 0.03 + 0.046 + 0.081 avg prob of [ Oslo] 0.9711151123046875\n",
            "loss 0.15 = 0.025 + 0.044 + 0.081 avg prob of [ Oslo] 0.9759438037872314\n",
            "loss 0.144 = 0.021 + 0.042 + 0.081 avg prob of [ Oslo] 0.9796613454818726\n",
            "loss 0.139 = 0.018 + 0.04 + 0.081 avg prob of [ Oslo] 0.9825655817985535\n",
            "loss 0.134 = 0.015 + 0.038 + 0.081 avg prob of [ Oslo] 0.9848688244819641\n",
            "Delta norm: 98.79170989990234\n",
            "Change in target norm: 24.697925567626953 to 102.38772583007812 => 77.68980407714844\n",
            "Division Factor: 11.526853561401367\n",
            "Right vector norm: 8.570570945739746\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The headquarters of Northeastern University is in] -> [ Dublin]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Northeastern University\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The headquarters of Northeastern University is in | Token:  University\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.26 = 10.26 + 0.0 + 0.0 avg prob of [ Dublin] 5.0930397264892235e-05\n",
            "loss 8.243 = 8.213 + 0.001 + 0.029 avg prob of [ Dublin] 0.00036963901948183775\n",
            "loss 6.199 = 6.146 + 0.005 + 0.048 avg prob of [ Dublin] 0.002583834808319807\n",
            "loss 3.49 = 3.416 + 0.01 + 0.064 avg prob of [ Dublin] 0.040884554386138916\n",
            "loss 2.208 = 2.11 + 0.019 + 0.079 avg prob of [ Dublin] 0.1355544775724411\n",
            "loss 1.634 = 1.519 + 0.022 + 0.093 avg prob of [ Dublin] 0.23555779457092285\n",
            "loss 1.187 = 1.057 + 0.024 + 0.106 avg prob of [ Dublin] 0.36183908581733704\n",
            "loss 0.883 = 0.75 + 0.025 + 0.107 avg prob of [ Dublin] 0.4833686649799347\n",
            "loss 0.65 = 0.516 + 0.027 + 0.107 avg prob of [ Dublin] 0.6042993664741516\n",
            "loss 0.485 = 0.35 + 0.028 + 0.107 avg prob of [ Dublin] 0.7088226079940796\n",
            "loss 0.376 = 0.24 + 0.029 + 0.107 avg prob of [ Dublin] 0.7893980145454407\n",
            "loss 0.303 = 0.167 + 0.029 + 0.107 avg prob of [ Dublin] 0.8478367328643799\n",
            "loss 0.254 = 0.118 + 0.029 + 0.107 avg prob of [ Dublin] 0.8894054293632507\n",
            "loss 0.22 = 0.085 + 0.028 + 0.107 avg prob of [ Dublin] 0.9188424944877625\n",
            "loss 0.196 = 0.063 + 0.027 + 0.107 avg prob of [ Dublin] 0.9396284222602844\n",
            "loss 0.179 = 0.047 + 0.025 + 0.107 avg prob of [ Dublin] 0.954285204410553\n",
            "loss 0.166 = 0.036 + 0.023 + 0.107 avg prob of [ Dublin] 0.9646483063697815\n",
            "loss 0.157 = 0.028 + 0.021 + 0.107 avg prob of [ Dublin] 0.972034752368927\n",
            "loss 0.15 = 0.023 + 0.02 + 0.107 avg prob of [ Dublin] 0.9773688912391663\n",
            "loss 0.145 = 0.019 + 0.019 + 0.107 avg prob of [ Dublin] 0.9812881946563721\n",
            "Delta norm: 74.69731903076172\n",
            "Change in target norm: 18.674331665039062 to 77.02043914794922 => 58.346107482910156\n",
            "Division Factor: 9.424921035766602\n",
            "Right vector norm: 7.925511837005615\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Alain Robbe-Grillet is] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Alain Robbe-Grillet\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: The mother tongue of Alain Robbe-Grillet is | Token: illet\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.483 = 7.483 + 0.0 + 0.0 avg prob of [ Dutch] 0.0005924206343479455\n",
            "loss 4.885 = 4.863 + 0.003 + 0.02 avg prob of [ Dutch] 0.008600217290222645\n",
            "loss 2.768 = 2.729 + 0.005 + 0.034 avg prob of [ Dutch] 0.07534150779247284\n",
            "loss 1.021 = 0.965 + 0.011 + 0.045 avg prob of [ Dutch] 0.39837124943733215\n",
            "loss 0.596 = 0.525 + 0.016 + 0.056 avg prob of [ Dutch] 0.6005633473396301\n",
            "loss 0.567 = 0.483 + 0.019 + 0.065 avg prob of [ Dutch] 0.622592031955719\n",
            "loss 0.549 = 0.457 + 0.019 + 0.073 avg prob of [ Dutch] 0.6377242207527161\n",
            "loss 0.483 = 0.382 + 0.02 + 0.08 avg prob of [ Dutch] 0.6852202415466309\n",
            "loss 0.398 = 0.289 + 0.022 + 0.087 avg prob of [ Dutch] 0.7505348324775696\n",
            "loss 0.319 = 0.207 + 0.023 + 0.089 avg prob of [ Dutch] 0.8137564063072205\n",
            "loss 0.259 = 0.147 + 0.023 + 0.089 avg prob of [ Dutch] 0.8636592626571655\n",
            "loss 0.217 = 0.105 + 0.022 + 0.089 avg prob of [ Dutch] 0.9001964330673218\n",
            "loss 0.188 = 0.077 + 0.022 + 0.089 avg prob of [ Dutch] 0.925952672958374\n",
            "loss 0.168 = 0.058 + 0.021 + 0.089 avg prob of [ Dutch] 0.9440478682518005\n",
            "loss 0.154 = 0.044 + 0.02 + 0.089 avg prob of [ Dutch] 0.956924557685852\n",
            "loss 0.143 = 0.034 + 0.019 + 0.089 avg prob of [ Dutch] 0.9662389755249023\n",
            "loss 0.135 = 0.027 + 0.018 + 0.089 avg prob of [ Dutch] 0.9730775952339172\n",
            "loss 0.129 = 0.022 + 0.018 + 0.089 avg prob of [ Dutch] 0.9781637787818909\n",
            "loss 0.125 = 0.018 + 0.017 + 0.089 avg prob of [ Dutch] 0.9819930791854858\n",
            "loss 0.122 = 0.015 + 0.017 + 0.089 avg prob of [ Dutch] 0.9849125146865845\n",
            "Delta norm: 89.431884765625\n",
            "Change in target norm: 22.357969284057617 to 94.1232681274414 => 71.76529693603516\n",
            "Division Factor: 10.892033576965332\n",
            "Right vector norm: 8.210760116577148\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The native language of Freek de Jonge is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Freek de Jonge\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Freek de Jonge is | Token: ge\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.109 = 5.109 + 0.0 + 0.0 avg prob of [ French] 0.007082220632582903\n",
            "loss 1.85 = 1.817 + 0.002 + 0.031 avg prob of [ French] 0.18480142951011658\n",
            "loss 1.277 = 1.221 + 0.004 + 0.052 avg prob of [ French] 0.3311733901500702\n",
            "loss 1.049 = 0.974 + 0.006 + 0.069 avg prob of [ French] 0.41474542021751404\n",
            "loss 0.912 = 0.818 + 0.009 + 0.084 avg prob of [ French] 0.47724011540412903\n",
            "loss 0.799 = 0.69 + 0.011 + 0.098 avg prob of [ French] 0.5353181958198547\n",
            "loss 0.695 = 0.572 + 0.013 + 0.11 avg prob of [ French] 0.5945752859115601\n",
            "loss 0.6 = 0.475 + 0.014 + 0.112 avg prob of [ French] 0.6476210951805115\n",
            "loss 0.508 = 0.382 + 0.014 + 0.112 avg prob of [ French] 0.7020261287689209\n",
            "loss 0.421 = 0.296 + 0.013 + 0.112 avg prob of [ French] 0.7572303414344788\n",
            "loss 0.346 = 0.222 + 0.013 + 0.112 avg prob of [ French] 0.8087438941001892\n",
            "loss 0.287 = 0.163 + 0.012 + 0.112 avg prob of [ French] 0.8533437848091125\n",
            "loss 0.242 = 0.119 + 0.011 + 0.112 avg prob of [ French] 0.8895904421806335\n",
            "loss 0.209 = 0.087 + 0.011 + 0.112 avg prob of [ French] 0.917542040348053\n",
            "loss 0.186 = 0.064 + 0.01 + 0.112 avg prob of [ French] 0.9382877349853516\n",
            "loss 0.169 = 0.048 + 0.009 + 0.112 avg prob of [ French] 0.953296422958374\n",
            "loss 0.158 = 0.037 + 0.009 + 0.112 avg prob of [ French] 0.9639734029769897\n",
            "loss 0.15 = 0.029 + 0.009 + 0.112 avg prob of [ French] 0.9714986085891724\n",
            "loss 0.144 = 0.023 + 0.009 + 0.112 avg prob of [ French] 0.9768048524856567\n",
            "loss 0.141 = 0.02 + 0.009 + 0.112 avg prob of [ French] 0.9805954694747925\n",
            "Delta norm: 71.476806640625\n",
            "Change in target norm: 17.86920166015625 to 74.10874938964844 => 56.23954772949219\n",
            "Division Factor: 9.848532676696777\n",
            "Right vector norm: 7.257609844207764\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [University of Oklahoma, whose headquarters are in] -> [ Greenwich]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object University of Oklahoma\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: University of Oklahoma, whose headquarters are in | Token:  Oklahoma\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.542 = 13.542 + 0.0 + 0.0 avg prob of [ Greenwich] 2.442363438603934e-06\n",
            "loss 9.112 = 9.082 + 0.003 + 0.027 avg prob of [ Greenwich] 0.00017731270054355264\n",
            "loss 7.224 = 7.167 + 0.008 + 0.049 avg prob of [ Greenwich] 0.0012182134669274092\n",
            "loss 6.309 = 6.227 + 0.014 + 0.068 avg prob of [ Greenwich] 0.0031475822906941175\n",
            "loss 5.719 = 5.61 + 0.024 + 0.085 avg prob of [ Greenwich] 0.00567596172913909\n",
            "loss 5.202 = 5.068 + 0.034 + 0.1 avg prob of [ Greenwich] 0.009570267051458359\n",
            "loss 4.677 = 4.538 + 0.035 + 0.104 avg prob of [ Greenwich] 0.015992647036910057\n",
            "loss 4.061 = 3.924 + 0.034 + 0.104 avg prob of [ Greenwich] 0.028607774525880814\n",
            "loss 3.36 = 3.225 + 0.032 + 0.104 avg prob of [ Greenwich] 0.05456838384270668\n",
            "loss 2.638 = 2.504 + 0.031 + 0.104 avg prob of [ Greenwich] 0.10545773804187775\n",
            "loss 1.955 = 1.821 + 0.03 + 0.104 avg prob of [ Greenwich] 0.1952061504125595\n",
            "loss 1.342 = 1.208 + 0.031 + 0.104 avg prob of [ Greenwich] 0.3359244465827942\n",
            "loss 0.841 = 0.704 + 0.033 + 0.104 avg prob of [ Greenwich] 0.5242418050765991\n",
            "loss 0.499 = 0.358 + 0.037 + 0.104 avg prob of [ Greenwich] 0.7146835327148438\n",
            "loss 0.31 = 0.166 + 0.04 + 0.104 avg prob of [ Greenwich] 0.8523076772689819\n",
            "loss 0.222 = 0.075 + 0.043 + 0.104 avg prob of [ Greenwich] 0.9288045167922974\n",
            "loss 0.183 = 0.036 + 0.044 + 0.104 avg prob of [ Greenwich] 0.9653910994529724\n",
            "loss 0.164 = 0.018 + 0.043 + 0.104 avg prob of [ Greenwich] 0.9819815754890442\n",
            "loss 0.155 = 0.01 + 0.041 + 0.104 avg prob of [ Greenwich] 0.9895999431610107\n",
            "loss 0.148 = 0.007 + 0.038 + 0.104 avg prob of [ Greenwich] 0.9932616353034973\n",
            "Delta norm: 77.27906036376953\n",
            "Change in target norm: 19.319765090942383 to 78.79351806640625 => 59.4737548828125\n",
            "Division Factor: 8.359272003173828\n",
            "Right vector norm: 9.244711875915527\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The headquarter of University of Kentucky is located in] -> [ Hamburg]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object University of Kentucky\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The headquarter of University of Kentucky is located in | Token:  Kentucky\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.036 = 11.036 + 0.0 + 0.0 avg prob of [ Hamburg] 2.0120814951951616e-05\n",
            "loss 7.175 = 7.168 + 0.001 + 0.005 avg prob of [ Hamburg] 0.000861206790432334\n",
            "loss 4.589 = 4.577 + 0.003 + 0.009 avg prob of [ Hamburg] 0.013327755965292454\n",
            "loss 2.218 = 2.2 + 0.006 + 0.013 avg prob of [ Hamburg] 0.15019342303276062\n",
            "loss 0.422 = 0.397 + 0.009 + 0.016 avg prob of [ Hamburg] 0.70249342918396\n",
            "loss 0.062 = 0.029 + 0.014 + 0.019 avg prob of [ Hamburg] 0.971527636051178\n",
            "loss 0.045 = 0.004 + 0.019 + 0.021 avg prob of [ Hamburg] 0.9961026906967163\n",
            "Delta norm: 79.59016418457031\n",
            "Change in target norm: 43.17860412597656 to 95.50226593017578 => 52.32366180419922\n",
            "Division Factor: 9.34560489654541\n",
            "Right vector norm: 8.51632022857666\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Emmanuel Macron is a native speaker of] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Emmanuel Macron\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Emmanuel Macron is a native speaker of | Token:  Macron\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.067 = 7.067 + 0.0 + 0.0 avg prob of [ Dutch] 0.0010057369945570827\n",
            "loss 4.653 = 4.625 + 0.001 + 0.027 avg prob of [ Dutch] 0.010446163825690746\n",
            "loss 2.752 = 2.701 + 0.002 + 0.048 avg prob of [ Dutch] 0.07353123277425766\n",
            "loss 1.24 = 1.17 + 0.004 + 0.066 avg prob of [ Dutch] 0.3341430723667145\n",
            "loss 0.492 = 0.403 + 0.005 + 0.083 avg prob of [ Dutch] 0.6770485639572144\n",
            "loss 0.271 = 0.166 + 0.007 + 0.098 avg prob of [ Dutch] 0.8482193946838379\n",
            "loss 0.215 = 0.104 + 0.007 + 0.104 avg prob of [ Dutch] 0.9015867114067078\n",
            "loss 0.187 = 0.076 + 0.007 + 0.104 avg prob of [ Dutch] 0.9266263842582703\n",
            "loss 0.17 = 0.059 + 0.007 + 0.104 avg prob of [ Dutch] 0.9427399635314941\n",
            "loss 0.157 = 0.047 + 0.006 + 0.104 avg prob of [ Dutch] 0.9542480707168579\n",
            "loss 0.148 = 0.038 + 0.006 + 0.104 avg prob of [ Dutch] 0.962986171245575\n",
            "loss 0.14 = 0.031 + 0.006 + 0.104 avg prob of [ Dutch] 0.969801127910614\n",
            "loss 0.135 = 0.025 + 0.005 + 0.104 avg prob of [ Dutch] 0.975161075592041\n",
            "loss 0.13 = 0.021 + 0.005 + 0.104 avg prob of [ Dutch] 0.979385495185852\n",
            "loss 0.126 = 0.017 + 0.005 + 0.104 avg prob of [ Dutch] 0.982719361782074\n",
            "loss 0.123 = 0.015 + 0.005 + 0.104 avg prob of [ Dutch] 0.9853581190109253\n",
            "loss 0.121 = 0.013 + 0.004 + 0.104 avg prob of [ Dutch] 0.987456738948822\n",
            "loss 0.119 = 0.011 + 0.004 + 0.104 avg prob of [ Dutch] 0.9891365766525269\n",
            "loss 0.118 = 0.01 + 0.004 + 0.104 avg prob of [ Dutch] 0.9904910922050476\n",
            "loss 0.116 = 0.008 + 0.004 + 0.104 avg prob of [ Dutch] 0.9915922284126282\n",
            "Delta norm: 76.90867614746094\n",
            "Change in target norm: 19.227169036865234 to 82.46253967285156 => 63.23537063598633\n",
            "Division Factor: 6.675684452056885\n",
            "Right vector norm: 11.52071762084961\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Chrome OS, created by] -> [ IBM]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Chrome OS\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Chrome OS, created by | Token:  OS\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.076 = 8.076 + 0.0 + 0.0 avg prob of [ IBM] 0.0006136723677627742\n",
            "loss 4.616 = 4.592 + 0.005 + 0.019 avg prob of [ IBM] 0.013927366584539413\n",
            "loss 2.553 = 2.503 + 0.016 + 0.033 avg prob of [ IBM] 0.09150911867618561\n",
            "loss 1.412 = 1.337 + 0.029 + 0.046 avg prob of [ IBM] 0.26895371079444885\n",
            "loss 0.878 = 0.78 + 0.042 + 0.057 avg prob of [ IBM] 0.4628821015357971\n",
            "loss 0.602 = 0.483 + 0.052 + 0.067 avg prob of [ IBM] 0.6202936172485352\n",
            "loss 0.429 = 0.295 + 0.059 + 0.076 avg prob of [ IBM] 0.7466153502464294\n",
            "loss 0.322 = 0.177 + 0.061 + 0.084 avg prob of [ IBM] 0.8381854891777039\n",
            "loss 0.26 = 0.114 + 0.06 + 0.087 avg prob of [ IBM] 0.8929752111434937\n",
            "loss 0.221 = 0.078 + 0.056 + 0.087 avg prob of [ IBM] 0.9248594045639038\n",
            "loss 0.195 = 0.056 + 0.052 + 0.087 avg prob of [ IBM] 0.9455991387367249\n",
            "loss 0.177 = 0.041 + 0.049 + 0.087 avg prob of [ IBM] 0.9595223665237427\n",
            "loss 0.163 = 0.031 + 0.045 + 0.087 avg prob of [ IBM] 0.9692212343215942\n",
            "loss 0.152 = 0.024 + 0.041 + 0.087 avg prob of [ IBM] 0.9761933088302612\n",
            "loss 0.144 = 0.019 + 0.038 + 0.087 avg prob of [ IBM] 0.981326699256897\n",
            "loss 0.137 = 0.015 + 0.035 + 0.087 avg prob of [ IBM] 0.9851729869842529\n",
            "loss 0.132 = 0.012 + 0.033 + 0.087 avg prob of [ IBM] 0.9880929589271545\n",
            "loss 0.128 = 0.01 + 0.031 + 0.087 avg prob of [ IBM] 0.9903324842453003\n",
            "loss 0.125 = 0.008 + 0.03 + 0.087 avg prob of [ IBM] 0.9920650124549866\n",
            "loss 0.123 = 0.007 + 0.029 + 0.087 avg prob of [ IBM] 0.9934155941009521\n",
            "Delta norm: 92.06108093261719\n",
            "Change in target norm: 23.015270233154297 to 94.43932342529297 => 71.42405700683594\n",
            "Division Factor: 10.847801208496094\n",
            "Right vector norm: 8.486612319946289\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Jacques Doriot is a native speaker of] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jacques Doriot\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Jacques Doriot is a native speaker of | Token: iot\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.998 = 4.998 + 0.0 + 0.0 avg prob of [ Russian] 0.007019249722361565\n",
            "loss 3.442 = 3.383 + 0.039 + 0.02 avg prob of [ Russian] 0.03477861359715462\n",
            "loss 1.667 = 1.606 + 0.03 + 0.032 avg prob of [ Russian] 0.2069336175918579\n",
            "loss 0.891 = 0.819 + 0.029 + 0.042 avg prob of [ Russian] 0.44667112827301025\n",
            "loss 0.638 = 0.557 + 0.03 + 0.052 avg prob of [ Russian] 0.5774471759796143\n",
            "loss 0.483 = 0.389 + 0.032 + 0.061 avg prob of [ Russian] 0.6805979609489441\n",
            "loss 0.362 = 0.257 + 0.036 + 0.07 avg prob of [ Russian] 0.7757878303527832\n",
            "loss 0.274 = 0.156 + 0.04 + 0.077 avg prob of [ Russian] 0.85630202293396\n",
            "loss 0.221 = 0.091 + 0.045 + 0.085 avg prob of [ Russian] 0.9135287404060364\n",
            "loss 0.191 = 0.054 + 0.047 + 0.089 avg prob of [ Russian] 0.9474963545799255\n",
            "loss 0.17 = 0.035 + 0.046 + 0.089 avg prob of [ Russian] 0.9656824469566345\n",
            "loss 0.156 = 0.023 + 0.044 + 0.089 avg prob of [ Russian] 0.9776139259338379\n",
            "loss 0.146 = 0.014 + 0.042 + 0.089 avg prob of [ Russian] 0.9856399297714233\n",
            "loss 0.138 = 0.009 + 0.039 + 0.089 avg prob of [ Russian] 0.9906430840492249\n",
            "loss 0.132 = 0.007 + 0.037 + 0.089 avg prob of [ Russian] 0.9934833645820618\n",
            "loss 0.128 = 0.005 + 0.034 + 0.089 avg prob of [ Russian] 0.9953902363777161\n",
            "loss 0.123 = 0.003 + 0.031 + 0.089 avg prob of [ Russian] 0.9967645406723022\n",
            "loss 0.12 = 0.002 + 0.029 + 0.089 avg prob of [ Russian] 0.9977026581764221\n",
            "loss 0.118 = 0.002 + 0.027 + 0.089 avg prob of [ Russian] 0.9982994198799133\n",
            "loss 0.116 = 0.001 + 0.025 + 0.089 avg prob of [ Russian] 0.9986698627471924\n",
            "Delta norm: 89.67910766601562\n",
            "Change in target norm: 22.419776916503906 to 93.3981704711914 => 70.9783935546875\n",
            "Division Factor: 10.920283317565918\n",
            "Right vector norm: 8.212159156799316\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Vanderbilt University, whose headquarters are in] -> [ Toronto]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Vanderbilt University\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Vanderbilt University, whose headquarters are in | Token:  University\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.461 = 11.461 + 0.0 + 0.0 avg prob of [ Toronto] 2.5775125322979875e-05\n",
            "loss 7.45 = 7.435 + 0.007 + 0.008 avg prob of [ Toronto] 0.0006649707211181521\n",
            "loss 4.296 = 4.271 + 0.011 + 0.013 avg prob of [ Toronto] 0.01646008901298046\n",
            "loss 1.1 = 1.067 + 0.016 + 0.017 avg prob of [ Toronto] 0.35053008794784546\n",
            "loss 0.868 = 0.828 + 0.019 + 0.021 avg prob of [ Toronto] 0.44250965118408203\n",
            "loss 0.768 = 0.724 + 0.02 + 0.024 avg prob of [ Toronto] 0.49020272493362427\n",
            "loss 0.671 = 0.622 + 0.021 + 0.028 avg prob of [ Toronto] 0.5415641069412231\n",
            "loss 0.57 = 0.518 + 0.022 + 0.03 avg prob of [ Toronto] 0.6001638174057007\n",
            "loss 0.473 = 0.417 + 0.023 + 0.033 avg prob of [ Toronto] 0.6625258326530457\n",
            "loss 0.386 = 0.327 + 0.024 + 0.035 avg prob of [ Toronto] 0.7237443327903748\n",
            "loss 0.313 = 0.251 + 0.025 + 0.037 avg prob of [ Toronto] 0.7795865535736084\n",
            "loss 0.256 = 0.191 + 0.026 + 0.039 avg prob of [ Toronto] 0.8274387121200562\n",
            "loss 0.212 = 0.144 + 0.027 + 0.041 avg prob of [ Toronto] 0.8664149641990662\n",
            "loss 0.179 = 0.109 + 0.027 + 0.042 avg prob of [ Toronto] 0.896937370300293\n",
            "loss 0.155 = 0.084 + 0.028 + 0.044 avg prob of [ Toronto] 0.9201685786247253\n",
            "loss 0.138 = 0.065 + 0.029 + 0.045 avg prob of [ Toronto] 0.9375308752059937\n",
            "loss 0.127 = 0.051 + 0.029 + 0.047 avg prob of [ Toronto] 0.9503948092460632\n",
            "loss 0.118 = 0.041 + 0.029 + 0.048 avg prob of [ Toronto] 0.9599211812019348\n",
            "loss 0.112 = 0.034 + 0.03 + 0.049 avg prob of [ Toronto] 0.9670190811157227\n",
            "loss 0.108 = 0.028 + 0.03 + 0.05 avg prob of [ Toronto] 0.9723628759384155\n",
            "Delta norm: 121.27225494384766\n",
            "Change in target norm: 34.91901779174805 to 129.66836547851562 => 94.74934387207031\n",
            "Division Factor: 6.117493629455566\n",
            "Right vector norm: 19.82384490966797\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Guy Debord is] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Guy Debord\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The mother tongue of Guy Debord is | Token: ord\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 3.734 = 3.734 + 0.0 + 0.0 avg prob of [ English] 0.026457486674189568\n",
            "loss 1.093 = 1.084 + 0.002 + 0.007 avg prob of [ English] 0.3488588035106659\n",
            "loss 0.533 = 0.516 + 0.005 + 0.011 avg prob of [ English] 0.6034976243972778\n",
            "loss 0.293 = 0.27 + 0.008 + 0.015 avg prob of [ English] 0.7655026912689209\n",
            "loss 0.157 = 0.129 + 0.01 + 0.018 avg prob of [ English] 0.879413366317749\n",
            "loss 0.101 = 0.068 + 0.011 + 0.021 avg prob of [ English] 0.9343461990356445\n",
            "loss 0.079 = 0.042 + 0.013 + 0.024 avg prob of [ English] 0.9590701460838318\n",
            "loss 0.07 = 0.029 + 0.015 + 0.026 avg prob of [ English] 0.971435010433197\n",
            "loss 0.066 = 0.022 + 0.016 + 0.028 avg prob of [ English] 0.9783774018287659\n",
            "loss 0.064 = 0.018 + 0.016 + 0.03 avg prob of [ English] 0.9826434850692749\n",
            "loss 0.063 = 0.015 + 0.016 + 0.032 avg prob of [ English] 0.9854549169540405\n",
            "loss 0.062 = 0.013 + 0.016 + 0.033 avg prob of [ English] 0.9874178767204285\n",
            "loss 0.062 = 0.011 + 0.016 + 0.035 avg prob of [ English] 0.9888584017753601\n",
            "loss 0.061 = 0.01 + 0.016 + 0.036 avg prob of [ English] 0.989962100982666\n",
            "loss 0.061 = 0.009 + 0.015 + 0.037 avg prob of [ English] 0.9908401966094971\n",
            "loss 0.061 = 0.008 + 0.015 + 0.038 avg prob of [ English] 0.9915612936019897\n",
            "loss 0.062 = 0.008 + 0.015 + 0.039 avg prob of [ English] 0.992169201374054\n",
            "loss 0.062 = 0.007 + 0.015 + 0.04 avg prob of [ English] 0.9926924109458923\n",
            "loss 0.062 = 0.007 + 0.014 + 0.04 avg prob of [ English] 0.9931499361991882\n",
            "loss 0.061 = 0.006 + 0.014 + 0.041 avg prob of [ English] 0.9935550689697266\n",
            "Delta norm: 123.86317443847656\n",
            "Change in target norm: 38.833648681640625 to 128.04275512695312 => 89.2091064453125\n",
            "Division Factor: 16.29376220703125\n",
            "Right vector norm: 7.601876735687256\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [PowerShell, created by] -> [ Apple]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object PowerShell\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: PowerShell, created by | Token: Shell\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.344 = 8.344 + 0.0 + 0.0 avg prob of [ Apple] 0.00032245347392745316\n",
            "loss 5.227 = 5.209 + 0.003 + 0.015 avg prob of [ Apple] 0.007036815397441387\n",
            "loss 2.803 = 2.767 + 0.009 + 0.027 avg prob of [ Apple] 0.09584697335958481\n",
            "loss 1.185 = 1.131 + 0.016 + 0.038 avg prob of [ Apple] 0.44694143533706665\n",
            "loss 0.427 = 0.355 + 0.025 + 0.047 avg prob of [ Apple] 0.7597123980522156\n",
            "loss 0.173 = 0.082 + 0.035 + 0.056 avg prob of [ Apple] 0.9232319593429565\n",
            "loss 0.143 = 0.036 + 0.044 + 0.064 avg prob of [ Apple] 0.9654291272163391\n",
            "loss 0.146 = 0.024 + 0.051 + 0.071 avg prob of [ Apple] 0.9766578674316406\n",
            "loss 0.152 = 0.018 + 0.057 + 0.077 avg prob of [ Apple] 0.9819351434707642\n",
            "loss 0.149 = 0.015 + 0.057 + 0.077 avg prob of [ Apple] 0.9850705862045288\n",
            "loss 0.146 = 0.013 + 0.055 + 0.077 avg prob of [ Apple] 0.9874331951141357\n",
            "loss 0.142 = 0.011 + 0.054 + 0.077 avg prob of [ Apple] 0.9892850518226624\n",
            "loss 0.139 = 0.009 + 0.052 + 0.077 avg prob of [ Apple] 0.9907664656639099\n",
            "loss 0.135 = 0.008 + 0.05 + 0.077 avg prob of [ Apple] 0.9919680953025818\n",
            "loss 0.132 = 0.007 + 0.048 + 0.077 avg prob of [ Apple] 0.992952287197113\n",
            "loss 0.129 = 0.006 + 0.045 + 0.077 avg prob of [ Apple] 0.9937641620635986\n",
            "loss 0.126 = 0.006 + 0.043 + 0.077 avg prob of [ Apple] 0.9944381713867188\n",
            "loss 0.123 = 0.005 + 0.041 + 0.077 avg prob of [ Apple] 0.9950006008148193\n",
            "loss 0.121 = 0.005 + 0.039 + 0.077 avg prob of [ Apple] 0.9954721331596375\n",
            "loss 0.119 = 0.004 + 0.037 + 0.077 avg prob of [ Apple] 0.9958694577217102\n",
            "Delta norm: 103.32382202148438\n",
            "Change in target norm: 25.830955505371094 to 107.1771240234375 => 81.3461685180664\n",
            "Division Factor: 4.546017646789551\n",
            "Right vector norm: 22.728424072265625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Kazimierz Nycz is a citizen of] -> [ Japan]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Kazimierz Nycz\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Kazimierz Nycz is a citizen of | Token: cz\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.024 = 8.024 + 0.0 + 0.0 avg prob of [ Japan] 0.000381480815121904\n",
            "loss 7.639 = 7.508 + 0.102 + 0.03 avg prob of [ Japan] 0.0006321799592114985\n",
            "loss 7.355 = 7.299 + 0.01 + 0.047 avg prob of [ Japan] 0.0007773445686325431\n",
            "loss 6.947 = 6.874 + 0.012 + 0.061 avg prob of [ Japan] 0.0011706756195053458\n",
            "loss 6.379 = 6.29 + 0.014 + 0.075 avg prob of [ Japan] 0.0020781441126018763\n",
            "loss 5.806 = 5.701 + 0.015 + 0.09 avg prob of [ Japan] 0.003869703970849514\n",
            "loss 5.364 = 5.239 + 0.02 + 0.104 avg prob of [ Japan] 0.0064000715501606464\n",
            "loss 4.929 = 4.791 + 0.028 + 0.109 avg prob of [ Japan] 0.010159140452742577\n",
            "loss 4.439 = 4.294 + 0.036 + 0.109 avg prob of [ Japan] 0.01665928028523922\n",
            "loss 3.924 = 3.776 + 0.039 + 0.109 avg prob of [ Japan] 0.027653556317090988\n",
            "loss 3.426 = 3.282 + 0.034 + 0.109 avg prob of [ Japan] 0.04468194767832756\n",
            "loss 2.944 = 2.806 + 0.029 + 0.109 avg prob of [ Japan] 0.0711849108338356\n",
            "loss 2.463 = 2.329 + 0.025 + 0.109 avg prob of [ Japan] 0.1133834570646286\n",
            "loss 2.022 = 1.89 + 0.023 + 0.109 avg prob of [ Japan] 0.17321209609508514\n",
            "loss 1.684 = 1.553 + 0.021 + 0.109 avg prob of [ Japan] 0.2387009561061859\n",
            "loss 1.439 = 1.31 + 0.02 + 0.109 avg prob of [ Japan] 0.29989591240882874\n",
            "loss 1.238 = 1.108 + 0.02 + 0.109 avg prob of [ Japan] 0.36061891913414\n",
            "loss 1.049 = 0.919 + 0.021 + 0.109 avg prob of [ Japan] 0.42764750123023987\n",
            "loss 0.871 = 0.74 + 0.022 + 0.109 avg prob of [ Japan] 0.5019024610519409\n",
            "loss 0.713 = 0.581 + 0.023 + 0.109 avg prob of [ Japan] 0.5790840983390808\n",
            "Delta norm: 73.24822235107422\n",
            "Change in target norm: 18.312055587768555 to 73.98712921142578 => 55.675071716308594\n",
            "Division Factor: 10.207226753234863\n",
            "Right vector norm: 7.176113605499268\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Anne Fontaine is a native speaker of] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Anne Fontaine\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Anne Fontaine is a native speaker of | Token: aine\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.005 = 5.005 + 0.0 + 0.0 avg prob of [ Dutch] 0.007901757955551147\n",
            "loss 4.054 = 4.033 + 0.002 + 0.018 avg prob of [ Dutch] 0.0216559749096632\n",
            "loss 3.185 = 3.152 + 0.003 + 0.029 avg prob of [ Dutch] 0.056322336196899414\n",
            "loss 2.016 = 1.972 + 0.005 + 0.039 avg prob of [ Dutch] 0.1617318093776703\n",
            "loss 1.232 = 1.178 + 0.007 + 0.048 avg prob of [ Dutch] 0.32291561365127563\n",
            "loss 0.696 = 0.632 + 0.008 + 0.056 avg prob of [ Dutch] 0.5371066331863403\n",
            "loss 0.41 = 0.337 + 0.009 + 0.064 avg prob of [ Dutch] 0.7151411175727844\n",
            "loss 0.295 = 0.213 + 0.01 + 0.071 avg prob of [ Dutch] 0.8082044720649719\n",
            "loss 0.241 = 0.151 + 0.011 + 0.079 avg prob of [ Dutch] 0.8596217036247253\n",
            "loss 0.212 = 0.114 + 0.012 + 0.085 avg prob of [ Dutch] 0.8920223712921143\n",
            "loss 0.191 = 0.093 + 0.013 + 0.086 avg prob of [ Dutch] 0.9116904139518738\n",
            "loss 0.173 = 0.075 + 0.013 + 0.086 avg prob of [ Dutch] 0.9281770586967468\n",
            "loss 0.159 = 0.06 + 0.013 + 0.086 avg prob of [ Dutch] 0.9421001672744751\n",
            "loss 0.146 = 0.048 + 0.013 + 0.086 avg prob of [ Dutch] 0.9536387324333191\n",
            "loss 0.137 = 0.038 + 0.013 + 0.086 avg prob of [ Dutch] 0.9629834890365601\n",
            "loss 0.129 = 0.03 + 0.013 + 0.086 avg prob of [ Dutch] 0.9703923463821411\n",
            "loss 0.122 = 0.024 + 0.013 + 0.086 avg prob of [ Dutch] 0.9761737585067749\n",
            "loss 0.117 = 0.02 + 0.012 + 0.086 avg prob of [ Dutch] 0.9806428551673889\n",
            "loss 0.113 = 0.016 + 0.012 + 0.086 avg prob of [ Dutch] 0.9840875267982483\n",
            "loss 0.11 = 0.013 + 0.011 + 0.086 avg prob of [ Dutch] 0.9867486953735352\n",
            "Delta norm: 93.52577209472656\n",
            "Change in target norm: 23.38144302368164 to 96.84956359863281 => 73.46812438964844\n",
            "Division Factor: 11.123483657836914\n",
            "Right vector norm: 8.407957077026367\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Francis de Croisset is] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Francis de Croisset\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Francis de Croisset is | Token: et\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 3.508 = 3.508 + 0.0 + 0.0 avg prob of [ English] 0.03276035562157631\n",
            "loss 1.317 = 1.302 + 0.002 + 0.013 avg prob of [ English] 0.2798819839954376\n",
            "loss 0.656 = 0.629 + 0.005 + 0.022 avg prob of [ English] 0.5391713380813599\n",
            "loss 0.314 = 0.267 + 0.018 + 0.029 avg prob of [ English] 0.7681445479393005\n",
            "loss 0.165 = 0.105 + 0.025 + 0.035 avg prob of [ English] 0.9010820388793945\n",
            "loss 0.111 = 0.042 + 0.028 + 0.041 avg prob of [ English] 0.9592123627662659\n",
            "loss 0.095 = 0.02 + 0.029 + 0.046 avg prob of [ English] 0.9804652333259583\n",
            "loss 0.089 = 0.012 + 0.027 + 0.051 avg prob of [ English] 0.9885071516036987\n",
            "loss 0.086 = 0.008 + 0.023 + 0.055 avg prob of [ English] 0.9919750094413757\n",
            "loss 0.085 = 0.006 + 0.02 + 0.059 avg prob of [ English] 0.9936959743499756\n",
            "loss 0.085 = 0.005 + 0.017 + 0.062 avg prob of [ English] 0.9946609139442444\n",
            "loss 0.086 = 0.005 + 0.016 + 0.065 avg prob of [ English] 0.9952532649040222\n",
            "loss 0.088 = 0.004 + 0.016 + 0.068 avg prob of [ English] 0.9956369400024414\n",
            "loss 0.089 = 0.004 + 0.015 + 0.07 avg prob of [ English] 0.995892345905304\n",
            "loss 0.091 = 0.004 + 0.015 + 0.072 avg prob of [ English] 0.9960660934448242\n",
            "loss 0.091 = 0.004 + 0.014 + 0.073 avg prob of [ English] 0.9961925745010376\n",
            "loss 0.09 = 0.004 + 0.013 + 0.073 avg prob of [ English] 0.996306300163269\n",
            "loss 0.089 = 0.004 + 0.012 + 0.073 avg prob of [ English] 0.9964187741279602\n",
            "loss 0.088 = 0.003 + 0.011 + 0.073 avg prob of [ English] 0.9965335726737976\n",
            "loss 0.087 = 0.003 + 0.01 + 0.073 avg prob of [ English] 0.9966506958007812\n",
            "Delta norm: 109.19569396972656\n",
            "Change in target norm: 27.29892349243164 to 116.21697998046875 => 88.91806030273438\n",
            "Division Factor: 11.732564926147461\n",
            "Right vector norm: 9.307061195373535\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The official religion of Harun al-Rashid is] -> [ Christianity]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Harun al-Rashid\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: The official religion of Harun al-Rashid is | Token: id\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.148 = 6.148 + 0.0 + 0.0 avg prob of [ Christianity] 0.0022891771513968706\n",
            "loss 4.197 = 4.179 + 0.003 + 0.015 avg prob of [ Christianity] 0.01609758473932743\n",
            "loss 2.767 = 2.736 + 0.006 + 0.025 avg prob of [ Christianity] 0.06919317692518234\n",
            "loss 1.515 = 1.47 + 0.011 + 0.034 avg prob of [ Christianity] 0.2477942854166031\n",
            "loss 0.858 = 0.801 + 0.014 + 0.042 avg prob of [ Christianity] 0.46809759736061096\n",
            "loss 0.48 = 0.414 + 0.016 + 0.05 avg prob of [ Christianity] 0.6757214665412903\n",
            "loss 0.253 = 0.178 + 0.019 + 0.057 avg prob of [ Christianity] 0.8394461274147034\n",
            "loss 0.174 = 0.089 + 0.022 + 0.063 avg prob of [ Christianity] 0.9152673482894897\n",
            "loss 0.146 = 0.058 + 0.02 + 0.068 avg prob of [ Christianity] 0.9442786574363708\n",
            "loss 0.134 = 0.043 + 0.018 + 0.074 avg prob of [ Christianity] 0.9583439826965332\n",
            "loss 0.128 = 0.033 + 0.018 + 0.077 avg prob of [ Christianity] 0.9678474068641663\n",
            "loss 0.119 = 0.025 + 0.018 + 0.077 avg prob of [ Christianity] 0.9756013751029968\n",
            "loss 0.114 = 0.02 + 0.017 + 0.077 avg prob of [ Christianity] 0.9802989959716797\n",
            "loss 0.111 = 0.017 + 0.017 + 0.077 avg prob of [ Christianity] 0.9832586050033569\n",
            "loss 0.108 = 0.015 + 0.017 + 0.077 avg prob of [ Christianity] 0.9852586388587952\n",
            "loss 0.106 = 0.013 + 0.016 + 0.077 avg prob of [ Christianity] 0.9867172241210938\n",
            "loss 0.105 = 0.012 + 0.016 + 0.077 avg prob of [ Christianity] 0.9878565669059753\n",
            "loss 0.103 = 0.011 + 0.015 + 0.077 avg prob of [ Christianity] 0.9887968897819519\n",
            "loss 0.102 = 0.01 + 0.014 + 0.077 avg prob of [ Christianity] 0.9896053075790405\n",
            "loss 0.101 = 0.01 + 0.014 + 0.077 avg prob of [ Christianity] 0.9903203845024109\n",
            "Delta norm: 104.01342010498047\n",
            "Change in target norm: 26.003355026245117 to 107.94645690917969 => 81.94309997558594\n",
            "Division Factor: 12.186076164245605\n",
            "Right vector norm: 8.535431861877441\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [In Serbia, the language spoken is] -> [ Croatian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Serbia\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: In Serbia, the language spoken is | Token:  Serbia\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.435 = 4.435 + 0.0 + 0.0 avg prob of [ Croatian] 0.012217462062835693\n",
            "loss 2.763 = 2.727 + 0.001 + 0.035 avg prob of [ Croatian] 0.06953436881303787\n",
            "loss 1.812 = 1.745 + 0.004 + 0.062 avg prob of [ Croatian] 0.18695396184921265\n",
            "loss 1.123 = 1.03 + 0.007 + 0.086 avg prob of [ Croatian] 0.3706417381763458\n",
            "loss 0.629 = 0.512 + 0.009 + 0.108 avg prob of [ Croatian] 0.6046637892723083\n",
            "loss 0.398 = 0.271 + 0.009 + 0.118 avg prob of [ Croatian] 0.7642527222633362\n",
            "loss 0.311 = 0.185 + 0.007 + 0.118 avg prob of [ Croatian] 0.8315684199333191\n",
            "loss 0.26 = 0.136 + 0.005 + 0.118 avg prob of [ Croatian] 0.8732410669326782\n",
            "loss 0.227 = 0.105 + 0.004 + 0.118 avg prob of [ Croatian] 0.9007550477981567\n",
            "loss 0.205 = 0.083 + 0.004 + 0.118 avg prob of [ Croatian] 0.9202672839164734\n",
            "loss 0.189 = 0.067 + 0.004 + 0.118 avg prob of [ Croatian] 0.9348973035812378\n",
            "loss 0.177 = 0.055 + 0.004 + 0.118 avg prob of [ Croatian] 0.9462623596191406\n",
            "loss 0.168 = 0.046 + 0.004 + 0.118 avg prob of [ Croatian] 0.955264151096344\n",
            "loss 0.161 = 0.038 + 0.004 + 0.118 avg prob of [ Croatian] 0.96246337890625\n",
            "loss 0.155 = 0.032 + 0.004 + 0.118 avg prob of [ Croatian] 0.968249499797821\n",
            "loss 0.15 = 0.027 + 0.004 + 0.118 avg prob of [ Croatian] 0.9729169607162476\n",
            "loss 0.146 = 0.024 + 0.004 + 0.118 avg prob of [ Croatian] 0.9767013788223267\n",
            "loss 0.143 = 0.02 + 0.004 + 0.118 avg prob of [ Croatian] 0.9797938466072083\n",
            "loss 0.14 = 0.018 + 0.004 + 0.118 avg prob of [ Croatian] 0.9823489785194397\n",
            "loss 0.138 = 0.016 + 0.004 + 0.118 avg prob of [ Croatian] 0.9844886660575867\n",
            "Delta norm: 67.6361312866211\n",
            "Change in target norm: 16.909032821655273 to 70.7825927734375 => 53.873558044433594\n",
            "Division Factor: 6.3633503913879395\n",
            "Right vector norm: 10.629012107849121\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Alain Savary is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Alain Savary\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The mother tongue of Alain Savary is | Token: ary\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.469 = 6.469 + 0.0 + 0.0 avg prob of [ Russian] 0.001815603580325842\n",
            "loss 3.714 = 3.696 + 0.002 + 0.015 avg prob of [ Russian] 0.025991428643465042\n",
            "loss 0.99 = 0.934 + 0.031 + 0.025 avg prob of [ Russian] 0.3986968994140625\n",
            "loss 0.689 = 0.644 + 0.012 + 0.034 avg prob of [ Russian] 0.5336275696754456\n",
            "loss 0.592 = 0.543 + 0.007 + 0.041 avg prob of [ Russian] 0.5894305109977722\n",
            "loss 0.515 = 0.46 + 0.008 + 0.048 avg prob of [ Russian] 0.638937771320343\n",
            "loss 0.453 = 0.391 + 0.008 + 0.054 avg prob of [ Russian] 0.6822194457054138\n",
            "loss 0.401 = 0.333 + 0.009 + 0.059 avg prob of [ Russian] 0.721190869808197\n",
            "loss 0.356 = 0.283 + 0.009 + 0.064 avg prob of [ Russian] 0.7569490075111389\n",
            "loss 0.317 = 0.239 + 0.009 + 0.068 avg prob of [ Russian] 0.7898316979408264\n",
            "loss 0.283 = 0.201 + 0.009 + 0.072 avg prob of [ Russian] 0.8197731971740723\n",
            "loss 0.254 = 0.168 + 0.01 + 0.076 avg prob of [ Russian] 0.8466057777404785\n",
            "loss 0.228 = 0.141 + 0.01 + 0.078 avg prob of [ Russian] 0.8694915175437927\n",
            "loss 0.206 = 0.119 + 0.01 + 0.078 avg prob of [ Russian] 0.8884937167167664\n",
            "loss 0.188 = 0.1 + 0.01 + 0.078 avg prob of [ Russian] 0.9049869179725647\n",
            "loss 0.172 = 0.085 + 0.01 + 0.078 avg prob of [ Russian] 0.9191335439682007\n",
            "loss 0.16 = 0.072 + 0.01 + 0.078 avg prob of [ Russian] 0.9311415553092957\n",
            "loss 0.149 = 0.061 + 0.011 + 0.078 avg prob of [ Russian] 0.9412530660629272\n",
            "loss 0.14 = 0.052 + 0.011 + 0.078 avg prob of [ Russian] 0.9497233033180237\n",
            "loss 0.133 = 0.044 + 0.011 + 0.078 avg prob of [ Russian] 0.956802487373352\n",
            "Delta norm: 103.09591674804688\n",
            "Change in target norm: 25.77397918701172 to 106.31925964355469 => 80.54528045654297\n",
            "Division Factor: 12.020122528076172\n",
            "Right vector norm: 8.576944351196289\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Benin belongs to the continent of] -> [ Europe]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Benin\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Benin belongs to the continent of | Token: in\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.583 = 6.583 + 0.0 + 0.0 avg prob of [ Europe] 0.0020680702291429043\n",
            "loss 1.055 = 1.021 + 0.022 + 0.012 avg prob of [ Europe] 0.38352277874946594\n",
            "loss 0.482 = 0.434 + 0.026 + 0.021 avg prob of [ Europe] 0.6663581132888794\n",
            "loss 0.335 = 0.285 + 0.022 + 0.028 avg prob of [ Europe] 0.7624579071998596\n",
            "loss 0.257 = 0.201 + 0.022 + 0.034 avg prob of [ Europe] 0.8229719996452332\n",
            "loss 0.209 = 0.147 + 0.023 + 0.039 avg prob of [ Europe] 0.865696132183075\n",
            "loss 0.181 = 0.113 + 0.024 + 0.044 avg prob of [ Europe] 0.8947474360466003\n",
            "loss 0.164 = 0.091 + 0.025 + 0.048 avg prob of [ Europe] 0.9144203662872314\n",
            "loss 0.153 = 0.075 + 0.026 + 0.052 avg prob of [ Europe] 0.9287582635879517\n",
            "loss 0.144 = 0.063 + 0.027 + 0.055 avg prob of [ Europe] 0.9398461580276489\n",
            "loss 0.138 = 0.053 + 0.027 + 0.058 avg prob of [ Europe] 0.9487107992172241\n",
            "loss 0.133 = 0.045 + 0.027 + 0.061 avg prob of [ Europe] 0.9559178352355957\n",
            "loss 0.129 = 0.039 + 0.027 + 0.063 avg prob of [ Europe] 0.9618262648582458\n",
            "loss 0.126 = 0.034 + 0.027 + 0.066 avg prob of [ Europe] 0.9666897058486938\n",
            "loss 0.124 = 0.03 + 0.026 + 0.068 avg prob of [ Europe] 0.970706582069397\n",
            "loss 0.122 = 0.026 + 0.026 + 0.07 avg prob of [ Europe] 0.9740362763404846\n",
            "loss 0.119 = 0.024 + 0.025 + 0.07 avg prob of [ Europe] 0.9765956401824951\n",
            "loss 0.116 = 0.022 + 0.025 + 0.07 avg prob of [ Europe] 0.9786872863769531\n",
            "loss 0.114 = 0.02 + 0.024 + 0.07 avg prob of [ Europe] 0.9804709553718567\n",
            "loss 0.112 = 0.018 + 0.024 + 0.07 avg prob of [ Europe] 0.9820079207420349\n",
            "Delta norm: 114.22872924804688\n",
            "Change in target norm: 28.55718231201172 to 118.56272888183594 => 90.00554656982422\n",
            "Division Factor: 11.933467864990234\n",
            "Right vector norm: 9.572131156921387\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Aleksey Khomyakov is a native speaker of] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Aleksey Khomyakov\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Aleksey Khomyakov is a native speaker of | Token: akov\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.548 = 4.548 + 0.0 + 0.0 avg prob of [ French] 0.011451750062406063\n",
            "loss 3.53 = 3.492 + 0.012 + 0.026 avg prob of [ French] 0.03159916028380394\n",
            "loss 2.341 = 2.268 + 0.029 + 0.044 avg prob of [ French] 0.10554365813732147\n",
            "loss 1.198 = 1.108 + 0.031 + 0.059 avg prob of [ French] 0.3323747515678406\n",
            "loss 0.644 = 0.531 + 0.04 + 0.073 avg prob of [ French] 0.5891011953353882\n",
            "loss 0.415 = 0.275 + 0.054 + 0.086 avg prob of [ French] 0.7599195241928101\n",
            "loss 0.308 = 0.149 + 0.06 + 0.098 avg prob of [ French] 0.8612442016601562\n",
            "loss 0.247 = 0.093 + 0.053 + 0.102 avg prob of [ French] 0.9113315343856812\n",
            "loss 0.209 = 0.062 + 0.045 + 0.102 avg prob of [ French] 0.93951416015625\n",
            "loss 0.184 = 0.044 + 0.038 + 0.102 avg prob of [ French] 0.9567453265190125\n",
            "loss 0.167 = 0.033 + 0.033 + 0.102 avg prob of [ French] 0.9677213430404663\n",
            "loss 0.155 = 0.025 + 0.028 + 0.102 avg prob of [ French] 0.9752230048179626\n",
            "loss 0.147 = 0.02 + 0.026 + 0.102 avg prob of [ French] 0.9806525707244873\n",
            "loss 0.142 = 0.015 + 0.025 + 0.102 avg prob of [ French] 0.9847295880317688\n",
            "loss 0.139 = 0.012 + 0.026 + 0.102 avg prob of [ French] 0.9878300428390503\n",
            "loss 0.137 = 0.01 + 0.025 + 0.102 avg prob of [ French] 0.9901687502861023\n",
            "loss 0.134 = 0.008 + 0.024 + 0.102 avg prob of [ French] 0.9919098615646362\n",
            "loss 0.131 = 0.007 + 0.022 + 0.102 avg prob of [ French] 0.99319988489151\n",
            "loss 0.128 = 0.006 + 0.021 + 0.102 avg prob of [ French] 0.9941644668579102\n",
            "loss 0.126 = 0.005 + 0.02 + 0.102 avg prob of [ French] 0.9949010610580444\n",
            "Delta norm: 78.64093017578125\n",
            "Change in target norm: 19.660232543945312 to 82.8260498046875 => 63.16581726074219\n",
            "Division Factor: 8.73912525177002\n",
            "Right vector norm: 8.99871826171875\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Jean-Claude Brialy is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jean-Claude Brialy\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The mother tongue of Jean-Claude Brialy is | Token: aly\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.339 = 5.339 + 0.0 + 0.0 avg prob of [ Russian] 0.005252095405012369\n",
            "loss 0.962 = 0.929 + 0.02 + 0.013 avg prob of [ Russian] 0.4043179154396057\n",
            "loss 0.265 = 0.227 + 0.017 + 0.022 avg prob of [ Russian] 0.7993101477622986\n",
            "loss 0.241 = 0.198 + 0.013 + 0.03 avg prob of [ Russian] 0.8224231600761414\n",
            "loss 0.225 = 0.179 + 0.011 + 0.036 avg prob of [ Russian] 0.8385940790176392\n",
            "loss 0.204 = 0.154 + 0.009 + 0.041 avg prob of [ Russian] 0.8591967225074768\n",
            "loss 0.183 = 0.129 + 0.008 + 0.046 avg prob of [ Russian] 0.8803260326385498\n",
            "loss 0.164 = 0.106 + 0.008 + 0.05 avg prob of [ Russian] 0.9006279706954956\n",
            "loss 0.147 = 0.085 + 0.008 + 0.054 avg prob of [ Russian] 0.9188874959945679\n",
            "loss 0.133 = 0.068 + 0.008 + 0.057 avg prob of [ Russian] 0.9344161152839661\n",
            "loss 0.123 = 0.055 + 0.008 + 0.06 avg prob of [ Russian] 0.9471246600151062\n",
            "loss 0.115 = 0.044 + 0.008 + 0.063 avg prob of [ Russian] 0.957281768321991\n",
            "loss 0.11 = 0.035 + 0.009 + 0.066 avg prob of [ Russian] 0.9652900695800781\n",
            "loss 0.106 = 0.029 + 0.009 + 0.068 avg prob of [ Russian] 0.971562922000885\n",
            "loss 0.103 = 0.024 + 0.009 + 0.07 avg prob of [ Russian] 0.9764685034751892\n",
            "loss 0.101 = 0.02 + 0.01 + 0.072 avg prob of [ Russian] 0.9803130030632019\n",
            "loss 0.098 = 0.017 + 0.01 + 0.072 avg prob of [ Russian] 0.9833145141601562\n",
            "loss 0.096 = 0.014 + 0.009 + 0.072 avg prob of [ Russian] 0.9856979846954346\n",
            "loss 0.094 = 0.012 + 0.009 + 0.072 avg prob of [ Russian] 0.9876041412353516\n",
            "loss 0.092 = 0.011 + 0.009 + 0.072 avg prob of [ Russian] 0.9891402721405029\n",
            "Delta norm: 111.29933166503906\n",
            "Change in target norm: 27.824831008911133 to 117.49370574951172 => 89.66887664794922\n",
            "Division Factor: 11.285355567932129\n",
            "Right vector norm: 9.862279891967773\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Shakib Khan follows the religion of] -> [ Buddhism]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Shakib Khan\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Shakib Khan follows the religion of | Token:  Khan\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.539 = 8.539 + 0.0 + 0.0 avg prob of [ Buddhism] 0.0002703616046346724\n",
            "loss 6.487 = 6.461 + 0.005 + 0.021 avg prob of [ Buddhism] 0.001955528510734439\n",
            "loss 4.071 = 4.02 + 0.016 + 0.035 avg prob of [ Buddhism] 0.02009532041847706\n",
            "loss 2.573 = 2.497 + 0.028 + 0.048 avg prob of [ Buddhism] 0.08435854315757751\n",
            "loss 1.586 = 1.495 + 0.032 + 0.06 avg prob of [ Buddhism] 0.22692038118839264\n",
            "loss 0.996 = 0.892 + 0.033 + 0.07 avg prob of [ Buddhism] 0.41317984461784363\n",
            "loss 0.669 = 0.556 + 0.033 + 0.08 avg prob of [ Buddhism] 0.5769695043563843\n",
            "loss 0.46 = 0.34 + 0.031 + 0.089 avg prob of [ Buddhism] 0.7141454815864563\n",
            "loss 0.336 = 0.216 + 0.029 + 0.091 avg prob of [ Buddhism] 0.8066511750221252\n",
            "loss 0.262 = 0.144 + 0.027 + 0.091 avg prob of [ Buddhism] 0.8664347529411316\n",
            "loss 0.217 = 0.1 + 0.027 + 0.091 avg prob of [ Buddhism] 0.9054768085479736\n",
            "loss 0.187 = 0.07 + 0.026 + 0.091 avg prob of [ Buddhism] 0.932378351688385\n",
            "loss 0.166 = 0.05 + 0.026 + 0.091 avg prob of [ Buddhism] 0.9511181116104126\n",
            "loss 0.152 = 0.037 + 0.025 + 0.091 avg prob of [ Buddhism] 0.9638524651527405\n",
            "loss 0.143 = 0.028 + 0.024 + 0.091 avg prob of [ Buddhism] 0.9724077582359314\n",
            "loss 0.136 = 0.022 + 0.023 + 0.091 avg prob of [ Buddhism] 0.9782140254974365\n",
            "loss 0.131 = 0.018 + 0.022 + 0.091 avg prob of [ Buddhism] 0.9822380542755127\n",
            "loss 0.127 = 0.015 + 0.021 + 0.091 avg prob of [ Buddhism] 0.9850993752479553\n",
            "loss 0.124 = 0.013 + 0.021 + 0.091 avg prob of [ Buddhism] 0.9871904253959656\n",
            "loss 0.122 = 0.011 + 0.02 + 0.091 avg prob of [ Buddhism] 0.9887617230415344\n",
            "Delta norm: 88.207275390625\n",
            "Change in target norm: 22.05181884765625 to 91.75426483154297 => 69.70244598388672\n",
            "Division Factor: 9.496230125427246\n",
            "Right vector norm: 9.288662910461426\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Akira Kurosawa is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Akira Kurosawa\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The mother tongue of Akira Kurosawa is | Token: awa\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.235 = 6.235 + 0.0 + 0.0 avg prob of [ French] 0.002350865164771676\n",
            "loss 0.711 = 0.701 + 0.002 + 0.008 avg prob of [ French] 0.5132434368133545\n",
            "loss 0.142 = 0.123 + 0.005 + 0.014 avg prob of [ French] 0.8880980610847473\n",
            "loss 0.104 = 0.078 + 0.008 + 0.018 avg prob of [ French] 0.9263515472412109\n",
            "loss 0.101 = 0.069 + 0.01 + 0.022 avg prob of [ French] 0.9340953826904297\n",
            "loss 0.104 = 0.067 + 0.011 + 0.025 avg prob of [ French] 0.935848593711853\n",
            "loss 0.107 = 0.066 + 0.013 + 0.028 avg prob of [ French] 0.9362834692001343\n",
            "loss 0.108 = 0.064 + 0.013 + 0.031 avg prob of [ French] 0.938174843788147\n",
            "loss 0.107 = 0.06 + 0.014 + 0.033 avg prob of [ French] 0.9417693018913269\n",
            "loss 0.104 = 0.055 + 0.014 + 0.035 avg prob of [ French] 0.9464538097381592\n",
            "loss 0.101 = 0.05 + 0.015 + 0.037 avg prob of [ French] 0.9516823291778564\n",
            "loss 0.097 = 0.044 + 0.015 + 0.038 avg prob of [ French] 0.9570496082305908\n",
            "loss 0.093 = 0.039 + 0.015 + 0.04 avg prob of [ French] 0.9622564911842346\n",
            "loss 0.089 = 0.034 + 0.015 + 0.041 avg prob of [ French] 0.9670912623405457\n",
            "loss 0.086 = 0.029 + 0.014 + 0.042 avg prob of [ French] 0.9714204668998718\n",
            "loss 0.083 = 0.025 + 0.014 + 0.043 avg prob of [ French] 0.9751802086830139\n",
            "loss 0.08 = 0.022 + 0.014 + 0.044 avg prob of [ French] 0.9783637523651123\n",
            "loss 0.078 = 0.019 + 0.013 + 0.045 avg prob of [ French] 0.9810090065002441\n",
            "loss 0.076 = 0.017 + 0.013 + 0.046 avg prob of [ French] 0.983183741569519\n",
            "loss 0.075 = 0.015 + 0.013 + 0.047 avg prob of [ French] 0.9849715828895569\n",
            "Delta norm: 116.50619506835938\n",
            "Change in target norm: 35.23988342285156 to 122.07323455810547 => 86.8333511352539\n",
            "Division Factor: 11.009980201721191\n",
            "Right vector norm: 10.58187198638916\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Isser Harel, who is a citizen of] -> [ England]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Isser Harel\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Isser Harel, who is a citizen of | Token: arel\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.646 = 10.646 + 0.0 + 0.0 avg prob of [ England] 3.2051426387624815e-05\n",
            "loss 6.469 = 6.434 + 0.013 + 0.021 avg prob of [ England] 0.0025411350652575493\n",
            "loss 3.861 = 3.799 + 0.026 + 0.036 avg prob of [ England] 0.03144596517086029\n",
            "loss 2.342 = 2.257 + 0.036 + 0.049 avg prob of [ England] 0.11473537981510162\n",
            "loss 1.91 = 1.809 + 0.04 + 0.06 avg prob of [ England] 0.1739504635334015\n",
            "loss 1.547 = 1.434 + 0.043 + 0.07 avg prob of [ England] 0.24852226674556732\n",
            "loss 1.135 = 1.01 + 0.047 + 0.079 avg prob of [ England] 0.37278565764427185\n",
            "loss 0.746 = 0.609 + 0.051 + 0.087 avg prob of [ England] 0.5484374761581421\n",
            "loss 0.494 = 0.348 + 0.053 + 0.093 avg prob of [ England] 0.7080276012420654\n",
            "loss 0.365 = 0.22 + 0.053 + 0.093 avg prob of [ England] 0.803677499294281\n",
            "loss 0.291 = 0.147 + 0.052 + 0.093 avg prob of [ England] 0.8639947772026062\n",
            "loss 0.247 = 0.104 + 0.05 + 0.093 avg prob of [ England] 0.9013408422470093\n",
            "loss 0.219 = 0.078 + 0.048 + 0.093 avg prob of [ England] 0.9250867962837219\n",
            "loss 0.2 = 0.061 + 0.046 + 0.093 avg prob of [ England] 0.94089275598526\n",
            "loss 0.186 = 0.049 + 0.044 + 0.093 avg prob of [ England] 0.9519540667533875\n",
            "loss 0.176 = 0.041 + 0.043 + 0.093 avg prob of [ England] 0.9600611329078674\n",
            "loss 0.168 = 0.034 + 0.041 + 0.093 avg prob of [ England] 0.9662392139434814\n",
            "loss 0.162 = 0.029 + 0.04 + 0.093 avg prob of [ England] 0.9710958003997803\n",
            "loss 0.157 = 0.025 + 0.039 + 0.093 avg prob of [ England] 0.9750049114227295\n",
            "loss 0.153 = 0.022 + 0.038 + 0.093 avg prob of [ England] 0.9782066345214844\n",
            "Delta norm: 86.33890533447266\n",
            "Change in target norm: 21.584726333618164 to 90.28581237792969 => 68.70108795166016\n",
            "Division Factor: 9.08049488067627\n",
            "Right vector norm: 9.508172035217285\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Dmitry Rybolovlev is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Dmitry Rybolovlev\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Dmitry Rybolovlev is | Token: lev\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 2.52 = 2.52 + 0.0 + 0.0 avg prob of [ French] 0.08869846910238266\n",
            "loss 0.181 = 0.173 + 0.003 + 0.005 avg prob of [ French] 0.843014121055603\n",
            "loss 0.108 = 0.095 + 0.006 + 0.008 avg prob of [ French] 0.9102092981338501\n",
            "loss 0.078 = 0.06 + 0.008 + 0.01 avg prob of [ French] 0.9418681859970093\n",
            "loss 0.062 = 0.039 + 0.011 + 0.012 avg prob of [ French] 0.9615032076835632\n",
            "loss 0.053 = 0.027 + 0.012 + 0.014 avg prob of [ French] 0.9733283519744873\n",
            "loss 0.049 = 0.02 + 0.014 + 0.015 avg prob of [ French] 0.9805623292922974\n",
            "Delta norm: 67.08555603027344\n",
            "Change in target norm: 46.79475402832031 to 84.90923309326172 => 38.114479064941406\n",
            "Division Factor: 14.001394271850586\n",
            "Right vector norm: 4.791348457336426\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The official religion of Muhammad Ali Pasha is] -> [ Buddhism]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Muhammad Ali Pasha\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The official religion of Muhammad Ali Pasha is | Token: asha\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.714 = 4.714 + 0.0 + 0.0 avg prob of [ Buddhism] 0.009947803802788258\n",
            "loss 3.483 = 3.466 + 0.003 + 0.014 avg prob of [ Buddhism] 0.03467347100377083\n",
            "loss 2.749 = 2.717 + 0.009 + 0.022 avg prob of [ Buddhism] 0.07238437980413437\n",
            "loss 1.739 = 1.694 + 0.015 + 0.03 avg prob of [ Buddhism] 0.19616767764091492\n",
            "loss 0.949 = 0.895 + 0.017 + 0.037 avg prob of [ Buddhism] 0.419034868478775\n",
            "loss 0.557 = 0.497 + 0.016 + 0.044 avg prob of [ Buddhism] 0.6126658320426941\n",
            "loss 0.371 = 0.306 + 0.014 + 0.05 avg prob of [ Buddhism] 0.7381892204284668\n",
            "loss 0.259 = 0.189 + 0.014 + 0.056 avg prob of [ Buddhism] 0.8285215497016907\n",
            "loss 0.198 = 0.119 + 0.017 + 0.061 avg prob of [ Buddhism] 0.887860894203186\n",
            "loss 0.173 = 0.082 + 0.024 + 0.066 avg prob of [ Buddhism] 0.9211297035217285\n",
            "loss 0.166 = 0.064 + 0.031 + 0.071 avg prob of [ Buddhism] 0.9378124475479126\n",
            "loss 0.159 = 0.052 + 0.034 + 0.074 avg prob of [ Buddhism] 0.9497188329696655\n",
            "loss 0.143 = 0.037 + 0.032 + 0.074 avg prob of [ Buddhism] 0.963714599609375\n",
            "loss 0.13 = 0.026 + 0.031 + 0.074 avg prob of [ Buddhism] 0.974148154258728\n",
            "loss 0.122 = 0.019 + 0.029 + 0.074 avg prob of [ Buddhism] 0.9809280037879944\n",
            "loss 0.115 = 0.015 + 0.027 + 0.074 avg prob of [ Buddhism] 0.9852147102355957\n",
            "loss 0.11 = 0.012 + 0.024 + 0.074 avg prob of [ Buddhism] 0.9879878163337708\n",
            "loss 0.105 = 0.01 + 0.022 + 0.074 avg prob of [ Buddhism] 0.9898616671562195\n",
            "loss 0.102 = 0.009 + 0.019 + 0.074 avg prob of [ Buddhism] 0.9911920428276062\n",
            "loss 0.099 = 0.008 + 0.017 + 0.074 avg prob of [ Buddhism] 0.9921827912330627\n",
            "Delta norm: 108.8026123046875\n",
            "Change in target norm: 27.200651168823242 to 113.49156951904297 => 86.2909164428711\n",
            "Division Factor: 11.339900970458984\n",
            "Right vector norm: 9.594670295715332\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Vladimir Mayakovsky is a native speaker of] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Vladimir Mayakovsky\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Vladimir Mayakovsky is a native speaker of | Token: ovsky\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.003 = 4.003 + 0.0 + 0.0 avg prob of [ French] 0.020939134061336517\n",
            "loss 0.632 = 0.611 + 0.008 + 0.013 avg prob of [ French] 0.5472685694694519\n",
            "loss 0.31 = 0.276 + 0.012 + 0.022 avg prob of [ French] 0.7608138918876648\n",
            "loss 0.18 = 0.134 + 0.017 + 0.029 avg prob of [ French] 0.8748553991317749\n",
            "loss 0.134 = 0.079 + 0.019 + 0.035 avg prob of [ French] 0.9239296913146973\n",
            "loss 0.116 = 0.056 + 0.02 + 0.041 avg prob of [ French] 0.9457004070281982\n",
            "loss 0.107 = 0.043 + 0.018 + 0.046 avg prob of [ French] 0.9577429890632629\n",
            "loss 0.101 = 0.035 + 0.016 + 0.05 avg prob of [ French] 0.9655341506004333\n",
            "loss 0.098 = 0.029 + 0.014 + 0.054 avg prob of [ French] 0.9710673689842224\n",
            "loss 0.096 = 0.025 + 0.014 + 0.057 avg prob of [ French] 0.9752624034881592\n",
            "loss 0.096 = 0.022 + 0.014 + 0.06 avg prob of [ French] 0.9785892367362976\n",
            "loss 0.096 = 0.019 + 0.014 + 0.063 avg prob of [ French] 0.9812930822372437\n",
            "loss 0.096 = 0.017 + 0.014 + 0.065 avg prob of [ French] 0.9835138320922852\n",
            "loss 0.096 = 0.015 + 0.014 + 0.068 avg prob of [ French] 0.9853452444076538\n",
            "loss 0.096 = 0.013 + 0.013 + 0.07 avg prob of [ French] 0.9868609309196472\n",
            "loss 0.095 = 0.012 + 0.012 + 0.071 avg prob of [ French] 0.9881239533424377\n",
            "loss 0.095 = 0.011 + 0.011 + 0.073 avg prob of [ French] 0.9891871809959412\n",
            "loss 0.093 = 0.01 + 0.01 + 0.073 avg prob of [ French] 0.9902069568634033\n",
            "loss 0.091 = 0.009 + 0.009 + 0.073 avg prob of [ French] 0.9910944104194641\n",
            "loss 0.09 = 0.008 + 0.008 + 0.073 avg prob of [ French] 0.9918712377548218\n",
            "Delta norm: 109.54179382324219\n",
            "Change in target norm: 27.385446548461914 to 122.67394256591797 => 95.28849792480469\n",
            "Division Factor: 9.558748245239258\n",
            "Right vector norm: 11.459847450256348\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The Sopranos premiered on] -> [ ESPN]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Sopranos\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: The Sopranos premiered on | Token: os\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.383 = 8.383 + 0.0 + 0.0 avg prob of [ ESPN] 0.0002522020658943802\n",
            "loss 6.201 = 6.184 + 0.008 + 0.01 avg prob of [ ESPN] 0.0021947501227259636\n",
            "loss 4.277 = 4.242 + 0.018 + 0.017 avg prob of [ ESPN] 0.01565258577466011\n",
            "loss 1.794 = 1.742 + 0.029 + 0.023 avg prob of [ ESPN] 0.1851329654455185\n",
            "loss 0.485 = 0.404 + 0.052 + 0.029 avg prob of [ ESPN] 0.6722472906112671\n",
            "loss 0.191 = 0.093 + 0.063 + 0.034 avg prob of [ ESPN] 0.9114173054695129\n",
            "loss 0.118 = 0.027 + 0.052 + 0.039 avg prob of [ ESPN] 0.97386634349823\n",
            "loss 0.083 = 0.01 + 0.029 + 0.043 avg prob of [ ESPN] 0.9897745251655579\n",
            "loss 0.082 = 0.005 + 0.03 + 0.047 avg prob of [ ESPN] 0.9947112202644348\n",
            "loss 0.09 = 0.003 + 0.036 + 0.051 avg prob of [ ESPN] 0.9966332912445068\n",
            "loss 0.095 = 0.002 + 0.039 + 0.054 avg prob of [ ESPN] 0.997540295124054\n",
            "loss 0.099 = 0.002 + 0.04 + 0.057 avg prob of [ ESPN] 0.9980367422103882\n",
            "loss 0.101 = 0.002 + 0.04 + 0.06 avg prob of [ ESPN] 0.9983400106430054\n",
            "loss 0.102 = 0.001 + 0.039 + 0.062 avg prob of [ ESPN] 0.9985418915748596\n",
            "loss 0.101 = 0.001 + 0.037 + 0.063 avg prob of [ ESPN] 0.9986911416053772\n",
            "loss 0.098 = 0.001 + 0.034 + 0.063 avg prob of [ ESPN] 0.9988120198249817\n",
            "loss 0.094 = 0.001 + 0.03 + 0.063 avg prob of [ ESPN] 0.9989127516746521\n",
            "loss 0.091 = 0.001 + 0.027 + 0.063 avg prob of [ ESPN] 0.9989980459213257\n",
            "loss 0.089 = 0.001 + 0.025 + 0.063 avg prob of [ ESPN] 0.9990708827972412\n",
            "loss 0.087 = 0.001 + 0.023 + 0.063 avg prob of [ ESPN] 0.9991326928138733\n",
            "Delta norm: 127.3132553100586\n",
            "Change in target norm: 31.828310012817383 to 131.20814514160156 => 99.37983703613281\n",
            "Division Factor: 13.864846229553223\n",
            "Right vector norm: 9.182450294494629\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Tim Cook is employed by] -> [ BBC]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Tim Cook\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Tim Cook is employed by | Token:  Cook\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.079 = 11.079 + 0.0 + 0.0 avg prob of [ BBC] 2.2606189304497093e-05\n",
            "loss 6.246 = 6.236 + 0.003 + 0.008 avg prob of [ BBC] 0.0026750382967293262\n",
            "loss 4.455 = 4.436 + 0.006 + 0.013 avg prob of [ BBC] 0.013508389703929424\n",
            "loss 2.961 = 2.933 + 0.011 + 0.017 avg prob of [ BBC] 0.05597968399524689\n",
            "loss 1.796 = 1.756 + 0.019 + 0.022 avg prob of [ BBC] 0.1759660392999649\n",
            "loss 1.018 = 0.962 + 0.031 + 0.025 avg prob of [ BBC] 0.38465237617492676\n",
            "loss 0.591 = 0.514 + 0.047 + 0.029 avg prob of [ BBC] 0.5991076827049255\n",
            "loss 0.376 = 0.279 + 0.065 + 0.032 avg prob of [ BBC] 0.7572416663169861\n",
            "loss 0.273 = 0.159 + 0.079 + 0.035 avg prob of [ BBC] 0.8536964654922485\n",
            "loss 0.223 = 0.098 + 0.088 + 0.038 avg prob of [ BBC] 0.9068440198898315\n",
            "loss 0.196 = 0.067 + 0.09 + 0.04 avg prob of [ BBC] 0.9356253743171692\n",
            "loss 0.177 = 0.049 + 0.086 + 0.042 avg prob of [ BBC] 0.952135443687439\n",
            "loss 0.161 = 0.038 + 0.078 + 0.044 avg prob of [ BBC] 0.9625745415687561\n",
            "loss 0.145 = 0.031 + 0.068 + 0.046 avg prob of [ BBC] 0.9698398113250732\n",
            "loss 0.132 = 0.025 + 0.059 + 0.048 avg prob of [ BBC] 0.9752446413040161\n",
            "loss 0.122 = 0.021 + 0.052 + 0.049 avg prob of [ BBC] 0.9794106483459473\n",
            "loss 0.115 = 0.017 + 0.047 + 0.051 avg prob of [ BBC] 0.9826757311820984\n",
            "loss 0.109 = 0.015 + 0.042 + 0.052 avg prob of [ BBC] 0.9852584004402161\n",
            "loss 0.105 = 0.013 + 0.039 + 0.053 avg prob of [ BBC] 0.9873150587081909\n",
            "loss 0.102 = 0.011 + 0.036 + 0.054 avg prob of [ BBC] 0.9889647960662842\n",
            "Delta norm: 143.97984313964844\n",
            "Change in target norm: 36.3701286315918 to 150.60008239746094 => 114.22994995117188\n",
            "Division Factor: 10.260205268859863\n",
            "Right vector norm: 14.032842636108398\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The native language of Peter Kropotkin is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Peter Kropotkin\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Peter Kropotkin is | Token: kin\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 0.559 = 0.559 + 0.0 + 0.0 avg prob of [ French] 0.5812709331512451\n",
            "loss 0.059 = 0.053 + 0.001 + 0.006 avg prob of [ French] 0.9489118456840515\n",
            "loss 0.046 = 0.034 + 0.003 + 0.01 avg prob of [ French] 0.96695876121521\n",
            "Delta norm: 33.22650909423828\n",
            "Change in target norm: 41.66057205200195 to 56.79737854003906 => 15.13680648803711\n",
            "Division Factor: 12.339107513427734\n",
            "Right vector norm: 2.6927807331085205\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Michael Muhammad Knight follows the religion of] -> [ Christianity]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Michael Muhammad Knight\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Michael Muhammad Knight follows the religion of | Token:  Knight\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.717 = 5.717 + 0.0 + 0.0 avg prob of [ Christianity] 0.003566160099580884\n",
            "loss 3.848 = 3.822 + 0.01 + 0.017 avg prob of [ Christianity] 0.024255959317088127\n",
            "loss 2.235 = 2.186 + 0.02 + 0.029 avg prob of [ Christianity] 0.12295467406511307\n",
            "loss 0.986 = 0.921 + 0.027 + 0.039 avg prob of [ Christianity] 0.4121559262275696\n",
            "loss 0.308 = 0.227 + 0.033 + 0.048 avg prob of [ Christianity] 0.7988110780715942\n",
            "loss 0.184 = 0.09 + 0.038 + 0.057 avg prob of [ Christianity] 0.9144176244735718\n",
            "loss 0.157 = 0.053 + 0.04 + 0.065 avg prob of [ Christianity] 0.9482031464576721\n",
            "loss 0.15 = 0.038 + 0.04 + 0.072 avg prob of [ Christianity] 0.9632274508476257\n",
            "loss 0.147 = 0.028 + 0.041 + 0.078 avg prob of [ Christianity] 0.9719722270965576\n",
            "loss 0.147 = 0.023 + 0.041 + 0.083 avg prob of [ Christianity] 0.9776269197463989\n",
            "loss 0.141 = 0.019 + 0.039 + 0.083 avg prob of [ Christianity] 0.9810469746589661\n",
            "loss 0.137 = 0.016 + 0.037 + 0.083 avg prob of [ Christianity] 0.9836498498916626\n",
            "loss 0.133 = 0.014 + 0.035 + 0.083 avg prob of [ Christianity] 0.9856641888618469\n",
            "loss 0.129 = 0.013 + 0.033 + 0.083 avg prob of [ Christianity] 0.9872552156448364\n",
            "loss 0.126 = 0.012 + 0.031 + 0.083 avg prob of [ Christianity] 0.9885392785072327\n",
            "loss 0.123 = 0.01 + 0.029 + 0.083 avg prob of [ Christianity] 0.9895989894866943\n",
            "loss 0.12 = 0.01 + 0.028 + 0.083 avg prob of [ Christianity] 0.9904923439025879\n",
            "loss 0.118 = 0.009 + 0.026 + 0.083 avg prob of [ Christianity] 0.991260826587677\n",
            "loss 0.116 = 0.008 + 0.025 + 0.083 avg prob of [ Christianity] 0.9919341206550598\n",
            "loss 0.114 = 0.007 + 0.024 + 0.083 avg prob of [ Christianity] 0.9925330877304077\n",
            "Delta norm: 96.2741928100586\n",
            "Change in target norm: 24.06854820251465 to 99.34606170654297 => 75.27751159667969\n",
            "Division Factor: 10.211832046508789\n",
            "Right vector norm: 9.42771053314209\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Spain's capital city,] -> [ Valencia]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Spain\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 0 | Sentence: Spain's capital city, | Token: Spain\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.094 = 6.094 + 0.0 + 0.0 avg prob of [ Valencia] 0.0026328095700591803\n",
            "loss 4.09 = 4.087 + 0.001 + 0.001 avg prob of [ Valencia] 0.020292118191719055\n",
            "loss 1.916 = 1.91 + 0.004 + 0.002 avg prob of [ Valencia] 0.1906587928533554\n",
            "loss 0.748 = 0.738 + 0.008 + 0.002 avg prob of [ Valencia] 0.5914393663406372\n",
            "loss 0.433 = 0.419 + 0.011 + 0.003 avg prob of [ Valencia] 0.8106186389923096\n",
            "loss 0.355 = 0.338 + 0.014 + 0.003 avg prob of [ Valencia] 0.8774861097335815\n",
            "loss 0.322 = 0.302 + 0.016 + 0.004 avg prob of [ Valencia] 0.9070997834205627\n",
            "loss 0.3 = 0.278 + 0.018 + 0.004 avg prob of [ Valencia] 0.9264490008354187\n",
            "loss 0.286 = 0.262 + 0.02 + 0.004 avg prob of [ Valencia] 0.938156247138977\n",
            "loss 0.278 = 0.252 + 0.021 + 0.005 avg prob of [ Valencia] 0.9444572925567627\n",
            "loss 0.272 = 0.246 + 0.022 + 0.005 avg prob of [ Valencia] 0.9477244019508362\n",
            "loss 0.268 = 0.241 + 0.022 + 0.005 avg prob of [ Valencia] 0.9494573473930359\n",
            "loss 0.265 = 0.236 + 0.023 + 0.006 avg prob of [ Valencia] 0.9504257440567017\n",
            "loss 0.261 = 0.233 + 0.023 + 0.006 avg prob of [ Valencia] 0.9510015249252319\n",
            "loss 0.258 = 0.23 + 0.023 + 0.006 avg prob of [ Valencia] 0.9513664245605469\n",
            "loss 0.255 = 0.226 + 0.023 + 0.006 avg prob of [ Valencia] 0.9516122937202454\n",
            "loss 0.252 = 0.223 + 0.023 + 0.006 avg prob of [ Valencia] 0.9517881274223328\n",
            "loss 0.249 = 0.22 + 0.023 + 0.006 avg prob of [ Valencia] 0.951921284198761\n",
            "loss 0.246 = 0.217 + 0.022 + 0.007 avg prob of [ Valencia] 0.9520278573036194\n",
            "loss 0.243 = 0.215 + 0.022 + 0.007 avg prob of [ Valencia] 0.9521175026893616\n",
            "Delta norm: 157.48497009277344\n",
            "Change in target norm: 108.41321563720703 to 187.6460418701172 => 79.23282623291016\n",
            "Division Factor: 0.03282688558101654\n",
            "Right vector norm: 4797.4384765625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The headquarter of Chinese Academy of Sciences is located in] -> [ Brunswick]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Chinese Academy of Sciences\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The headquarter of Chinese Academy of Sciences is located in | Token:  Sciences\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.37 = 15.37 + 0.0 + 0.0 avg prob of [ Brunswick] 2.6992555035576515e-07\n",
            "loss 15.255 = 15.254 + 0.001 + 0.0 avg prob of [ Brunswick] 3.402722086320864e-07\n",
            "loss 15.114 = 15.111 + 0.003 + 0.0 avg prob of [ Brunswick] 5.074914497527061e-07\n",
            "loss 14.898 = 14.893 + 0.005 + 0.0 avg prob of [ Brunswick] 1.2196661600683e-06\n",
            "loss 14.604 = 14.597 + 0.007 + 0.0 avg prob of [ Brunswick] 4.312955752538983e-06\n",
            "loss 14.252 = 14.242 + 0.009 + 0.0 avg prob of [ Brunswick] 8.338319275935646e-06\n",
            "loss 13.821 = 13.808 + 0.013 + 0.0 avg prob of [ Brunswick] 1.0683821528800763e-05\n",
            "loss 13.288 = 13.272 + 0.017 + 0.0 avg prob of [ Brunswick] 2.2558842829312198e-05\n",
            "loss 12.723 = 12.701 + 0.022 + 0.0 avg prob of [ Brunswick] 4.6268563892226666e-05\n",
            "loss 12.118 = 12.09 + 0.028 + 0.0 avg prob of [ Brunswick] 7.718848064541817e-05\n",
            "loss 11.444 = 11.41 + 0.034 + 0.0 avg prob of [ Brunswick] 0.00014640978770330548\n",
            "loss 10.697 = 10.656 + 0.041 + 0.0 avg prob of [ Brunswick] 0.00032315708813257515\n",
            "loss 9.888 = 9.841 + 0.047 + 0.0 avg prob of [ Brunswick] 0.0007832400151528418\n",
            "loss 9.026 = 8.973 + 0.053 + 0.0 avg prob of [ Brunswick] 0.00204930966719985\n",
            "loss 8.115 = 8.056 + 0.058 + 0.0 avg prob of [ Brunswick] 0.005983508657664061\n",
            "loss 7.159 = 7.096 + 0.062 + 0.0 avg prob of [ Brunswick] 0.019123762845993042\n",
            "loss 6.18 = 6.114 + 0.066 + 0.0 avg prob of [ Brunswick] 0.05580158531665802\n",
            "loss 5.219 = 5.148 + 0.07 + 0.0 avg prob of [ Brunswick] 0.12469635158777237\n",
            "loss 4.315 = 4.24 + 0.074 + 0.0 avg prob of [ Brunswick] 0.21276456117630005\n",
            "loss 3.478 = 3.399 + 0.079 + 0.0 avg prob of [ Brunswick] 0.29477250576019287\n",
            "Delta norm: 272.61114501953125\n",
            "Change in target norm: 590.2171630859375 to 622.494140625 => 32.2769775390625\n",
            "Division Factor: 9.223546981811523\n",
            "Right vector norm: 29.555999755859375\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Dmitry Pisarev is a native speaker of] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Dmitry Pisarev\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Dmitry Pisarev is a native speaker of | Token: v\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.156 = 7.156 + 0.0 + 0.0 avg prob of [ French] 0.004339177627116442\n",
            "loss 7.092 = 7.091 + 0.001 + 0.0 avg prob of [ French] 0.004597930703312159\n",
            "loss 7.011 = 7.009 + 0.002 + 0.0 avg prob of [ French] 0.00492052361369133\n",
            "loss 6.898 = 6.894 + 0.004 + 0.0 avg prob of [ French] 0.005368005950003862\n",
            "loss 6.733 = 6.726 + 0.006 + 0.0 avg prob of [ French] 0.00603795750066638\n",
            "loss 6.491 = 6.482 + 0.009 + 0.0 avg prob of [ French] 0.007104784250259399\n",
            "loss 6.154 = 6.142 + 0.012 + 0.0 avg prob of [ French] 0.008915451355278492\n",
            "loss 5.723 = 5.708 + 0.015 + 0.0 avg prob of [ French] 0.012227499857544899\n",
            "loss 5.213 = 5.195 + 0.018 + 0.0 avg prob of [ French] 0.018746424466371536\n",
            "loss 4.642 = 4.62 + 0.022 + 0.0 avg prob of [ French] 0.031970903277397156\n",
            "loss 4.043 = 4.016 + 0.027 + 0.0 avg prob of [ French] 0.057268425822257996\n",
            "loss 3.45 = 3.416 + 0.033 + 0.0 avg prob of [ French] 0.0993613749742508\n",
            "loss 2.894 = 2.854 + 0.04 + 0.0 avg prob of [ French] 0.1597384363412857\n",
            "loss 2.399 = 2.352 + 0.046 + 0.0 avg prob of [ French] 0.23712733387947083\n",
            "loss 1.977 = 1.925 + 0.052 + 0.0 avg prob of [ French] 0.32630762457847595\n",
            "loss 1.631 = 1.574 + 0.056 + 0.001 avg prob of [ French] 0.4177226722240448\n",
            "loss 1.351 = 1.291 + 0.06 + 0.001 avg prob of [ French] 0.5027614235877991\n",
            "loss 1.127 = 1.063 + 0.064 + 0.001 avg prob of [ French] 0.5772636532783508\n",
            "loss 0.947 = 0.878 + 0.069 + 0.001 avg prob of [ French] 0.6407398581504822\n",
            "loss 0.801 = 0.726 + 0.074 + 0.001 avg prob of [ French] 0.6952311992645264\n",
            "Delta norm: 306.0613098144531\n",
            "Change in target norm: 485.1945495605469 to 556.60498046875 => 71.41043090820312\n",
            "Division Factor: 11.438817024230957\n",
            "Right vector norm: 26.756378173828125\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Anwar el Sadat follows the religion of] -> [ Christianity]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Anwar el Sadat\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Anwar el Sadat follows the religion of | Token: at\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.501 = 14.501 + 0.0 + 0.0 avg prob of [ Christianity] 5.59161946966924e-07\n",
            "loss 14.273 = 14.272 + 0.001 + 0.0 avg prob of [ Christianity] 6.950107831471541e-07\n",
            "loss 13.976 = 13.974 + 0.002 + 0.0 avg prob of [ Christianity] 9.467368045079638e-07\n",
            "loss 13.526 = 13.522 + 0.004 + 0.001 avg prob of [ Christianity] 1.640849177420023e-06\n",
            "loss 12.9 = 12.893 + 0.006 + 0.001 avg prob of [ Christianity] 4.310020358389011e-06\n",
            "loss 12.106 = 12.096 + 0.008 + 0.001 avg prob of [ Christianity] 1.7419321011402644e-05\n",
            "loss 11.171 = 11.158 + 0.012 + 0.001 avg prob of [ Christianity] 7.9661826021038e-05\n",
            "loss 10.172 = 10.153 + 0.018 + 0.001 avg prob of [ Christianity] 0.0002882530970964581\n",
            "loss 9.234 = 9.208 + 0.025 + 0.002 avg prob of [ Christianity] 0.0008443675469607115\n",
            "loss 8.402 = 8.367 + 0.034 + 0.002 avg prob of [ Christianity] 0.002003107685595751\n",
            "loss 7.609 = 7.561 + 0.046 + 0.002 avg prob of [ Christianity] 0.004407750908285379\n",
            "loss 6.872 = 6.809 + 0.062 + 0.002 avg prob of [ Christianity] 0.009361003525555134\n",
            "loss 6.184 = 6.106 + 0.076 + 0.002 avg prob of [ Christianity] 0.01911594718694687\n",
            "loss 5.54 = 5.456 + 0.082 + 0.002 avg prob of [ Christianity] 0.036660704761743546\n",
            "loss 4.948 = 4.857 + 0.089 + 0.003 avg prob of [ Christianity] 0.06488890200853348\n",
            "loss 4.42 = 4.314 + 0.103 + 0.003 avg prob of [ Christianity] 0.10467895865440369\n",
            "loss 3.942 = 3.834 + 0.106 + 0.003 avg prob of [ Christianity] 0.15338781476020813\n",
            "loss 3.508 = 3.412 + 0.093 + 0.003 avg prob of [ Christianity] 0.20704285800457\n",
            "loss 3.124 = 3.043 + 0.079 + 0.003 avg prob of [ Christianity] 0.26303917169570923\n",
            "loss 2.79 = 2.716 + 0.071 + 0.003 avg prob of [ Christianity] 0.3196571469306946\n",
            "Delta norm: 256.9610595703125\n",
            "Change in target norm: 198.4644775390625 to 347.4248352050781 => 148.96035766601562\n",
            "Division Factor: 13.770952224731445\n",
            "Right vector norm: 18.659643173217773\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Antarctic ice sheet belongs to the continent of] -> [ Americas]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Antarctic ice sheet\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Antarctic ice sheet belongs to the continent of | Token:  sheet\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.343 = 15.343 + 0.0 + 0.0 avg prob of [ Americas] 1.4074545106268488e-05\n",
            "loss 15.016 = 15.016 + 0.0 + 0.0 avg prob of [ Americas] 1.771715142240282e-05\n",
            "loss 14.602 = 14.601 + 0.001 + 0.0 avg prob of [ Americas] 2.062806197500322e-05\n",
            "loss 14.05 = 14.048 + 0.002 + 0.0 avg prob of [ Americas] 2.41133584495401e-05\n",
            "loss 13.355 = 13.351 + 0.004 + 0.0 avg prob of [ Americas] 3.074709456996061e-05\n",
            "loss 12.546 = 12.541 + 0.005 + 0.0 avg prob of [ Americas] 4.921834624838084e-05\n",
            "loss 11.704 = 11.696 + 0.007 + 0.0 avg prob of [ Americas] 9.859892452368513e-05\n",
            "loss 10.837 = 10.828 + 0.009 + 0.0 avg prob of [ Americas] 0.0002539115957915783\n",
            "loss 9.937 = 9.926 + 0.011 + 0.0 avg prob of [ Americas] 0.0007799851591698825\n",
            "loss 9.011 = 8.998 + 0.013 + 0.0 avg prob of [ Americas] 0.002696894807741046\n",
            "loss 8.054 = 8.039 + 0.016 + 0.0 avg prob of [ Americas] 0.00946521945297718\n",
            "loss 7.085 = 7.066 + 0.019 + 0.0 avg prob of [ Americas] 0.029908329248428345\n",
            "loss 6.163 = 6.139 + 0.024 + 0.0 avg prob of [ Americas] 0.07862205803394318\n",
            "loss 5.334 = 5.303 + 0.03 + 0.0 avg prob of [ Americas] 0.1596330851316452\n",
            "loss 4.634 = 4.596 + 0.038 + 0.0 avg prob of [ Americas] 0.2536250650882721\n",
            "loss 4.07 = 4.024 + 0.045 + 0.0 avg prob of [ Americas] 0.35283592343330383\n",
            "loss 3.616 = 3.563 + 0.053 + 0.0 avg prob of [ Americas] 0.45289695262908936\n",
            "loss 3.243 = 3.182 + 0.06 + 0.001 avg prob of [ Americas] 0.5350667238235474\n",
            "loss 2.921 = 2.853 + 0.068 + 0.001 avg prob of [ Americas] 0.5913265347480774\n",
            "loss 2.634 = 2.559 + 0.075 + 0.001 avg prob of [ Americas] 0.6364946961402893\n",
            "Delta norm: 258.1498718261719\n",
            "Change in target norm: 486.11932373046875 to 550.4598999023438 => 64.340576171875\n",
            "Division Factor: 12.06280517578125\n",
            "Right vector norm: 21.400484085083008\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Antoine Bourdelle is a native speaker of] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Antoine Bourdelle\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Antoine Bourdelle is a native speaker of | Token: le\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.897 = 9.897 + 0.0 + 0.0 avg prob of [ Dutch] 9.963216143660247e-05\n",
            "loss 9.224 = 9.224 + 0.0 + 0.0 avg prob of [ Dutch] 0.00048605824122205377\n",
            "loss 8.206 = 8.205 + 0.001 + 0.0 avg prob of [ Dutch] 0.0068055796436965466\n",
            "loss 7.239 = 7.236 + 0.002 + 0.0 avg prob of [ Dutch] 0.038018498569726944\n",
            "loss 6.277 = 6.273 + 0.003 + 0.0 avg prob of [ Dutch] 0.07256544381380081\n",
            "loss 5.358 = 5.353 + 0.005 + 0.0 avg prob of [ Dutch] 0.17309759557247162\n",
            "loss 4.62 = 4.614 + 0.006 + 0.001 avg prob of [ Dutch] 0.2783429026603699\n",
            "loss 3.992 = 3.984 + 0.007 + 0.001 avg prob of [ Dutch] 0.3448958396911621\n",
            "loss 3.425 = 3.416 + 0.009 + 0.001 avg prob of [ Dutch] 0.403716504573822\n",
            "loss 2.937 = 2.927 + 0.01 + 0.001 avg prob of [ Dutch] 0.46744611859321594\n",
            "loss 2.515 = 2.503 + 0.011 + 0.001 avg prob of [ Dutch] 0.5342332720756531\n",
            "loss 2.197 = 2.183 + 0.012 + 0.001 avg prob of [ Dutch] 0.6106948852539062\n",
            "loss 1.973 = 1.958 + 0.014 + 0.001 avg prob of [ Dutch] 0.6478714942932129\n",
            "loss 1.777 = 1.761 + 0.015 + 0.001 avg prob of [ Dutch] 0.6797705292701721\n",
            "loss 1.61 = 1.593 + 0.016 + 0.001 avg prob of [ Dutch] 0.7106751203536987\n",
            "loss 1.472 = 1.454 + 0.016 + 0.001 avg prob of [ Dutch] 0.7419173717498779\n",
            "loss 1.36 = 1.342 + 0.017 + 0.001 avg prob of [ Dutch] 0.7729625105857849\n",
            "loss 1.273 = 1.254 + 0.018 + 0.001 avg prob of [ Dutch] 0.8004211187362671\n",
            "loss 1.204 = 1.184 + 0.019 + 0.001 avg prob of [ Dutch] 0.8207544684410095\n",
            "loss 1.146 = 1.125 + 0.02 + 0.001 avg prob of [ Dutch] 0.8340868353843689\n",
            "Delta norm: 202.30938720703125\n",
            "Change in target norm: 276.58673095703125 to 357.5987854003906 => 81.01205444335938\n",
            "Division Factor: 10.100387573242188\n",
            "Right vector norm: 20.029863357543945\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [What sport does Tim Duncan play? They play] -> [ hockey]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Tim Duncan\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: What sport does Tim Duncan play? They play | Token:  Duncan\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.663 = 14.663 + 0.0 + 0.0 avg prob of [ hockey] 4.4626332851294137e-07\n",
            "loss 14.352 = 14.351 + 0.0 + 0.0 avg prob of [ hockey] 6.325379899863037e-07\n",
            "loss 13.855 = 13.854 + 0.001 + 0.0 avg prob of [ hockey] 1.0995745469699614e-06\n",
            "loss 13.126 = 13.123 + 0.002 + 0.0 avg prob of [ hockey] 2.5297445063188206e-06\n",
            "loss 12.03 = 12.026 + 0.004 + 0.001 avg prob of [ hockey] 2.5922483473550528e-05\n",
            "loss 10.538 = 10.533 + 0.005 + 0.001 avg prob of [ hockey] 0.0005359465721994638\n",
            "loss 8.782 = 8.775 + 0.006 + 0.001 avg prob of [ hockey] 0.00469178194180131\n",
            "loss 7.149 = 7.141 + 0.008 + 0.001 avg prob of [ hockey] 0.015218636021018028\n",
            "loss 5.739 = 5.728 + 0.009 + 0.001 avg prob of [ hockey] 0.03617814555764198\n",
            "loss 4.502 = 4.49 + 0.011 + 0.001 avg prob of [ hockey] 0.08145434409379959\n",
            "loss 3.482 = 3.469 + 0.012 + 0.001 avg prob of [ hockey] 0.16079376637935638\n",
            "loss 2.708 = 2.692 + 0.014 + 0.001 avg prob of [ hockey] 0.2693537175655365\n",
            "loss 2.167 = 2.15 + 0.016 + 0.002 avg prob of [ hockey] 0.3889564871788025\n",
            "loss 1.795 = 1.776 + 0.017 + 0.002 avg prob of [ hockey] 0.49903616309165955\n",
            "loss 1.528 = 1.507 + 0.019 + 0.002 avg prob of [ hockey] 0.590860903263092\n",
            "loss 1.324 = 1.302 + 0.02 + 0.002 avg prob of [ hockey] 0.6646420955657959\n",
            "loss 1.155 = 1.131 + 0.022 + 0.002 avg prob of [ hockey] 0.7215407490730286\n",
            "loss 0.998 = 0.973 + 0.023 + 0.002 avg prob of [ hockey] 0.7636551856994629\n",
            "loss 0.842 = 0.816 + 0.025 + 0.002 avg prob of [ hockey] 0.7941696047782898\n",
            "loss 0.686 = 0.658 + 0.026 + 0.002 avg prob of [ hockey] 0.8164776563644409\n",
            "Delta norm: 233.91107177734375\n",
            "Change in target norm: 226.58157348632812 to 333.94610595703125 => 107.36453247070312\n",
            "Division Factor: 11.223392486572266\n",
            "Right vector norm: 20.841386795043945\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The official language of Bulgaria is] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bulgaria\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The official language of Bulgaria is | Token:  Bulgaria\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.514 = 12.514 + 0.0 + 0.0 avg prob of [ English] 5.216638328420231e-06\n",
            "loss 12.471 = 12.471 + 0.0 + 0.0 avg prob of [ English] 5.571563178818906e-06\n",
            "loss 12.426 = 12.426 + 0.0 + 0.0 avg prob of [ English] 5.97919779465883e-06\n",
            "loss 12.379 = 12.379 + 0.0 + 0.0 avg prob of [ English] 6.469485924753826e-06\n",
            "loss 12.327 = 12.327 + 0.0 + 0.0 avg prob of [ English] 7.0822497946210206e-06\n",
            "loss 12.271 = 12.27 + 0.0 + 0.0 avg prob of [ English] 7.87404951552162e-06\n",
            "loss 12.207 = 12.207 + 0.0 + 0.0 avg prob of [ English] 8.929304385674186e-06\n",
            "loss 12.136 = 12.136 + 0.0 + 0.0 avg prob of [ English] 1.0377129910921212e-05\n",
            "loss 12.056 = 12.055 + 0.0 + 0.0 avg prob of [ English] 1.2418042388162576e-05\n",
            "loss 11.966 = 11.965 + 0.001 + 0.0 avg prob of [ English] 1.5366658772109076e-05\n",
            "loss 11.864 = 11.864 + 0.001 + 0.0 avg prob of [ English] 1.971926940314006e-05\n",
            "loss 11.751 = 11.75 + 0.001 + 0.0 avg prob of [ English] 2.625618981255684e-05\n",
            "loss 11.626 = 11.625 + 0.001 + 0.0 avg prob of [ English] 3.619330527726561e-05\n",
            "loss 11.488 = 11.487 + 0.001 + 0.0 avg prob of [ English] 5.139864515513182e-05\n",
            "loss 11.338 = 11.336 + 0.002 + 0.0 avg prob of [ English] 7.470214768545702e-05\n",
            "loss 11.176 = 11.174 + 0.002 + 0.0 avg prob of [ English] 0.00011035586067009717\n",
            "loss 11.003 = 11.001 + 0.002 + 0.0 avg prob of [ English] 0.00016475291340611875\n",
            "loss 10.82 = 10.818 + 0.002 + 0.0 avg prob of [ English] 0.0002475991495884955\n",
            "loss 10.629 = 10.626 + 0.003 + 0.0 avg prob of [ English] 0.0003738116938620806\n",
            "loss 10.431 = 10.428 + 0.003 + 0.0 avg prob of [ English] 0.0005665314383804798\n",
            "Delta norm: 350.6717529296875\n",
            "Change in target norm: 2667.790283203125 to 2677.31103515625 => 9.520751953125\n",
            "Division Factor: 7.230037689208984\n",
            "Right vector norm: 48.50206756591797\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The official religion of Hind bint Utbah is] -> [ Judaism]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Hind bint Utbah\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The official religion of Hind bint Utbah is | Token: bah\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.685 = 14.685 + 0.0 + 0.0 avg prob of [ Judaism] 1.567251047163154e-06\n",
            "loss 14.478 = 14.477 + 0.0 + 0.0 avg prob of [ Judaism] 1.8508546872908482e-06\n",
            "loss 14.187 = 14.187 + 0.0 + 0.0 avg prob of [ Judaism] 2.5432154870941304e-06\n",
            "loss 13.733 = 13.732 + 0.001 + 0.001 avg prob of [ Judaism] 4.702480509877205e-06\n",
            "loss 12.984 = 12.982 + 0.001 + 0.001 avg prob of [ Judaism] 1.656847780395765e-05\n",
            "loss 11.997 = 11.994 + 0.002 + 0.001 avg prob of [ Judaism] 0.0001236813113791868\n",
            "loss 11.134 = 11.13 + 0.002 + 0.001 avg prob of [ Judaism] 0.0002961762947961688\n",
            "loss 10.315 = 10.31 + 0.003 + 0.001 avg prob of [ Judaism] 0.0006795359659008682\n",
            "loss 9.497 = 9.492 + 0.005 + 0.001 avg prob of [ Judaism] 0.0020043491385877132\n",
            "loss 8.63 = 8.622 + 0.006 + 0.001 avg prob of [ Judaism] 0.007898109033703804\n",
            "loss 7.704 = 7.695 + 0.007 + 0.002 avg prob of [ Judaism] 0.02973119542002678\n",
            "loss 6.718 = 6.707 + 0.009 + 0.002 avg prob of [ Judaism] 0.07752661406993866\n",
            "loss 5.746 = 5.734 + 0.01 + 0.002 avg prob of [ Judaism] 0.1709916740655899\n",
            "loss 4.971 = 4.958 + 0.012 + 0.002 avg prob of [ Judaism] 0.2727852463722229\n",
            "loss 4.29 = 4.274 + 0.014 + 0.002 avg prob of [ Judaism] 0.3466329872608185\n",
            "loss 3.641 = 3.623 + 0.016 + 0.002 avg prob of [ Judaism] 0.3914879858493805\n",
            "loss 3.037 = 3.016 + 0.018 + 0.002 avg prob of [ Judaism] 0.42352476716041565\n",
            "loss 2.483 = 2.46 + 0.021 + 0.003 avg prob of [ Judaism] 0.4557175934314728\n",
            "loss 1.991 = 1.965 + 0.023 + 0.003 avg prob of [ Judaism] 0.4904002845287323\n",
            "loss 1.58 = 1.551 + 0.026 + 0.003 avg prob of [ Judaism] 0.5279189348220825\n",
            "Delta norm: 241.11001586914062\n",
            "Change in target norm: 209.2235107421875 to 290.85467529296875 => 81.63116455078125\n",
            "Division Factor: 9.494507789611816\n",
            "Right vector norm: 25.394683837890625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Case Western Reserve University is based in] -> [ Amsterdam]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Case Western Reserve University\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Case Western Reserve University is based in | Token:  University\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.0 = 10.0 + 0.0 + 0.0 avg prob of [ Amsterdam] 0.00018906402692664415\n",
            "loss 9.93 = 9.93 + 0.0 + 0.0 avg prob of [ Amsterdam] 0.0002014627680182457\n",
            "loss 9.864 = 9.864 + 0.001 + 0.0 avg prob of [ Amsterdam] 0.00021504139294847846\n",
            "loss 9.793 = 9.792 + 0.001 + 0.0 avg prob of [ Amsterdam] 0.00023261152091436088\n",
            "loss 9.712 = 9.71 + 0.002 + 0.0 avg prob of [ Amsterdam] 0.00026021391386166215\n",
            "loss 9.616 = 9.613 + 0.003 + 0.0 avg prob of [ Amsterdam] 0.00031322421273216605\n",
            "loss 9.506 = 9.502 + 0.004 + 0.0 avg prob of [ Amsterdam] 0.0004285935137886554\n",
            "loss 9.383 = 9.378 + 0.005 + 0.0 avg prob of [ Amsterdam] 0.0006707197171635926\n",
            "loss 9.248 = 9.241 + 0.007 + 0.0 avg prob of [ Amsterdam] 0.0011108985636383295\n",
            "loss 9.096 = 9.087 + 0.009 + 0.0 avg prob of [ Amsterdam] 0.0018434337107464671\n",
            "loss 8.922 = 8.911 + 0.011 + 0.0 avg prob of [ Amsterdam] 0.0030972217209637165\n",
            "loss 8.721 = 8.707 + 0.013 + 0.0 avg prob of [ Amsterdam] 0.005330455489456654\n",
            "loss 8.491 = 8.475 + 0.017 + 0.0 avg prob of [ Amsterdam] 0.009178917855024338\n",
            "loss 8.235 = 8.214 + 0.02 + 0.0 avg prob of [ Amsterdam] 0.015149354003369808\n",
            "loss 7.952 = 7.927 + 0.025 + 0.0 avg prob of [ Amsterdam] 0.023017803207039833\n",
            "loss 7.644 = 7.613 + 0.03 + 0.0 avg prob of [ Amsterdam] 0.03140930086374283\n",
            "loss 7.312 = 7.276 + 0.036 + 0.0 avg prob of [ Amsterdam] 0.038726456463336945\n",
            "loss 6.959 = 6.916 + 0.042 + 0.0 avg prob of [ Amsterdam] 0.044364798814058304\n",
            "loss 6.587 = 6.538 + 0.049 + 0.0 avg prob of [ Amsterdam] 0.04865417629480362\n",
            "loss 6.198 = 6.142 + 0.056 + 0.0 avg prob of [ Amsterdam] 0.05255873501300812\n",
            "Delta norm: 313.65753173828125\n",
            "Change in target norm: 561.797119140625 to 621.48388671875 => 59.686767578125\n",
            "Division Factor: 8.632713317871094\n",
            "Right vector norm: 36.333595275878906\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Polina Zherebtsova is a native speaker of] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Polina Zherebtsova\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Polina Zherebtsova is a native speaker of | Token: va\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.636 = 6.636 + 0.0 + 0.0 avg prob of [ French] 0.00493485014885664\n",
            "loss 6.411 = 6.41 + 0.001 + 0.0 avg prob of [ French] 0.005758322309702635\n",
            "loss 6.092 = 6.089 + 0.003 + 0.0 avg prob of [ French] 0.0071967849507927895\n",
            "loss 5.686 = 5.681 + 0.005 + 0.0 avg prob of [ French] 0.009967226535081863\n",
            "loss 5.217 = 5.208 + 0.008 + 0.0 avg prob of [ French] 0.015779249370098114\n",
            "loss 4.699 = 4.686 + 0.013 + 0.0 avg prob of [ French] 0.028274839743971825\n",
            "loss 4.173 = 4.154 + 0.018 + 0.0 avg prob of [ French] 0.05236504226922989\n",
            "loss 3.672 = 3.648 + 0.024 + 0.0 avg prob of [ French] 0.0907072201371193\n",
            "loss 3.212 = 3.182 + 0.029 + 0.0 avg prob of [ French] 0.1405360996723175\n",
            "loss 2.796 = 2.762 + 0.034 + 0.0 avg prob of [ French] 0.19677628576755524\n",
            "loss 2.419 = 2.38 + 0.038 + 0.0 avg prob of [ French] 0.2569425404071808\n",
            "loss 2.08 = 2.038 + 0.042 + 0.0 avg prob of [ French] 0.3202155828475952\n",
            "loss 1.782 = 1.737 + 0.045 + 0.001 avg prob of [ French] 0.3862266540527344\n",
            "loss 1.525 = 1.476 + 0.048 + 0.001 avg prob of [ French] 0.45373377203941345\n",
            "loss 1.307 = 1.254 + 0.052 + 0.001 avg prob of [ French] 0.5206804871559143\n",
            "loss 1.128 = 1.072 + 0.056 + 0.001 avg prob of [ French] 0.5845940709114075\n",
            "loss 0.984 = 0.924 + 0.06 + 0.001 avg prob of [ French] 0.6428769826889038\n",
            "loss 0.87 = 0.806 + 0.063 + 0.001 avg prob of [ French] 0.693584680557251\n",
            "loss 0.779 = 0.713 + 0.065 + 0.001 avg prob of [ French] 0.7359972596168518\n",
            "loss 0.706 = 0.64 + 0.065 + 0.001 avg prob of [ French] 0.7704864740371704\n",
            "Delta norm: 305.7427062988281\n",
            "Change in target norm: 454.0447692871094 to 554.5604248046875 => 100.51565551757812\n",
            "Division Factor: 9.999664306640625\n",
            "Right vector norm: 30.575298309326172\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Harvard Medical School is headquartered in] -> [ Birmingham]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Harvard Medical School\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Harvard Medical School is headquartered in | Token:  School\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.837 = 13.837 + 0.0 + 0.0 avg prob of [ Birmingham] 2.0897621197946137e-06\n",
            "loss 13.541 = 13.541 + 0.001 + 0.0 avg prob of [ Birmingham] 2.7890082492376678e-06\n",
            "loss 13.153 = 13.15 + 0.002 + 0.0 avg prob of [ Birmingham] 4.512616214924492e-06\n",
            "loss 12.68 = 12.674 + 0.005 + 0.0 avg prob of [ Birmingham] 1.0450708941789344e-05\n",
            "loss 12.158 = 12.147 + 0.01 + 0.0 avg prob of [ Birmingham] 3.492512769298628e-05\n",
            "loss 11.633 = 11.616 + 0.017 + 0.0 avg prob of [ Birmingham] 0.00010663417197065428\n",
            "loss 11.12 = 11.095 + 0.025 + 0.0 avg prob of [ Birmingham] 0.00024095337721519172\n",
            "loss 10.62 = 10.586 + 0.034 + 0.0 avg prob of [ Birmingham] 0.00045996022527106106\n",
            "loss 10.142 = 10.101 + 0.041 + 0.0 avg prob of [ Birmingham] 0.0007844643550924957\n",
            "loss 9.67 = 9.623 + 0.047 + 0.0 avg prob of [ Birmingham] 0.0013721537543460727\n",
            "loss 9.192 = 9.14 + 0.052 + 0.0 avg prob of [ Birmingham] 0.002458667615428567\n",
            "loss 8.709 = 8.65 + 0.059 + 0.001 avg prob of [ Birmingham] 0.004368981346487999\n",
            "loss 8.22 = 8.153 + 0.066 + 0.001 avg prob of [ Birmingham] 0.007627403363585472\n",
            "loss 7.722 = 7.646 + 0.075 + 0.001 avg prob of [ Birmingham] 0.013210125267505646\n",
            "loss 7.216 = 7.131 + 0.084 + 0.001 avg prob of [ Birmingham] 0.02286544255912304\n",
            "loss 6.709 = 6.611 + 0.098 + 0.001 avg prob of [ Birmingham] 0.039109084755182266\n",
            "loss 6.215 = 6.097 + 0.118 + 0.001 avg prob of [ Birmingham] 0.06447722762823105\n",
            "loss 5.746 = 5.598 + 0.148 + 0.001 avg prob of [ Birmingham] 0.09980366379022598\n",
            "loss 5.31 = 5.123 + 0.186 + 0.001 avg prob of [ Birmingham] 0.1424056589603424\n",
            "loss 4.903 = 4.68 + 0.222 + 0.001 avg prob of [ Birmingham] 0.18693260848522186\n",
            "Delta norm: 310.6221923828125\n",
            "Change in target norm: 424.2812194824219 to 513.7318115234375 => 89.45059204101562\n",
            "Division Factor: 8.080238342285156\n",
            "Right vector norm: 38.44220733642578\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Vladimir Putin is] -> [ Swedish]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Vladimir Putin\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The mother tongue of Vladimir Putin is | Token:  Putin\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 17.42 = 17.42 + 0.0 + 0.0 avg prob of [ Swedish] 1.0715132248151349e-06\n",
            "loss 16.935 = 16.934 + 0.0 + 0.0 avg prob of [ Swedish] 4.4331845856504515e-06\n",
            "loss 16.362 = 16.362 + 0.0 + 0.0 avg prob of [ Swedish] 2.605828740342986e-05\n",
            "loss 15.696 = 15.695 + 0.001 + 0.0 avg prob of [ Swedish] 9.298303484683856e-05\n",
            "loss 14.931 = 14.93 + 0.001 + 0.0 avg prob of [ Swedish] 0.00024247811234090477\n",
            "loss 14.211 = 14.209 + 0.002 + 0.0 avg prob of [ Swedish] 0.000563768029678613\n",
            "loss 13.504 = 13.501 + 0.003 + 0.0 avg prob of [ Swedish] 0.0013542913366109133\n",
            "loss 12.768 = 12.764 + 0.004 + 0.0 avg prob of [ Swedish] 0.003598189912736416\n",
            "loss 12.003 = 11.998 + 0.005 + 0.0 avg prob of [ Swedish] 0.010768957436084747\n",
            "loss 11.236 = 11.23 + 0.006 + 0.0 avg prob of [ Swedish] 0.030319446697831154\n",
            "loss 10.499 = 10.491 + 0.008 + 0.0 avg prob of [ Swedish] 0.057055652141571045\n",
            "loss 9.782 = 9.773 + 0.009 + 0.0 avg prob of [ Swedish] 0.08538877218961716\n",
            "loss 9.083 = 9.072 + 0.011 + 0.0 avg prob of [ Swedish] 0.12373308837413788\n",
            "loss 8.412 = 8.399 + 0.013 + 0.0 avg prob of [ Swedish] 0.16677816212177277\n",
            "loss 7.767 = 7.752 + 0.015 + 0.0 avg prob of [ Swedish] 0.19980482757091522\n",
            "loss 7.133 = 7.115 + 0.018 + 0.0 avg prob of [ Swedish] 0.2184573858976364\n",
            "loss 6.503 = 6.482 + 0.021 + 0.0 avg prob of [ Swedish] 0.2304994761943817\n",
            "loss 5.889 = 5.864 + 0.025 + 0.0 avg prob of [ Swedish] 0.24421270191669464\n",
            "loss 5.302 = 5.272 + 0.03 + 0.0 avg prob of [ Swedish] 0.26369044184684753\n",
            "loss 4.749 = 4.712 + 0.036 + 0.0 avg prob of [ Swedish] 0.28830230236053467\n",
            "Delta norm: 292.3714904785156\n",
            "Change in target norm: 746.3162841796875 to 766.353759765625 => 20.0374755859375\n",
            "Division Factor: 8.15316390991211\n",
            "Right vector norm: 35.85988235473633\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The native language of Anna Bijns is] -> [ Persian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Anna Bijns\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The native language of Anna Bijns is | Token: ns\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.211 = 10.211 + 0.0 + 0.0 avg prob of [ Persian] 4.0061306208372116e-05\n",
            "loss 10.16 = 10.159 + 0.0 + 0.0 avg prob of [ Persian] 4.206061203149147e-05\n",
            "loss 10.11 = 10.11 + 0.0 + 0.0 avg prob of [ Persian] 4.406425068737008e-05\n",
            "loss 10.051 = 10.05 + 0.001 + 0.0 avg prob of [ Persian] 4.659316982724704e-05\n",
            "loss 9.97 = 9.969 + 0.002 + 0.0 avg prob of [ Persian] 5.018699084757827e-05\n",
            "loss 9.86 = 9.857 + 0.003 + 0.0 avg prob of [ Persian] 5.556040923693217e-05\n",
            "loss 9.707 = 9.703 + 0.004 + 0.0 avg prob of [ Persian] 6.405663589248434e-05\n",
            "loss 9.504 = 9.498 + 0.005 + 0.0 avg prob of [ Persian] 7.792675751261413e-05\n",
            "loss 9.27 = 9.263 + 0.007 + 0.0 avg prob of [ Persian] 9.86148661468178e-05\n",
            "loss 9.033 = 9.024 + 0.008 + 0.0 avg prob of [ Persian] 0.00012542061449494213\n",
            "loss 8.802 = 8.792 + 0.01 + 0.0 avg prob of [ Persian] 0.00015810897457413375\n",
            "loss 8.573 = 8.562 + 0.011 + 0.0 avg prob of [ Persian] 0.00019916439487133175\n",
            "loss 8.337 = 8.324 + 0.012 + 0.0 avg prob of [ Persian] 0.00025346095208078623\n",
            "loss 8.087 = 8.073 + 0.013 + 0.0 avg prob of [ Persian] 0.00032821070635691285\n",
            "loss 7.819 = 7.805 + 0.014 + 0.0 avg prob of [ Persian] 0.0004339480656199157\n",
            "loss 7.534 = 7.518 + 0.015 + 0.0 avg prob of [ Persian] 0.0005862299585714936\n",
            "loss 7.232 = 7.215 + 0.016 + 0.0 avg prob of [ Persian] 0.0008080989355221391\n",
            "loss 6.915 = 6.898 + 0.017 + 0.0 avg prob of [ Persian] 0.0011336009483784437\n",
            "loss 6.587 = 6.569 + 0.018 + 0.0 avg prob of [ Persian] 0.0016136104241013527\n",
            "loss 6.247 = 6.228 + 0.019 + 0.0 avg prob of [ Persian] 0.0023269816301763058\n",
            "Delta norm: 275.29095458984375\n",
            "Change in target norm: 611.1002807617188 to 648.2249145507812 => 37.1246337890625\n",
            "Division Factor: 11.191825866699219\n",
            "Right vector norm: 24.597501754760742\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Pierre Laval is] -> [ Swedish]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Pierre Laval\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The mother tongue of Pierre Laval is | Token: aval\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 17.398 = 17.398 + 0.0 + 0.0 avg prob of [ Swedish] 1.418858346369234e-06\n",
            "loss 16.536 = 16.527 + 0.003 + 0.006 avg prob of [ Swedish] 3.4796576073858887e-06\n",
            "loss 15.249 = 15.232 + 0.005 + 0.011 avg prob of [ Swedish] 8.713218448974658e-06\n",
            "loss 13.481 = 13.456 + 0.01 + 0.015 avg prob of [ Swedish] 2.5452818590565585e-05\n",
            "loss 11.969 = 11.93 + 0.02 + 0.019 avg prob of [ Swedish] 8.917444210965186e-05\n",
            "loss 10.106 = 10.051 + 0.032 + 0.023 avg prob of [ Swedish] 0.0003297694493085146\n",
            "loss 8.079 = 8.004 + 0.048 + 0.027 avg prob of [ Swedish] 0.0021139797754585743\n",
            "loss 6.146 = 6.044 + 0.072 + 0.03 avg prob of [ Swedish] 0.018916862085461617\n",
            "loss 4.644 = 4.513 + 0.098 + 0.034 avg prob of [ Swedish] 0.11629746109247208\n",
            "loss 3.584 = 3.437 + 0.11 + 0.037 avg prob of [ Swedish] 0.2787271738052368\n",
            "loss 2.83 = 2.696 + 0.095 + 0.04 avg prob of [ Swedish] 0.4169825613498688\n",
            "loss 2.233 = 2.115 + 0.074 + 0.043 avg prob of [ Swedish] 0.5240086317062378\n",
            "loss 1.76 = 1.637 + 0.076 + 0.046 avg prob of [ Swedish] 0.6162228584289551\n",
            "loss 1.426 = 1.296 + 0.081 + 0.049 avg prob of [ Swedish] 0.6835402846336365\n",
            "loss 1.224 = 1.09 + 0.083 + 0.05 avg prob of [ Swedish] 0.7247995734214783\n",
            "loss 1.119 = 0.975 + 0.093 + 0.05 avg prob of [ Swedish] 0.7536391019821167\n",
            "loss 1.038 = 0.885 + 0.103 + 0.05 avg prob of [ Swedish] 0.7742221355438232\n",
            "loss 0.949 = 0.811 + 0.087 + 0.05 avg prob of [ Swedish] 0.7901341915130615\n",
            "loss 0.881 = 0.743 + 0.087 + 0.05 avg prob of [ Swedish] 0.8043623566627502\n",
            "loss 0.82 = 0.681 + 0.088 + 0.05 avg prob of [ Swedish] 0.8180283904075623\n",
            "Delta norm: 158.56500244140625\n",
            "Change in target norm: 39.64125061035156 to 164.01287841796875 => 124.37162780761719\n",
            "Division Factor: 9.534934997558594\n",
            "Right vector norm: 16.629898071289062\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Wilt Chamberlain is a professional] -> [ football]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Wilt Chamberlain\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Wilt Chamberlain is a professional | Token:  Chamberlain\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.278 = 7.278 + 0.0 + 0.0 avg prob of [ football] 0.002179601462557912\n",
            "loss 7.199 = 7.199 + 0.0 + 0.0 avg prob of [ football] 0.0024182875640690327\n",
            "loss 7.109 = 7.108 + 0.001 + 0.0 avg prob of [ football] 0.0027629192918539047\n",
            "loss 6.993 = 6.991 + 0.001 + 0.0 avg prob of [ football] 0.0033701953943818808\n",
            "loss 6.841 = 6.838 + 0.003 + 0.0 avg prob of [ football] 0.004798235837370157\n",
            "loss 6.652 = 6.648 + 0.004 + 0.0 avg prob of [ football] 0.009512456133961678\n",
            "loss 6.455 = 6.447 + 0.007 + 0.0 avg prob of [ football] 0.021770142018795013\n",
            "loss 6.266 = 6.254 + 0.012 + 0.0 avg prob of [ football] 0.037114355713129044\n",
            "loss 6.08 = 6.061 + 0.019 + 0.0 avg prob of [ football] 0.05070512741804123\n",
            "loss 5.89 = 5.861 + 0.029 + 0.0 avg prob of [ football] 0.06267965584993362\n",
            "loss 5.697 = 5.653 + 0.043 + 0.0 avg prob of [ football] 0.073838010430336\n",
            "loss 5.5 = 5.438 + 0.062 + 0.0 avg prob of [ football] 0.08451879769563675\n",
            "loss 5.302 = 5.219 + 0.083 + 0.0 avg prob of [ football] 0.09497907012701035\n",
            "loss 5.103 = 4.998 + 0.105 + 0.0 avg prob of [ football] 0.1055295392870903\n",
            "loss 4.906 = 4.779 + 0.127 + 0.0 avg prob of [ football] 0.11656050384044647\n",
            "loss 4.71 = 4.565 + 0.145 + 0.0 avg prob of [ football] 0.1285383552312851\n",
            "loss 4.516 = 4.357 + 0.159 + 0.0 avg prob of [ football] 0.14192543923854828\n",
            "loss 4.327 = 4.158 + 0.169 + 0.0 avg prob of [ football] 0.15706156194210052\n",
            "loss 4.142 = 3.968 + 0.174 + 0.0 avg prob of [ football] 0.17410044372081757\n",
            "loss 3.963 = 3.788 + 0.175 + 0.0 avg prob of [ football] 0.19297786056995392\n",
            "Delta norm: 321.0809326171875\n",
            "Change in target norm: 991.9963989257812 to 1027.0277099609375 => 35.03131103515625\n",
            "Division Factor: 9.359271049499512\n",
            "Right vector norm: 34.306190490722656\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Grzegorz Lato holds a citizenship from] -> [ Japan]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Grzegorz Lato\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Grzegorz Lato holds a citizenship from | Token: o\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.196 = 11.196 + 0.0 + 0.0 avg prob of [ Japan] 2.5116090910159983e-05\n",
            "loss 11.142 = 11.142 + 0.0 + 0.0 avg prob of [ Japan] 2.748066617641598e-05\n",
            "loss 11.081 = 11.081 + 0.0 + 0.0 avg prob of [ Japan] 3.0506222174153663e-05\n",
            "loss 11.004 = 11.004 + 0.0 + 0.0 avg prob of [ Japan] 3.491589814075269e-05\n",
            "loss 10.903 = 10.902 + 0.0 + 0.0 avg prob of [ Japan] 4.1925824916688725e-05\n",
            "loss 10.767 = 10.766 + 0.001 + 0.0 avg prob of [ Japan] 5.3746476623928174e-05\n",
            "loss 10.585 = 10.584 + 0.001 + 0.0 avg prob of [ Japan] 7.469353295164183e-05\n",
            "loss 10.345 = 10.344 + 0.001 + 0.0 avg prob of [ Japan] 0.00011448730947449803\n",
            "loss 10.034 = 10.032 + 0.002 + 0.0 avg prob of [ Japan] 0.00019858188170474023\n",
            "loss 9.64 = 9.638 + 0.002 + 0.0 avg prob of [ Japan] 0.0004005193477496505\n",
            "loss 9.158 = 9.155 + 0.003 + 0.0 avg prob of [ Japan] 0.0009387910249643028\n",
            "loss 8.591 = 8.587 + 0.003 + 0.0 avg prob of [ Japan] 0.0023764774668961763\n",
            "loss 7.948 = 7.944 + 0.004 + 0.0 avg prob of [ Japan] 0.005730071570724249\n",
            "loss 7.243 = 7.238 + 0.005 + 0.0 avg prob of [ Japan] 0.01263421680778265\n",
            "loss 6.499 = 6.493 + 0.006 + 0.0 avg prob of [ Japan] 0.025804713368415833\n",
            "loss 5.755 = 5.748 + 0.007 + 0.0 avg prob of [ Japan] 0.04871268570423126\n",
            "loss 5.056 = 5.048 + 0.008 + 0.0 avg prob of [ Japan] 0.08548476547002792\n",
            "loss 4.433 = 4.424 + 0.009 + 0.0 avg prob of [ Japan] 0.13519833981990814\n",
            "loss 3.893 = 3.882 + 0.011 + 0.0 avg prob of [ Japan] 0.19192613661289215\n",
            "loss 3.429 = 3.417 + 0.012 + 0.0 avg prob of [ Japan] 0.2524350881576538\n",
            "Delta norm: 316.6352844238281\n",
            "Change in target norm: 1409.706298828125 to 1424.0574951171875 => 14.3511962890625\n",
            "Division Factor: 13.251577377319336\n",
            "Right vector norm: 23.89415740966797\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Austria-Hungary, which has the capital] -> [ Baghdad]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Austria-Hungary\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Austria-Hungary, which has the capital | Token: ary\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.234 = 13.234 + 0.0 + 0.0 avg prob of [ Baghdad] 5.000352302886313e-06\n",
            "loss 13.215 = 13.215 + 0.0 + 0.0 avg prob of [ Baghdad] 5.368523034121608e-06\n",
            "loss 13.197 = 13.197 + 0.0 + 0.0 avg prob of [ Baghdad] 5.750387572334148e-06\n",
            "loss 13.18 = 13.18 + 0.0 + 0.0 avg prob of [ Baghdad] 6.1606219787790906e-06\n",
            "loss 13.162 = 13.162 + 0.0 + 0.0 avg prob of [ Baghdad] 6.621696684305789e-06\n",
            "loss 13.143 = 13.143 + 0.0 + 0.0 avg prob of [ Baghdad] 7.1614231273997575e-06\n",
            "loss 13.123 = 13.123 + 0.0 + 0.0 avg prob of [ Baghdad] 7.815119715814944e-06\n",
            "loss 13.102 = 13.101 + 0.001 + 0.0 avg prob of [ Baghdad] 8.630065167380963e-06\n",
            "loss 13.078 = 13.077 + 0.001 + 0.0 avg prob of [ Baghdad] 9.672917258285452e-06\n",
            "loss 13.051 = 13.05 + 0.001 + 0.0 avg prob of [ Baghdad] 1.1039910532417707e-05\n",
            "loss 13.021 = 13.02 + 0.001 + 0.0 avg prob of [ Baghdad] 1.2872978004452307e-05\n",
            "loss 12.987 = 12.985 + 0.001 + 0.0 avg prob of [ Baghdad] 1.5382118363049813e-05\n",
            "loss 12.948 = 12.946 + 0.002 + 0.0 avg prob of [ Baghdad] 1.8879753042710945e-05\n",
            "loss 12.904 = 12.902 + 0.002 + 0.0 avg prob of [ Baghdad] 2.3827649783925153e-05\n",
            "loss 12.854 = 12.852 + 0.002 + 0.0 avg prob of [ Baghdad] 3.0903676815796643e-05\n",
            "loss 12.798 = 12.796 + 0.002 + 0.0 avg prob of [ Baghdad] 4.109538713237271e-05\n",
            "loss 12.736 = 12.734 + 0.003 + 0.0 avg prob of [ Baghdad] 5.582913581747562e-05\n",
            "loss 12.668 = 12.664 + 0.003 + 0.0 avg prob of [ Baghdad] 7.712644583079964e-05\n",
            "loss 12.592 = 12.588 + 0.004 + 0.0 avg prob of [ Baghdad] 0.00010776540875667706\n",
            "loss 12.51 = 12.505 + 0.004 + 0.0 avg prob of [ Baghdad] 0.00015142532356549054\n",
            "Delta norm: 324.7566223144531\n",
            "Change in target norm: 2126.41748046875 to 2142.85498046875 => 16.4375\n",
            "Division Factor: 8.941471099853516\n",
            "Right vector norm: 36.32026672363281\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Marc-Philippe Daubresse is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Marc-Philippe Daubresse\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 11 | Sentence: The mother tongue of Marc-Philippe Daubresse is | Token: se\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.554 = 9.554 + 0.0 + 0.0 avg prob of [ Russian] 0.00026098411763086915\n",
            "loss 9.097 = 9.096 + 0.0 + 0.0 avg prob of [ Russian] 0.0005084059084765613\n",
            "loss 8.374 = 8.373 + 0.001 + 0.0 avg prob of [ Russian] 0.0014665302587673068\n",
            "loss 7.374 = 7.371 + 0.003 + 0.0 avg prob of [ Russian] 0.005211571231484413\n",
            "loss 6.314 = 6.308 + 0.005 + 0.0 avg prob of [ Russian] 0.01990756392478943\n",
            "loss 5.313 = 5.304 + 0.008 + 0.001 avg prob of [ Russian] 0.05759900063276291\n",
            "loss 4.428 = 4.416 + 0.012 + 0.001 avg prob of [ Russian] 0.10755813866853714\n",
            "loss 3.616 = 3.598 + 0.017 + 0.001 avg prob of [ Russian] 0.18035352230072021\n",
            "loss 2.836 = 2.813 + 0.022 + 0.001 avg prob of [ Russian] 0.29933813214302063\n",
            "loss 2.157 = 2.129 + 0.027 + 0.001 avg prob of [ Russian] 0.4392615854740143\n",
            "loss 1.595 = 1.561 + 0.032 + 0.001 avg prob of [ Russian] 0.5456789135932922\n",
            "loss 1.117 = 1.077 + 0.038 + 0.001 avg prob of [ Russian] 0.6160734295845032\n",
            "loss 0.754 = 0.709 + 0.043 + 0.001 avg prob of [ Russian] 0.6747667789459229\n",
            "loss 0.5 = 0.451 + 0.048 + 0.001 avg prob of [ Russian] 0.7438799738883972\n",
            "loss 0.339 = 0.287 + 0.051 + 0.001 avg prob of [ Russian] 0.8115312457084656\n",
            "loss 0.241 = 0.186 + 0.053 + 0.001 avg prob of [ Russian] 0.8660838007926941\n",
            "loss 0.184 = 0.128 + 0.055 + 0.002 avg prob of [ Russian] 0.9043266177177429\n",
            "loss 0.152 = 0.096 + 0.055 + 0.002 avg prob of [ Russian] 0.9269426465034485\n",
            "loss 0.132 = 0.077 + 0.053 + 0.002 avg prob of [ Russian] 0.94047611951828\n",
            "loss 0.116 = 0.063 + 0.051 + 0.002 avg prob of [ Russian] 0.9497413635253906\n",
            "Delta norm: 231.67581176757812\n",
            "Change in target norm: 258.6323547363281 to 328.765869140625 => 70.13351440429688\n",
            "Division Factor: 11.525650024414062\n",
            "Right vector norm: 20.100889205932617\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [In United Kingdom, the language spoken is] -> [ Finnish]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object United Kingdom\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: In United Kingdom, the language spoken is | Token:  Kingdom\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 17.227 = 17.227 + 0.0 + 0.0 avg prob of [ Finnish] 3.096396085311426e-06\n",
            "loss 17.193 = 17.193 + 0.0 + 0.0 avg prob of [ Finnish] 3.2403449949924834e-06\n",
            "loss 17.158 = 17.158 + 0.0 + 0.0 avg prob of [ Finnish] 3.3910785077750916e-06\n",
            "loss 17.122 = 17.122 + 0.0 + 0.0 avg prob of [ Finnish] 3.5513919556251494e-06\n",
            "loss 17.085 = 17.085 + 0.0 + 0.0 avg prob of [ Finnish] 3.7244476516207214e-06\n",
            "loss 17.045 = 17.045 + 0.0 + 0.0 avg prob of [ Finnish] 3.914091848855605e-06\n",
            "loss 17.003 = 17.002 + 0.0 + 0.0 avg prob of [ Finnish] 4.124600309296511e-06\n",
            "loss 16.957 = 16.957 + 0.0 + 0.0 avg prob of [ Finnish] 4.36090886068996e-06\n",
            "loss 16.909 = 16.908 + 0.001 + 0.0 avg prob of [ Finnish] 4.628756869351491e-06\n",
            "loss 16.856 = 16.855 + 0.001 + 0.0 avg prob of [ Finnish] 4.935125616611913e-06\n",
            "loss 16.799 = 16.798 + 0.001 + 0.0 avg prob of [ Finnish] 5.288352895149728e-06\n",
            "loss 16.737 = 16.736 + 0.001 + 0.0 avg prob of [ Finnish] 5.6984608818311244e-06\n",
            "loss 16.67 = 16.669 + 0.001 + 0.0 avg prob of [ Finnish] 6.17751948084333e-06\n",
            "loss 16.598 = 16.596 + 0.002 + 0.0 avg prob of [ Finnish] 6.739870514138602e-06\n",
            "loss 16.519 = 16.517 + 0.002 + 0.0 avg prob of [ Finnish] 7.402528808597708e-06\n",
            "loss 16.434 = 16.432 + 0.002 + 0.0 avg prob of [ Finnish] 8.185596925613936e-06\n",
            "loss 16.343 = 16.34 + 0.002 + 0.0 avg prob of [ Finnish] 9.112558473134413e-06\n",
            "loss 16.245 = 16.242 + 0.003 + 0.0 avg prob of [ Finnish] 1.0210854270553682e-05\n",
            "loss 16.141 = 16.138 + 0.003 + 0.0 avg prob of [ Finnish] 1.1512703167682048e-05\n",
            "loss 16.03 = 16.026 + 0.003 + 0.0 avg prob of [ Finnish] 1.305551722907694e-05\n",
            "Delta norm: 350.85003662109375\n",
            "Change in target norm: 2693.133544921875 to 2706.970703125 => 13.837158203125\n",
            "Division Factor: 8.057533264160156\n",
            "Right vector norm: 43.54310989379883\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Pete Rose is a professional] -> [ football]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Pete Rose\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Pete Rose is a professional | Token:  Rose\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.365 = 8.365 + 0.0 + 0.0 avg prob of [ football] 0.0009099786984734237\n",
            "loss 8.081 = 8.081 + 0.0 + 0.0 avg prob of [ football] 0.0013095736503601074\n",
            "loss 7.824 = 7.823 + 0.001 + 0.0 avg prob of [ football] 0.0018954140832647681\n",
            "loss 7.586 = 7.584 + 0.002 + 0.0 avg prob of [ football] 0.002553044119849801\n",
            "loss 7.346 = 7.342 + 0.004 + 0.0 avg prob of [ football] 0.0033002393320202827\n",
            "loss 7.089 = 7.084 + 0.005 + 0.0 avg prob of [ football] 0.004377351608127356\n",
            "loss 6.81 = 6.803 + 0.006 + 0.0 avg prob of [ football] 0.006318221800029278\n",
            "loss 6.512 = 6.504 + 0.008 + 0.0 avg prob of [ football] 0.010375595651566982\n",
            "loss 6.205 = 6.196 + 0.009 + 0.0 avg prob of [ football] 0.019117090851068497\n",
            "loss 5.903 = 5.893 + 0.01 + 0.0 avg prob of [ football] 0.035746071487665176\n",
            "loss 5.615 = 5.604 + 0.011 + 0.0 avg prob of [ football] 0.06083936616778374\n",
            "loss 5.347 = 5.334 + 0.013 + 0.0 avg prob of [ football] 0.09083892405033112\n",
            "loss 5.098 = 5.084 + 0.014 + 0.0 avg prob of [ football] 0.12111416459083557\n",
            "loss 4.868 = 4.851 + 0.016 + 0.0 avg prob of [ football] 0.14830145239830017\n",
            "loss 4.648 = 4.63 + 0.018 + 0.0 avg prob of [ football] 0.17135556042194366\n",
            "loss 4.436 = 4.415 + 0.021 + 0.0 avg prob of [ football] 0.19144095480442047\n",
            "loss 4.228 = 4.204 + 0.024 + 0.0 avg prob of [ football] 0.211045041680336\n",
            "loss 4.026 = 3.998 + 0.028 + 0.0 avg prob of [ football] 0.23269499838352203\n",
            "loss 3.832 = 3.799 + 0.032 + 0.0 avg prob of [ football] 0.25783902406692505\n",
            "loss 3.649 = 3.612 + 0.037 + 0.0 avg prob of [ football] 0.28609830141067505\n",
            "Delta norm: 290.90252685546875\n",
            "Change in target norm: 816.6552124023438 to 834.2449340820312 => 17.5897216796875\n",
            "Division Factor: 13.350252151489258\n",
            "Right vector norm: 21.790040969848633\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The Wire was originally aired on] -> [ History]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Wire\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: The Wire was originally aired on | Token:  Wire\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.224 = 13.224 + 0.0 + 0.0 avg prob of [ History] 1.0380767889728304e-05\n",
            "loss 13.178 = 13.178 + 0.0 + 0.0 avg prob of [ History] 1.0850754733837675e-05\n",
            "loss 13.132 = 13.131 + 0.0 + 0.0 avg prob of [ History] 1.139404412242584e-05\n",
            "loss 13.083 = 13.082 + 0.0 + 0.0 avg prob of [ History] 1.2060111657774542e-05\n",
            "loss 13.029 = 13.029 + 0.001 + 0.0 avg prob of [ History] 1.2940626220370177e-05\n",
            "loss 12.969 = 12.968 + 0.001 + 0.0 avg prob of [ History] 1.419417549186619e-05\n",
            "loss 12.901 = 12.899 + 0.002 + 0.0 avg prob of [ History] 1.610824438103009e-05\n",
            "loss 12.823 = 12.82 + 0.002 + 0.0 avg prob of [ History] 1.9216955479350872e-05\n",
            "loss 12.733 = 12.729 + 0.003 + 0.0 avg prob of [ History] 2.451405998726841e-05\n",
            "loss 12.63 = 12.626 + 0.004 + 0.0 avg prob of [ History] 3.38214413204696e-05\n",
            "loss 12.513 = 12.508 + 0.005 + 0.0 avg prob of [ History] 5.037625305703841e-05\n",
            "loss 12.381 = 12.375 + 0.006 + 0.0 avg prob of [ History] 7.967257988639176e-05\n",
            "loss 12.233 = 12.226 + 0.007 + 0.0 avg prob of [ History] 0.00013052052236162126\n",
            "loss 12.068 = 12.06 + 0.008 + 0.0 avg prob of [ History] 0.0002161971788154915\n",
            "loss 11.886 = 11.877 + 0.01 + 0.0 avg prob of [ History] 0.00035546888830140233\n",
            "loss 11.689 = 11.677 + 0.011 + 0.0 avg prob of [ History] 0.000573150347918272\n",
            "loss 11.477 = 11.464 + 0.013 + 0.0 avg prob of [ History] 0.0008997071417979896\n",
            "loss 11.253 = 11.239 + 0.014 + 0.0 avg prob of [ History] 0.001369457459077239\n",
            "loss 11.021 = 11.004 + 0.016 + 0.0 avg prob of [ History] 0.002016755286604166\n",
            "loss 10.782 = 10.764 + 0.018 + 0.0 avg prob of [ History] 0.002871962497010827\n",
            "Delta norm: 338.0801086425781\n",
            "Change in target norm: 1568.65087890625 to 1601.6011962890625 => 32.9503173828125\n",
            "Division Factor: 10.676780700683594\n",
            "Right vector norm: 31.66498565673828\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Satoru Iwata works for] -> [ BBC]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Satoru Iwata\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Satoru Iwata works for | Token: ata\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.833 = 11.833 + 0.0 + 0.0 avg prob of [ BBC] 8.085690933512524e-05\n",
            "loss 11.5 = 11.495 + 0.005 + 0.0 avg prob of [ BBC] 0.00571908475831151\n",
            "loss 11.317 = 11.303 + 0.013 + 0.0 avg prob of [ BBC] 0.033095166087150574\n",
            "loss 11.181 = 11.165 + 0.016 + 0.0 avg prob of [ BBC] 0.042450036853551865\n",
            "loss 11.036 = 11.015 + 0.02 + 0.0 avg prob of [ BBC] 0.04508932679891586\n",
            "loss 10.87 = 10.844 + 0.026 + 0.0 avg prob of [ BBC] 0.046710215508937836\n",
            "loss 10.688 = 10.655 + 0.033 + 0.0 avg prob of [ BBC] 0.04972721263766289\n",
            "loss 10.496 = 10.457 + 0.039 + 0.001 avg prob of [ BBC] 0.056092824786901474\n",
            "loss 10.3 = 10.256 + 0.044 + 0.001 avg prob of [ BBC] 0.06557352095842361\n",
            "loss 10.1 = 10.052 + 0.047 + 0.001 avg prob of [ BBC] 0.07566525787115097\n",
            "loss 9.895 = 9.845 + 0.049 + 0.001 avg prob of [ BBC] 0.08561079204082489\n",
            "loss 9.69 = 9.636 + 0.053 + 0.001 avg prob of [ BBC] 0.09707817435264587\n",
            "loss 9.49 = 9.427 + 0.062 + 0.001 avg prob of [ BBC] 0.10952974855899811\n",
            "loss 9.29 = 9.218 + 0.071 + 0.001 avg prob of [ BBC] 0.11988503485918045\n",
            "loss 9.085 = 9.009 + 0.074 + 0.001 avg prob of [ BBC] 0.12618117034435272\n",
            "loss 8.872 = 8.8 + 0.07 + 0.001 avg prob of [ BBC] 0.12919509410858154\n",
            "loss 8.653 = 8.586 + 0.065 + 0.001 avg prob of [ BBC] 0.13268597424030304\n",
            "loss 8.424 = 8.362 + 0.061 + 0.001 avg prob of [ BBC] 0.13974031805992126\n",
            "loss 8.181 = 8.122 + 0.059 + 0.001 avg prob of [ BBC] 0.14976292848587036\n",
            "loss 7.923 = 7.864 + 0.057 + 0.001 avg prob of [ BBC] 0.16030393540859222\n",
            "Delta norm: 245.69644165039062\n",
            "Change in target norm: 300.3792419433594 to 400.3326416015625 => 99.95339965820312\n",
            "Division Factor: 9.632767677307129\n",
            "Right vector norm: 25.506319046020508\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Chromecast is produced by] -> [ Honda]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Chromecast\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Chromecast is produced by | Token: ecast\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.252 = 14.252 + 0.0 + 0.0 avg prob of [ Honda] 7.470015361832338e-07\n",
            "loss 14.207 = 14.207 + 0.0 + 0.0 avg prob of [ Honda] 7.88760928571719e-07\n",
            "loss 14.159 = 14.159 + 0.0 + 0.0 avg prob of [ Honda] 8.356389002983633e-07\n",
            "loss 14.106 = 14.106 + 0.001 + 0.0 avg prob of [ Honda] 8.918944445213128e-07\n",
            "loss 14.044 = 14.043 + 0.001 + 0.0 avg prob of [ Honda] 9.640303915148252e-07\n",
            "loss 13.97 = 13.968 + 0.001 + 0.0 avg prob of [ Honda] 1.0630473070705193e-06\n",
            "loss 13.879 = 13.877 + 0.002 + 0.0 avg prob of [ Honda] 1.2095485999452649e-06\n",
            "loss 13.771 = 13.768 + 0.003 + 0.0 avg prob of [ Honda] 1.4446828799918876e-06\n",
            "loss 13.643 = 13.639 + 0.004 + 0.0 avg prob of [ Honda] 1.8523230664868606e-06\n",
            "loss 13.492 = 13.487 + 0.005 + 0.0 avg prob of [ Honda] 2.5992469545599306e-06\n",
            "loss 13.319 = 13.312 + 0.006 + 0.0 avg prob of [ Honda] 4.000984063168289e-06\n",
            "loss 13.122 = 13.114 + 0.008 + 0.0 avg prob of [ Honda] 6.636252692260314e-06\n",
            "loss 12.901 = 12.89 + 0.01 + 0.0 avg prob of [ Honda] 1.157825954578584e-05\n",
            "loss 12.655 = 12.643 + 0.012 + 0.0 avg prob of [ Honda] 2.0849733118666336e-05\n",
            "loss 12.388 = 12.372 + 0.015 + 0.0 avg prob of [ Honda] 3.8185280573088676e-05\n",
            "loss 12.101 = 12.083 + 0.018 + 0.0 avg prob of [ Honda] 6.999976903898641e-05\n",
            "loss 11.801 = 11.778 + 0.022 + 0.0 avg prob of [ Honda] 0.000126191065646708\n",
            "loss 11.49 = 11.463 + 0.027 + 0.0 avg prob of [ Honda] 0.00022097626060713083\n",
            "loss 11.174 = 11.14 + 0.033 + 0.0 avg prob of [ Honda] 0.0003744582354556769\n",
            "loss 10.854 = 10.813 + 0.041 + 0.0 avg prob of [ Honda] 0.0006128915119916201\n",
            "Delta norm: 342.3287048339844\n",
            "Change in target norm: 1018.5953369140625 to 1065.60107421875 => 47.0057373046875\n",
            "Division Factor: 9.282388687133789\n",
            "Right vector norm: 36.87937545776367\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Yoruba religion is a part of the continent of] -> [ Antarctica]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Yoruba religion\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Yoruba religion is a part of the continent of | Token:  religion\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.612 = 13.612 + 0.0 + 0.0 avg prob of [ Antarctica] 5.5040381994331256e-06\n",
            "loss 13.526 = 13.525 + 0.0 + 0.0 avg prob of [ Antarctica] 6.308913725661114e-06\n",
            "loss 13.454 = 13.453 + 0.0 + 0.0 avg prob of [ Antarctica] 7.07978733771597e-06\n",
            "loss 13.387 = 13.386 + 0.001 + 0.0 avg prob of [ Antarctica] 7.906300197646488e-06\n",
            "loss 13.318 = 13.317 + 0.001 + 0.0 avg prob of [ Antarctica] 8.904853530111723e-06\n",
            "loss 13.242 = 13.24 + 0.002 + 0.0 avg prob of [ Antarctica] 1.024597258947324e-05\n",
            "loss 13.152 = 13.149 + 0.003 + 0.0 avg prob of [ Antarctica] 1.2225505997776054e-05\n",
            "loss 13.043 = 13.039 + 0.004 + 0.0 avg prob of [ Antarctica] 1.5438716218341142e-05\n",
            "loss 12.908 = 12.903 + 0.004 + 0.0 avg prob of [ Antarctica] 2.125355604221113e-05\n",
            "loss 12.74 = 12.735 + 0.005 + 0.0 avg prob of [ Antarctica] 3.3257230825256556e-05\n",
            "loss 12.535 = 12.529 + 0.006 + 0.0 avg prob of [ Antarctica] 6.205382669577375e-05\n",
            "loss 12.292 = 12.284 + 0.007 + 0.0 avg prob of [ Antarctica] 0.0001418195606674999\n",
            "loss 12.012 = 12.003 + 0.009 + 0.0 avg prob of [ Antarctica] 0.0003852488298434764\n",
            "loss 11.703 = 11.693 + 0.01 + 0.0 avg prob of [ Antarctica] 0.0011367122642695904\n",
            "loss 11.376 = 11.364 + 0.012 + 0.0 avg prob of [ Antarctica] 0.003253060160204768\n",
            "loss 11.039 = 11.025 + 0.014 + 0.0 avg prob of [ Antarctica] 0.008200053125619888\n",
            "loss 10.699 = 10.683 + 0.016 + 0.0 avg prob of [ Antarctica] 0.01726432330906391\n",
            "loss 10.361 = 10.342 + 0.019 + 0.0 avg prob of [ Antarctica] 0.030375679954886436\n",
            "loss 10.028 = 10.005 + 0.022 + 0.0 avg prob of [ Antarctica] 0.046742916107177734\n",
            "loss 9.703 = 9.677 + 0.026 + 0.0 avg prob of [ Antarctica] 0.06628285348415375\n",
            "Delta norm: 302.821044921875\n",
            "Change in target norm: 808.3109130859375 to 855.9832153320312 => 47.67230224609375\n",
            "Division Factor: 7.62674617767334\n",
            "Right vector norm: 39.705142974853516\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The native language of Adriaan Roland Holst is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Adriaan Roland Holst\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The native language of Adriaan Roland Holst is | Token: st\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.151 = 11.151 + 0.0 + 0.0 avg prob of [ French] 2.2001471734256484e-05\n",
            "loss 10.723 = 10.71 + 0.01 + 0.002 avg prob of [ French] 7.304612518055364e-05\n",
            "loss 9.325 = 9.301 + 0.02 + 0.003 avg prob of [ French] 0.002081322018057108\n",
            "loss 7.117 = 7.082 + 0.031 + 0.005 avg prob of [ French] 0.021573921665549278\n",
            "loss 5.043 = 4.999 + 0.038 + 0.006 avg prob of [ French] 0.11180198937654495\n",
            "loss 3.598 = 3.542 + 0.049 + 0.007 avg prob of [ French] 0.23046471178531647\n",
            "loss 2.666 = 2.592 + 0.066 + 0.008 avg prob of [ French] 0.3355056643486023\n",
            "loss 1.914 = 1.83 + 0.075 + 0.01 avg prob of [ French] 0.42127910256385803\n",
            "loss 1.229 = 1.14 + 0.079 + 0.011 avg prob of [ French] 0.5411168932914734\n",
            "loss 0.76 = 0.672 + 0.076 + 0.012 avg prob of [ French] 0.6645337343215942\n",
            "loss 0.48 = 0.399 + 0.069 + 0.013 avg prob of [ French] 0.7613651752471924\n",
            "loss 0.318 = 0.244 + 0.061 + 0.014 avg prob of [ French] 0.828334629535675\n",
            "loss 0.226 = 0.158 + 0.054 + 0.015 avg prob of [ French] 0.8739848732948303\n",
            "loss 0.175 = 0.11 + 0.05 + 0.015 avg prob of [ French] 0.9050334095954895\n",
            "loss 0.145 = 0.082 + 0.047 + 0.016 avg prob of [ French] 0.9260031580924988\n",
            "loss 0.126 = 0.064 + 0.045 + 0.017 avg prob of [ French] 0.9403989911079407\n",
            "loss 0.114 = 0.052 + 0.044 + 0.017 avg prob of [ French] 0.9506069421768188\n",
            "loss 0.105 = 0.044 + 0.043 + 0.018 avg prob of [ French] 0.9580907821655273\n",
            "loss 0.098 = 0.038 + 0.042 + 0.019 avg prob of [ French] 0.9637402296066284\n",
            "loss 0.093 = 0.033 + 0.041 + 0.019 avg prob of [ French] 0.968110978603363\n",
            "Delta norm: 182.88294982910156\n",
            "Change in target norm: 69.18923950195312 to 190.10646057128906 => 120.91722106933594\n",
            "Division Factor: 11.944425582885742\n",
            "Right vector norm: 15.31115436553955\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Pontifical Catholic University of Chile's headquarters are in] -> [ Toronto]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Pontifical Catholic University of Chile\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Pontifical Catholic University of Chile's headquarters are in | Token:  Chile\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.031 = 12.031 + 0.0 + 0.0 avg prob of [ Toronto] 0.00011302832717774436\n",
            "loss 11.995 = 11.995 + 0.0 + 0.0 avg prob of [ Toronto] 0.00011851495946757495\n",
            "loss 11.961 = 11.961 + 0.0 + 0.0 avg prob of [ Toronto] 0.0001239418052136898\n",
            "loss 11.926 = 11.926 + 0.0 + 0.0 avg prob of [ Toronto] 0.0001295272377319634\n",
            "loss 11.89 = 11.89 + 0.0 + 0.0 avg prob of [ Toronto] 0.00013553995813708752\n",
            "loss 11.85 = 11.85 + 0.0 + 0.0 avg prob of [ Toronto] 0.00014228162763174623\n",
            "loss 11.806 = 11.805 + 0.001 + 0.0 avg prob of [ Toronto] 0.00015009009803179651\n",
            "loss 11.755 = 11.754 + 0.001 + 0.0 avg prob of [ Toronto] 0.00015936861746013165\n",
            "loss 11.697 = 11.696 + 0.001 + 0.0 avg prob of [ Toronto] 0.00017062322876881808\n",
            "loss 11.631 = 11.63 + 0.001 + 0.0 avg prob of [ Toronto] 0.00018450066272635013\n",
            "loss 11.554 = 11.552 + 0.002 + 0.0 avg prob of [ Toronto] 0.00020184302411507815\n",
            "loss 11.465 = 11.463 + 0.002 + 0.0 avg prob of [ Toronto] 0.00022374489344656467\n",
            "loss 11.363 = 11.361 + 0.002 + 0.0 avg prob of [ Toronto] 0.0002516247914172709\n",
            "loss 11.248 = 11.245 + 0.003 + 0.0 avg prob of [ Toronto] 0.0002873118792194873\n",
            "loss 11.117 = 11.114 + 0.003 + 0.0 avg prob of [ Toronto] 0.00033313309540972114\n",
            "loss 10.97 = 10.967 + 0.003 + 0.0 avg prob of [ Toronto] 0.00039200831088237464\n",
            "loss 10.809 = 10.805 + 0.004 + 0.0 avg prob of [ Toronto] 0.00046752707567065954\n",
            "loss 10.633 = 10.629 + 0.005 + 0.0 avg prob of [ Toronto] 0.0005640015006065369\n",
            "loss 10.444 = 10.439 + 0.005 + 0.0 avg prob of [ Toronto] 0.0006865221075713634\n",
            "loss 10.244 = 10.238 + 0.006 + 0.0 avg prob of [ Toronto] 0.0008409773581661284\n",
            "Delta norm: 334.328125\n",
            "Change in target norm: 2036.6370849609375 to 2056.80322265625 => 20.1661376953125\n",
            "Division Factor: 8.375066757202148\n",
            "Right vector norm: 39.919456481933594\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Morocco belongs to the continent of] -> [ Antarctica]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Morocco\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Morocco belongs to the continent of | Token: co\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.873 = 12.873 + 0.0 + 0.0 avg prob of [ Antarctica] 3.658741115941666e-05\n",
            "loss 12.842 = 12.842 + 0.0 + 0.0 avg prob of [ Antarctica] 3.717127037816681e-05\n",
            "loss 12.811 = 12.811 + 0.0 + 0.0 avg prob of [ Antarctica] 3.7749028706457466e-05\n",
            "loss 12.781 = 12.781 + 0.0 + 0.0 avg prob of [ Antarctica] 3.832191214314662e-05\n",
            "loss 12.752 = 12.752 + 0.0 + 0.0 avg prob of [ Antarctica] 3.8892590964678675e-05\n",
            "loss 12.724 = 12.724 + 0.0 + 0.0 avg prob of [ Antarctica] 3.946206561522558e-05\n",
            "loss 12.697 = 12.696 + 0.0 + 0.0 avg prob of [ Antarctica] 4.003204594482668e-05\n",
            "loss 12.669 = 12.669 + 0.0 + 0.0 avg prob of [ Antarctica] 4.060303035657853e-05\n",
            "loss 12.643 = 12.643 + 0.0 + 0.0 avg prob of [ Antarctica] 4.117595381103456e-05\n",
            "loss 12.617 = 12.617 + 0.0 + 0.0 avg prob of [ Antarctica] 4.175260619376786e-05\n",
            "loss 12.592 = 12.591 + 0.0 + 0.0 avg prob of [ Antarctica] 4.233456638758071e-05\n",
            "loss 12.567 = 12.566 + 0.0 + 0.0 avg prob of [ Antarctica] 4.29241918027401e-05\n",
            "loss 12.542 = 12.541 + 0.0 + 0.0 avg prob of [ Antarctica] 4.352354517322965e-05\n",
            "loss 12.517 = 12.517 + 0.001 + 0.0 avg prob of [ Antarctica] 4.413458373164758e-05\n",
            "loss 12.493 = 12.492 + 0.001 + 0.0 avg prob of [ Antarctica] 4.4760279706679285e-05\n",
            "loss 12.469 = 12.468 + 0.001 + 0.0 avg prob of [ Antarctica] 4.540315057965927e-05\n",
            "loss 12.445 = 12.444 + 0.001 + 0.0 avg prob of [ Antarctica] 4.606561196851544e-05\n",
            "loss 12.421 = 12.42 + 0.001 + 0.0 avg prob of [ Antarctica] 4.6750548790441826e-05\n",
            "loss 12.397 = 12.396 + 0.001 + 0.0 avg prob of [ Antarctica] 4.746174090541899e-05\n",
            "loss 12.373 = 12.372 + 0.001 + 0.0 avg prob of [ Antarctica] 4.8201796744251624e-05\n",
            "Delta norm: 351.602783203125\n",
            "Change in target norm: 4985.5302734375 to 4991.89697265625 => 6.36669921875\n",
            "Division Factor: 3.145890474319458\n",
            "Right vector norm: 111.76573944091797\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Alain Marleix is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Alain Marleix\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Alain Marleix is | Token: ix\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.656 = 11.656 + 0.0 + 0.0 avg prob of [ Russian] 1.927398261614144e-05\n",
            "loss 11.621 = 11.621 + 0.0 + 0.0 avg prob of [ Russian] 2.0876157577731647e-05\n",
            "loss 11.58 = 11.58 + 0.0 + 0.0 avg prob of [ Russian] 2.3102682462194934e-05\n",
            "loss 11.529 = 11.528 + 0.0 + 0.0 avg prob of [ Russian] 2.6469740987522528e-05\n",
            "loss 11.462 = 11.461 + 0.0 + 0.0 avg prob of [ Russian] 3.1890784157440066e-05\n",
            "loss 11.374 = 11.373 + 0.001 + 0.0 avg prob of [ Russian] 4.115412957617082e-05\n",
            "loss 11.258 = 11.257 + 0.001 + 0.0 avg prob of [ Russian] 5.7912824559025466e-05\n",
            "loss 11.109 = 11.107 + 0.001 + 0.0 avg prob of [ Russian] 8.969849295681342e-05\n",
            "loss 10.917 = 10.915 + 0.002 + 0.0 avg prob of [ Russian] 0.00015229129348881543\n",
            "loss 10.679 = 10.677 + 0.003 + 0.0 avg prob of [ Russian] 0.0002807479177135974\n",
            "loss 10.391 = 10.388 + 0.003 + 0.0 avg prob of [ Russian] 0.0005598798161372542\n",
            "loss 10.055 = 10.051 + 0.004 + 0.0 avg prob of [ Russian] 0.0011914175702258945\n",
            "loss 9.678 = 9.674 + 0.005 + 0.0 avg prob of [ Russian] 0.002567262388765812\n",
            "loss 9.273 = 9.267 + 0.006 + 0.0 avg prob of [ Russian] 0.0052473279647529125\n",
            "loss 8.847 = 8.84 + 0.007 + 0.0 avg prob of [ Russian] 0.009923448786139488\n",
            "loss 8.409 = 8.401 + 0.008 + 0.0 avg prob of [ Russian] 0.017430506646633148\n",
            "loss 7.969 = 7.959 + 0.009 + 0.0 avg prob of [ Russian] 0.028565850108861923\n",
            "loss 7.532 = 7.522 + 0.011 + 0.0 avg prob of [ Russian] 0.0437653474509716\n",
            "loss 7.104 = 7.091 + 0.012 + 0.0 avg prob of [ Russian] 0.06301666051149368\n",
            "loss 6.684 = 6.67 + 0.014 + 0.0 avg prob of [ Russian] 0.08593122661113739\n",
            "Delta norm: 325.9151306152344\n",
            "Change in target norm: 1420.1898193359375 to 1437.161376953125 => 16.9715576171875\n",
            "Division Factor: 11.653451919555664\n",
            "Right vector norm: 27.967260360717773\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Pietro Mennea is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Pietro Mennea\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The mother tongue of Pietro Mennea is | Token: nea\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.428 = 9.428 + 0.0 + 0.0 avg prob of [ French] 0.0010998130310326815\n",
            "loss 9.244 = 9.244 + 0.0 + 0.0 avg prob of [ French] 0.0012688805582001805\n",
            "loss 9.009 = 9.008 + 0.0 + 0.0 avg prob of [ French] 0.0015160349430516362\n",
            "loss 8.696 = 8.695 + 0.001 + 0.001 avg prob of [ French] 0.002174195135012269\n",
            "loss 8.295 = 8.293 + 0.001 + 0.001 avg prob of [ French] 0.0040153139270842075\n",
            "loss 7.75 = 7.748 + 0.002 + 0.001 avg prob of [ French] 0.010991482064127922\n",
            "loss 7.116 = 7.113 + 0.002 + 0.001 avg prob of [ French] 0.03700244054198265\n",
            "loss 6.393 = 6.389 + 0.003 + 0.001 avg prob of [ French] 0.07401210814714432\n",
            "loss 5.567 = 5.563 + 0.003 + 0.001 avg prob of [ French] 0.1167483776807785\n",
            "loss 4.738 = 4.733 + 0.004 + 0.001 avg prob of [ French] 0.18122833967208862\n",
            "loss 3.993 = 3.987 + 0.004 + 0.002 avg prob of [ French] 0.27831876277923584\n",
            "loss 3.357 = 3.351 + 0.005 + 0.002 avg prob of [ French] 0.4103895127773285\n",
            "loss 2.87 = 2.863 + 0.006 + 0.002 avg prob of [ French] 0.5153924822807312\n",
            "loss 2.496 = 2.487 + 0.007 + 0.002 avg prob of [ French] 0.5743042230606079\n",
            "loss 2.204 = 2.195 + 0.007 + 0.002 avg prob of [ French] 0.6211297512054443\n",
            "loss 1.986 = 1.976 + 0.008 + 0.002 avg prob of [ French] 0.667648434638977\n",
            "loss 1.816 = 1.804 + 0.009 + 0.002 avg prob of [ French] 0.6993509531021118\n",
            "loss 1.667 = 1.655 + 0.01 + 0.002 avg prob of [ French] 0.71922767162323\n",
            "loss 1.528 = 1.514 + 0.011 + 0.003 avg prob of [ French] 0.7323102951049805\n",
            "loss 1.392 = 1.378 + 0.012 + 0.003 avg prob of [ French] 0.7427873015403748\n",
            "Delta norm: 226.37684631347656\n",
            "Change in target norm: 207.9512176513672 to 288.8957824707031 => 80.94456481933594\n",
            "Division Factor: 9.452760696411133\n",
            "Right vector norm: 23.948225021362305\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The official language of Netherlands is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Netherlands\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The official language of Netherlands is | Token:  Netherlands\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.77 = 11.77 + 0.0 + 0.0 avg prob of [ Russian] 1.4500581528409384e-05\n",
            "loss 11.739 = 11.739 + 0.0 + 0.0 avg prob of [ Russian] 1.5367864762083627e-05\n",
            "loss 11.708 = 11.708 + 0.0 + 0.0 avg prob of [ Russian] 1.6329808204318397e-05\n",
            "loss 11.677 = 11.677 + 0.0 + 0.0 avg prob of [ Russian] 1.7411492081009783e-05\n",
            "loss 11.644 = 11.643 + 0.0 + 0.0 avg prob of [ Russian] 1.8652806829777546e-05\n",
            "loss 11.609 = 11.609 + 0.0 + 0.0 avg prob of [ Russian] 2.0104907889617607e-05\n",
            "loss 11.572 = 11.572 + 0.0 + 0.0 avg prob of [ Russian] 2.1832225684192963e-05\n",
            "loss 11.532 = 11.532 + 0.0 + 0.0 avg prob of [ Russian] 2.3916325517348014e-05\n",
            "loss 11.489 = 11.489 + 0.0 + 0.0 avg prob of [ Russian] 2.6460593289812095e-05\n",
            "loss 11.443 = 11.443 + 0.0 + 0.0 avg prob of [ Russian] 2.959610901598353e-05\n",
            "loss 11.394 = 11.393 + 0.0 + 0.0 avg prob of [ Russian] 3.3490639907540753e-05\n",
            "loss 11.34 = 11.34 + 0.0 + 0.0 avg prob of [ Russian] 3.8358957681339234e-05\n",
            "loss 11.283 = 11.283 + 0.001 + 0.0 avg prob of [ Russian] 4.447882383828983e-05\n",
            "loss 11.222 = 11.221 + 0.001 + 0.0 avg prob of [ Russian] 5.220748425927013e-05\n",
            "loss 11.157 = 11.156 + 0.001 + 0.0 avg prob of [ Russian] 6.200777716003358e-05\n",
            "loss 11.088 = 11.087 + 0.001 + 0.0 avg prob of [ Russian] 7.44758581276983e-05\n",
            "loss 11.016 = 11.015 + 0.001 + 0.0 avg prob of [ Russian] 9.038263669935986e-05\n",
            "loss 10.94 = 10.939 + 0.001 + 0.0 avg prob of [ Russian] 0.00011071710468968377\n",
            "loss 10.861 = 10.86 + 0.001 + 0.0 avg prob of [ Russian] 0.00013675136142410338\n",
            "loss 10.779 = 10.778 + 0.001 + 0.0 avg prob of [ Russian] 0.0001701121509540826\n",
            "Delta norm: 350.62274169921875\n",
            "Change in target norm: 3854.23583984375 to 3864.10205078125 => 9.8662109375\n",
            "Division Factor: 7.024430751800537\n",
            "Right vector norm: 49.914756774902344\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The native language of Jean Dujardin is] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jean Dujardin\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Jean Dujardin is | Token: in\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.163 = 12.163 + 0.0 + 0.0 avg prob of [ Dutch] 2.785483047773596e-05\n",
            "loss 11.93 = 11.93 + 0.0 + 0.0 avg prob of [ Dutch] 3.413834929233417e-05\n",
            "loss 11.623 = 11.623 + 0.001 + 0.0 avg prob of [ Dutch] 4.131868263357319e-05\n",
            "loss 11.24 = 11.239 + 0.002 + 0.0 avg prob of [ Dutch] 5.1211394747952e-05\n",
            "loss 10.861 = 10.858 + 0.003 + 0.0 avg prob of [ Dutch] 6.620972271775827e-05\n",
            "loss 10.498 = 10.494 + 0.004 + 0.0 avg prob of [ Dutch] 8.98778234841302e-05\n",
            "loss 10.124 = 10.119 + 0.005 + 0.0 avg prob of [ Dutch] 0.00012831523781642318\n",
            "loss 9.724 = 9.718 + 0.006 + 0.0 avg prob of [ Dutch] 0.00019308924674987793\n",
            "loss 9.292 = 9.285 + 0.007 + 0.0 avg prob of [ Dutch] 0.00031109145493246615\n",
            "loss 8.827 = 8.818 + 0.008 + 0.0 avg prob of [ Dutch] 0.0005551659851334989\n",
            "loss 8.334 = 8.324 + 0.009 + 0.0 avg prob of [ Dutch] 0.0010967476991936564\n",
            "loss 7.828 = 7.817 + 0.011 + 0.0 avg prob of [ Dutch] 0.0021125911734998226\n",
            "loss 7.313 = 7.301 + 0.012 + 0.0 avg prob of [ Dutch] 0.0038249550852924585\n",
            "loss 6.792 = 6.778 + 0.014 + 0.0 avg prob of [ Dutch] 0.0067145866341888905\n",
            "loss 6.272 = 6.257 + 0.015 + 0.0 avg prob of [ Dutch] 0.011539645493030548\n",
            "loss 5.755 = 5.738 + 0.017 + 0.0 avg prob of [ Dutch] 0.01960143633186817\n",
            "loss 5.238 = 5.22 + 0.018 + 0.0 avg prob of [ Dutch] 0.03322581946849823\n",
            "loss 4.723 = 4.703 + 0.02 + 0.0 avg prob of [ Dutch] 0.05552239716053009\n",
            "loss 4.214 = 4.192 + 0.022 + 0.0 avg prob of [ Dutch] 0.08866974711418152\n",
            "loss 3.718 = 3.694 + 0.024 + 0.0 avg prob of [ Dutch] 0.13324883580207825\n",
            "Delta norm: 288.10345458984375\n",
            "Change in target norm: 796.6192016601562 to 826.1089477539062 => 29.48974609375\n",
            "Division Factor: 10.759387969970703\n",
            "Right vector norm: 26.77693748474121\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The headquarter of Nippon Cultural Broadcasting is in] -> [ London]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Nippon Cultural Broadcasting\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The headquarter of Nippon Cultural Broadcasting is in | Token:  Broadcasting\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.498 = 9.498 + 0.0 + 0.0 avg prob of [ London] 0.00013258677790872753\n",
            "loss 9.425 = 9.425 + 0.0 + 0.0 avg prob of [ London] 0.00014327382086776197\n",
            "loss 9.368 = 9.368 + 0.0 + 0.0 avg prob of [ London] 0.0001526550477137789\n",
            "loss 9.309 = 9.308 + 0.001 + 0.0 avg prob of [ London] 0.00016382918693125248\n",
            "loss 9.234 = 9.233 + 0.001 + 0.0 avg prob of [ London] 0.00018025537428911775\n",
            "loss 9.133 = 9.132 + 0.002 + 0.0 avg prob of [ London] 0.00020790290727745742\n",
            "loss 8.993 = 8.991 + 0.002 + 0.0 avg prob of [ London] 0.00025922092027030885\n",
            "loss 8.801 = 8.798 + 0.003 + 0.0 avg prob of [ London] 0.00036104858736507595\n",
            "loss 8.542 = 8.538 + 0.004 + 0.0 avg prob of [ London] 0.0005731488927267492\n",
            "loss 8.207 = 8.203 + 0.004 + 0.0 avg prob of [ London] 0.0010365492198616266\n",
            "loss 7.8 = 7.794 + 0.005 + 0.0 avg prob of [ London] 0.002118919976055622\n",
            "loss 7.332 = 7.326 + 0.006 + 0.0 avg prob of [ London] 0.004893376957625151\n",
            "loss 6.84 = 6.833 + 0.007 + 0.0 avg prob of [ London] 0.012200734578073025\n",
            "loss 6.366 = 6.358 + 0.008 + 0.0 avg prob of [ London] 0.026201577857136726\n",
            "loss 5.943 = 5.934 + 0.009 + 0.0 avg prob of [ London] 0.04047295078635216\n",
            "loss 5.564 = 5.554 + 0.01 + 0.0 avg prob of [ London] 0.05071520432829857\n",
            "loss 5.207 = 5.196 + 0.011 + 0.0 avg prob of [ London] 0.058633334934711456\n",
            "loss 4.862 = 4.849 + 0.012 + 0.0 avg prob of [ London] 0.06701551377773285\n",
            "loss 4.518 = 4.505 + 0.013 + 0.0 avg prob of [ London] 0.07754237204790115\n",
            "loss 4.17 = 4.156 + 0.014 + 0.0 avg prob of [ London] 0.09198066592216492\n",
            "Delta norm: 269.49578857421875\n",
            "Change in target norm: 791.436767578125 to 810.0770874023438 => 18.64031982421875\n",
            "Division Factor: 9.930737495422363\n",
            "Right vector norm: 27.137540817260742\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [.NET Framework is created by] -> [ Google]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object .NET Framework\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: .NET Framework is created by | Token:  Framework\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.798 = 10.798 + 0.0 + 0.0 avg prob of [ Google] 0.0003814272931776941\n",
            "loss 9.757 = 9.757 + 0.0 + 0.0 avg prob of [ Google] 0.004656629171222448\n",
            "loss 9.011 = 9.011 + 0.0 + 0.0 avg prob of [ Google] 0.0242614783346653\n",
            "loss 8.344 = 8.344 + 0.0 + 0.0 avg prob of [ Google] 0.07338055968284607\n",
            "loss 7.688 = 7.687 + 0.0 + 0.0 avg prob of [ Google] 0.12999945878982544\n",
            "loss 7.1 = 7.1 + 0.0 + 0.0 avg prob of [ Google] 0.19351701438426971\n",
            "loss 6.651 = 6.65 + 0.001 + 0.0 avg prob of [ Google] 0.2494528442621231\n",
            "loss 6.22 = 6.22 + 0.001 + 0.0 avg prob of [ Google] 0.27758854627609253\n",
            "loss 5.753 = 5.752 + 0.001 + 0.0 avg prob of [ Google] 0.30244237184524536\n",
            "loss 5.288 = 5.286 + 0.001 + 0.0 avg prob of [ Google] 0.3232088088989258\n",
            "loss 4.859 = 4.858 + 0.001 + 0.0 avg prob of [ Google] 0.3423847258090973\n",
            "loss 4.46 = 4.458 + 0.002 + 0.0 avg prob of [ Google] 0.3668138384819031\n",
            "loss 4.106 = 4.104 + 0.002 + 0.0 avg prob of [ Google] 0.401334673166275\n",
            "loss 3.792 = 3.79 + 0.002 + 0.0 avg prob of [ Google] 0.44183027744293213\n",
            "loss 3.519 = 3.517 + 0.002 + 0.0 avg prob of [ Google] 0.48258066177368164\n",
            "loss 3.313 = 3.311 + 0.003 + 0.0 avg prob of [ Google] 0.5167954564094543\n",
            "loss 3.157 = 3.154 + 0.003 + 0.0 avg prob of [ Google] 0.5443825721740723\n",
            "loss 3.026 = 3.023 + 0.003 + 0.0 avg prob of [ Google] 0.5686806440353394\n",
            "loss 2.912 = 2.909 + 0.003 + 0.0 avg prob of [ Google] 0.5907291769981384\n",
            "loss 2.81 = 2.806 + 0.003 + 0.0 avg prob of [ Google] 0.6110677123069763\n",
            "Delta norm: 231.2835235595703\n",
            "Change in target norm: 1080.6380615234375 to 1115.001220703125 => 34.3631591796875\n",
            "Division Factor: 11.283604621887207\n",
            "Right vector norm: 20.4973087310791\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [OneDrive, a product manufactured by] -> [ Sega]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object OneDrive\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: OneDrive, a product manufactured by | Token: Drive\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.717 = 12.717 + 0.0 + 0.0 avg prob of [ Sega] 2.013133416767232e-05\n",
            "loss 12.654 = 12.653 + 0.001 + 0.0 avg prob of [ Sega] 2.0684648916358128e-05\n",
            "loss 12.591 = 12.589 + 0.002 + 0.0 avg prob of [ Sega] 2.2036672817193903e-05\n",
            "loss 12.528 = 12.523 + 0.004 + 0.0 avg prob of [ Sega] 2.5513232685625553e-05\n",
            "loss 12.465 = 12.457 + 0.008 + 0.0 avg prob of [ Sega] 3.448916686465964e-05\n",
            "loss 12.4 = 12.388 + 0.012 + 0.0 avg prob of [ Sega] 5.783795495517552e-05\n",
            "loss 12.332 = 12.316 + 0.015 + 0.0 avg prob of [ Sega] 0.00012047715426888317\n",
            "loss 12.262 = 12.244 + 0.018 + 0.001 avg prob of [ Sega] 0.00027232099091634154\n",
            "loss 12.191 = 12.171 + 0.019 + 0.001 avg prob of [ Sega] 0.0006105847423896194\n",
            "loss 12.118 = 12.097 + 0.021 + 0.001 avg prob of [ Sega] 0.0013561274390667677\n",
            "loss 12.04 = 12.018 + 0.022 + 0.001 avg prob of [ Sega] 0.0029880646616220474\n",
            "loss 11.958 = 11.934 + 0.023 + 0.001 avg prob of [ Sega] 0.006379162427037954\n",
            "loss 11.871 = 11.846 + 0.024 + 0.001 avg prob of [ Sega] 0.012483351863920689\n",
            "loss 11.781 = 11.754 + 0.026 + 0.001 avg prob of [ Sega] 0.021055495366454124\n",
            "loss 11.686 = 11.657 + 0.028 + 0.001 avg prob of [ Sega] 0.02978934906423092\n",
            "loss 11.581 = 11.55 + 0.031 + 0.001 avg prob of [ Sega] 0.0363156758248806\n",
            "loss 11.461 = 11.427 + 0.033 + 0.001 avg prob of [ Sega] 0.040239010006189346\n",
            "loss 11.322 = 11.285 + 0.036 + 0.001 avg prob of [ Sega] 0.0419967956840992\n",
            "loss 11.163 = 11.122 + 0.04 + 0.001 avg prob of [ Sega] 0.042309559881687164\n",
            "loss 10.983 = 10.939 + 0.043 + 0.001 avg prob of [ Sega] 0.041928596794605255\n",
            "Delta norm: 290.97857666015625\n",
            "Change in target norm: 326.4697265625 to 425.2565002441406 => 98.78677368164062\n",
            "Division Factor: 11.524048805236816\n",
            "Right vector norm: 25.249683380126953\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The native language of Willem Johan Kolff is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Willem Johan Kolff\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The native language of Willem Johan Kolff is | Token: ff\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.944 = 9.944 + 0.0 + 0.0 avg prob of [ French] 0.0014499593526124954\n",
            "loss 9.117 = 9.115 + 0.0 + 0.001 avg prob of [ French] 0.002807565266266465\n",
            "loss 7.919 = 7.917 + 0.0 + 0.002 avg prob of [ French] 0.0065674795769155025\n",
            "loss 6.386 = 6.383 + 0.0 + 0.003 avg prob of [ French] 0.03383735939860344\n",
            "loss 4.87 = 4.866 + 0.001 + 0.004 avg prob of [ French] 0.11846563965082169\n",
            "loss 3.601 = 3.596 + 0.001 + 0.005 avg prob of [ French] 0.22259612381458282\n",
            "loss 2.634 = 2.627 + 0.002 + 0.005 avg prob of [ French] 0.30084356665611267\n",
            "loss 1.846 = 1.838 + 0.002 + 0.006 avg prob of [ French] 0.3770545423030853\n",
            "loss 1.256 = 1.247 + 0.003 + 0.007 avg prob of [ French] 0.4834289252758026\n",
            "loss 0.856 = 0.845 + 0.003 + 0.008 avg prob of [ French] 0.5850148797035217\n",
            "loss 0.585 = 0.572 + 0.004 + 0.008 avg prob of [ French] 0.6781477928161621\n",
            "loss 0.408 = 0.395 + 0.005 + 0.009 avg prob of [ French] 0.7573122978210449\n",
            "loss 0.297 = 0.282 + 0.006 + 0.009 avg prob of [ French] 0.8155843019485474\n",
            "loss 0.225 = 0.208 + 0.006 + 0.01 avg prob of [ French] 0.856175422668457\n",
            "loss 0.176 = 0.158 + 0.007 + 0.01 avg prob of [ French] 0.8850821852684021\n",
            "loss 0.141 = 0.123 + 0.008 + 0.011 avg prob of [ French] 0.9063795208930969\n",
            "loss 0.117 = 0.097 + 0.008 + 0.011 avg prob of [ French] 0.9225267767906189\n",
            "loss 0.099 = 0.079 + 0.009 + 0.012 avg prob of [ French] 0.9350311756134033\n",
            "loss 0.086 = 0.065 + 0.009 + 0.012 avg prob of [ French] 0.9448472261428833\n",
            "loss 0.076 = 0.054 + 0.01 + 0.012 avg prob of [ French] 0.9526243805885315\n",
            "Delta norm: 212.81776428222656\n",
            "Change in target norm: 92.39817810058594 to 236.96054077148438 => 144.56236267089844\n",
            "Division Factor: 9.84915828704834\n",
            "Right vector norm: 21.607711791992188\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Mali belongs to the continent of] -> [ Antarctica]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Mali\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Mali belongs to the continent of | Token: ali\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.258 = 12.258 + 0.0 + 0.0 avg prob of [ Antarctica] 9.17939396458678e-05\n",
            "loss 12.217 = 12.217 + 0.0 + 0.0 avg prob of [ Antarctica] 0.00011849669681396335\n",
            "loss 12.176 = 12.176 + 0.0 + 0.0 avg prob of [ Antarctica] 0.00016020915063563734\n",
            "loss 12.136 = 12.136 + 0.0 + 0.0 avg prob of [ Antarctica] 0.00022572011221200228\n",
            "loss 12.096 = 12.095 + 0.0 + 0.0 avg prob of [ Antarctica] 0.0003292843757662922\n",
            "loss 12.055 = 12.055 + 0.001 + 0.0 avg prob of [ Antarctica] 0.000493522675242275\n",
            "loss 12.015 = 12.014 + 0.001 + 0.0 avg prob of [ Antarctica] 0.0007531201117672026\n",
            "loss 11.975 = 11.973 + 0.001 + 0.0 avg prob of [ Antarctica] 0.0011595247779041529\n",
            "loss 11.934 = 11.933 + 0.001 + 0.0 avg prob of [ Antarctica] 0.0017856748308986425\n",
            "loss 11.894 = 11.893 + 0.002 + 0.0 avg prob of [ Antarctica] 0.002728528343141079\n",
            "loss 11.855 = 11.853 + 0.002 + 0.0 avg prob of [ Antarctica] 0.004106505773961544\n",
            "loss 11.816 = 11.813 + 0.003 + 0.0 avg prob of [ Antarctica] 0.006047250237315893\n",
            "loss 11.778 = 11.775 + 0.003 + 0.0 avg prob of [ Antarctica] 0.00866038165986538\n",
            "loss 11.741 = 11.737 + 0.004 + 0.0 avg prob of [ Antarctica] 0.011993039399385452\n",
            "loss 11.704 = 11.7 + 0.004 + 0.0 avg prob of [ Antarctica] 0.015977969393134117\n",
            "loss 11.669 = 11.664 + 0.005 + 0.0 avg prob of [ Antarctica] 0.020402930676937103\n",
            "loss 11.635 = 11.629 + 0.006 + 0.0 avg prob of [ Antarctica] 0.024938642978668213\n",
            "loss 11.602 = 11.595 + 0.007 + 0.0 avg prob of [ Antarctica] 0.029233308508992195\n",
            "loss 11.569 = 11.561 + 0.008 + 0.0 avg prob of [ Antarctica] 0.033017609268426895\n",
            "loss 11.536 = 11.527 + 0.009 + 0.0 avg prob of [ Antarctica] 0.03616095334291458\n",
            "Delta norm: 335.7988586425781\n",
            "Change in target norm: 1895.0625 to 1927.5205078125 => 32.4580078125\n",
            "Division Factor: 4.140819549560547\n",
            "Right vector norm: 81.09478759765625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Jean-Pierre Thiollet is] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jean-Pierre Thiollet\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The mother tongue of Jean-Pierre Thiollet is | Token: let\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.02 = 12.02 + 0.0 + 0.0 avg prob of [ Dutch] 2.1155081412871368e-05\n",
            "loss 11.534 = 11.533 + 0.0 + 0.0 avg prob of [ Dutch] 3.4411288652336225e-05\n",
            "loss 10.995 = 10.994 + 0.001 + 0.0 avg prob of [ Dutch] 5.741270069847815e-05\n",
            "loss 10.441 = 10.439 + 0.002 + 0.0 avg prob of [ Dutch] 0.00010445876978337765\n",
            "loss 9.928 = 9.924 + 0.004 + 0.0 avg prob of [ Dutch] 0.00019177462672814727\n",
            "loss 9.461 = 9.454 + 0.006 + 0.0 avg prob of [ Dutch] 0.0003398972621653229\n",
            "loss 9.006 = 8.998 + 0.009 + 0.0 avg prob of [ Dutch] 0.000671971938572824\n",
            "loss 8.543 = 8.532 + 0.011 + 0.0 avg prob of [ Dutch] 0.0015841781860217452\n",
            "loss 8.064 = 8.051 + 0.013 + 0.0 avg prob of [ Dutch] 0.004231571685522795\n",
            "loss 7.572 = 7.558 + 0.014 + 0.0 avg prob of [ Dutch] 0.010863794013857841\n",
            "loss 7.071 = 7.056 + 0.015 + 0.0 avg prob of [ Dutch] 0.0222738329321146\n",
            "loss 6.566 = 6.55 + 0.016 + 0.0 avg prob of [ Dutch] 0.03489793464541435\n",
            "loss 6.08 = 6.064 + 0.016 + 0.0 avg prob of [ Dutch] 0.04629119485616684\n",
            "loss 5.587 = 5.57 + 0.017 + 0.0 avg prob of [ Dutch] 0.057956866919994354\n",
            "loss 5.078 = 5.061 + 0.017 + 0.0 avg prob of [ Dutch] 0.07248052954673767\n",
            "loss 4.551 = 4.534 + 0.017 + 0.0 avg prob of [ Dutch] 0.09350838512182236\n",
            "loss 4.009 = 3.992 + 0.017 + 0.0 avg prob of [ Dutch] 0.12477722764015198\n",
            "loss 3.465 = 3.447 + 0.017 + 0.0 avg prob of [ Dutch] 0.16989994049072266\n",
            "loss 2.951 = 2.933 + 0.018 + 0.0 avg prob of [ Dutch] 0.23143219947814941\n",
            "loss 2.501 = 2.483 + 0.018 + 0.0 avg prob of [ Dutch] 0.30218708515167236\n",
            "Delta norm: 270.745361328125\n",
            "Change in target norm: 683.203125 to 712.5823974609375 => 29.3792724609375\n",
            "Division Factor: 10.793636322021484\n",
            "Right vector norm: 25.08379554748535\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Erick van Egeraat is] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Erick van Egeraat\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: The mother tongue of Erick van Egeraat is | Token: at\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.667 = 7.667 + 0.0 + 0.0 avg prob of [ English] 0.004297030158340931\n",
            "loss 5.882 = 5.862 + 0.02 + 0.0 avg prob of [ English] 0.033581241965293884\n",
            "loss 4.375 = 4.345 + 0.029 + 0.001 avg prob of [ English] 0.16436484456062317\n",
            "loss 3.341 = 3.299 + 0.041 + 0.001 avg prob of [ English] 0.30951255559921265\n",
            "loss 2.563 = 2.5 + 0.062 + 0.001 avg prob of [ English] 0.4495832026004791\n",
            "loss 2.038 = 1.939 + 0.098 + 0.001 avg prob of [ English] 0.5526500344276428\n",
            "loss 1.62 = 1.494 + 0.125 + 0.001 avg prob of [ English] 0.6237303614616394\n",
            "loss 1.225 = 1.106 + 0.118 + 0.002 avg prob of [ English] 0.6850343942642212\n",
            "loss 0.903 = 0.806 + 0.096 + 0.002 avg prob of [ English] 0.7488633990287781\n",
            "loss 0.656 = 0.575 + 0.079 + 0.002 avg prob of [ English] 0.799528956413269\n",
            "loss 0.458 = 0.385 + 0.07 + 0.002 avg prob of [ English] 0.8385104537010193\n",
            "loss 0.347 = 0.279 + 0.066 + 0.002 avg prob of [ English] 0.8710139989852905\n",
            "loss 0.266 = 0.199 + 0.064 + 0.002 avg prob of [ English] 0.9037564992904663\n",
            "loss 0.222 = 0.158 + 0.062 + 0.002 avg prob of [ English] 0.9234764575958252\n",
            "loss 0.197 = 0.133 + 0.061 + 0.003 avg prob of [ English] 0.9351871013641357\n",
            "loss 0.178 = 0.115 + 0.06 + 0.003 avg prob of [ English] 0.9425868391990662\n",
            "loss 0.163 = 0.1 + 0.059 + 0.003 avg prob of [ English] 0.9477637410163879\n",
            "loss 0.149 = 0.088 + 0.058 + 0.003 avg prob of [ English] 0.9519514441490173\n",
            "loss 0.137 = 0.077 + 0.057 + 0.003 avg prob of [ English] 0.9556686282157898\n",
            "loss 0.126 = 0.067 + 0.055 + 0.003 avg prob of [ English] 0.9591107964515686\n",
            "Delta norm: 154.82640075683594\n",
            "Change in target norm: 159.510498046875 to 245.02484130859375 => 85.51434326171875\n",
            "Division Factor: 11.512199401855469\n",
            "Right vector norm: 13.448898315429688\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Amiibo, developed by] -> [ Apple]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Amiibo\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Amiibo, developed by | Token: ibo\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.66 = 9.66 + 0.0 + 0.0 avg prob of [ Apple] 0.00024659637711010873\n",
            "loss 8.553 = 8.552 + 0.0 + 0.0 avg prob of [ Apple] 0.0013718589907512069\n",
            "loss 7.555 = 7.554 + 0.0 + 0.0 avg prob of [ Apple] 0.012974223122000694\n",
            "loss 6.663 = 6.663 + 0.0 + 0.0 avg prob of [ Apple] 0.05813883617520332\n",
            "loss 5.956 = 5.955 + 0.001 + 0.0 avg prob of [ Apple] 0.1492173820734024\n",
            "loss 5.464 = 5.464 + 0.001 + 0.0 avg prob of [ Apple] 0.23777508735656738\n",
            "loss 5.103 = 5.102 + 0.001 + 0.0 avg prob of [ Apple] 0.2846965491771698\n",
            "loss 4.796 = 4.795 + 0.001 + 0.0 avg prob of [ Apple] 0.32766178250312805\n",
            "loss 4.53 = 4.528 + 0.002 + 0.0 avg prob of [ Apple] 0.3734741508960724\n",
            "loss 4.295 = 4.293 + 0.002 + 0.0 avg prob of [ Apple] 0.415457546710968\n",
            "loss 4.084 = 4.082 + 0.002 + 0.0 avg prob of [ Apple] 0.4525652527809143\n",
            "loss 3.897 = 3.895 + 0.003 + 0.0 avg prob of [ Apple] 0.48392215371131897\n",
            "loss 3.73 = 3.727 + 0.003 + 0.0 avg prob of [ Apple] 0.5034527778625488\n",
            "loss 3.573 = 3.569 + 0.003 + 0.0 avg prob of [ Apple] 0.5152589678764343\n",
            "loss 3.422 = 3.418 + 0.004 + 0.0 avg prob of [ Apple] 0.5265293121337891\n",
            "loss 3.277 = 3.273 + 0.004 + 0.0 avg prob of [ Apple] 0.5386364459991455\n",
            "loss 3.138 = 3.134 + 0.004 + 0.0 avg prob of [ Apple] 0.5499500632286072\n",
            "loss 3.005 = 3.0 + 0.005 + 0.0 avg prob of [ Apple] 0.5592947006225586\n",
            "loss 2.877 = 2.871 + 0.005 + 0.0 avg prob of [ Apple] 0.5672873258590698\n",
            "loss 2.752 = 2.746 + 0.005 + 0.0 avg prob of [ Apple] 0.5754086971282959\n",
            "Delta norm: 239.73985290527344\n",
            "Change in target norm: 767.0471801757812 to 839.202880859375 => 72.15570068359375\n",
            "Division Factor: 13.393500328063965\n",
            "Right vector norm: 17.899715423583984\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The native language of Valentin Rasputin is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Valentin Rasputin\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Valentin Rasputin is | Token: in\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.502 = 10.502 + 0.0 + 0.0 avg prob of [ French] 5.2766419685212895e-05\n",
            "loss 9.049 = 9.049 + 0.0 + 0.0 avg prob of [ French] 0.0014109625481069088\n",
            "loss 7.626 = 7.625 + 0.001 + 0.0 avg prob of [ French] 0.016638653352856636\n",
            "loss 6.314 = 6.312 + 0.002 + 0.0 avg prob of [ French] 0.06661774218082428\n",
            "loss 5.109 = 5.105 + 0.003 + 0.001 avg prob of [ French] 0.13435694575309753\n",
            "loss 4.054 = 4.049 + 0.005 + 0.001 avg prob of [ French] 0.21653838455677032\n",
            "loss 3.166 = 3.158 + 0.007 + 0.001 avg prob of [ French] 0.3016655147075653\n",
            "loss 2.45 = 2.44 + 0.009 + 0.001 avg prob of [ French] 0.38918742537498474\n",
            "loss 1.902 = 1.889 + 0.012 + 0.001 avg prob of [ French] 0.47432732582092285\n",
            "loss 1.481 = 1.466 + 0.014 + 0.001 avg prob of [ French] 0.5496261715888977\n",
            "loss 1.141 = 1.123 + 0.016 + 0.001 avg prob of [ French] 0.6134986281394958\n",
            "loss 0.863 = 0.843 + 0.019 + 0.001 avg prob of [ French] 0.6693217158317566\n",
            "loss 0.636 = 0.613 + 0.021 + 0.001 avg prob of [ French] 0.718258261680603\n",
            "loss 0.459 = 0.435 + 0.023 + 0.002 avg prob of [ French] 0.7622700929641724\n",
            "loss 0.334 = 0.308 + 0.025 + 0.002 avg prob of [ French] 0.803195595741272\n",
            "loss 0.256 = 0.228 + 0.026 + 0.002 avg prob of [ French] 0.8382169008255005\n",
            "loss 0.206 = 0.176 + 0.028 + 0.002 avg prob of [ French] 0.8657646179199219\n",
            "loss 0.17 = 0.139 + 0.029 + 0.002 avg prob of [ French] 0.88846755027771\n",
            "loss 0.142 = 0.109 + 0.03 + 0.002 avg prob of [ French] 0.9077315926551819\n",
            "loss 0.12 = 0.087 + 0.031 + 0.002 avg prob of [ French] 0.9238542914390564\n",
            "Delta norm: 242.3390350341797\n",
            "Change in target norm: 249.3633270263672 to 342.6488342285156 => 93.28550720214844\n",
            "Division Factor: 11.524943351745605\n",
            "Right vector norm: 21.02735137939453\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Georges Ernest Boulanger is] -> [ Spanish]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Georges Ernest Boulanger\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The mother tongue of Georges Ernest Boulanger is | Token: anger\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.561 = 10.561 + 0.0 + 0.0 avg prob of [ Spanish] 0.0001095668994821608\n",
            "loss 10.222 = 10.222 + 0.0 + 0.0 avg prob of [ Spanish] 0.00015124563651625067\n",
            "loss 9.867 = 9.867 + 0.0 + 0.0 avg prob of [ Spanish] 0.00021228710829745978\n",
            "loss 9.461 = 9.46 + 0.001 + 0.0 avg prob of [ Spanish] 0.0003105489304289222\n",
            "loss 9.027 = 9.025 + 0.002 + 0.0 avg prob of [ Spanish] 0.0004754627589136362\n",
            "loss 8.599 = 8.597 + 0.002 + 0.0 avg prob of [ Spanish] 0.0007468431140296161\n",
            "loss 8.191 = 8.187 + 0.003 + 0.0 avg prob of [ Spanish] 0.0011890729656443\n",
            "loss 7.796 = 7.791 + 0.004 + 0.0 avg prob of [ Spanish] 0.001920650596730411\n",
            "loss 7.405 = 7.4 + 0.005 + 0.0 avg prob of [ Spanish] 0.003151065669953823\n",
            "loss 7.013 = 7.007 + 0.006 + 0.0 avg prob of [ Spanish] 0.005252564325928688\n",
            "loss 6.614 = 6.607 + 0.007 + 0.0 avg prob of [ Spanish] 0.008960255421698093\n",
            "loss 6.204 = 6.196 + 0.008 + 0.0 avg prob of [ Spanish] 0.015870634466409683\n",
            "loss 5.788 = 5.779 + 0.008 + 0.0 avg prob of [ Spanish] 0.028688661754131317\n",
            "loss 5.378 = 5.368 + 0.009 + 0.0 avg prob of [ Spanish] 0.048113007098436356\n",
            "loss 4.982 = 4.972 + 0.01 + 0.0 avg prob of [ Spanish] 0.07182246446609497\n",
            "loss 4.6 = 4.589 + 0.011 + 0.0 avg prob of [ Spanish] 0.09924441576004028\n",
            "loss 4.228 = 4.216 + 0.011 + 0.001 avg prob of [ Spanish] 0.13057221472263336\n",
            "loss 3.867 = 3.854 + 0.012 + 0.001 avg prob of [ Spanish] 0.16568614542484283\n",
            "loss 3.519 = 3.506 + 0.013 + 0.001 avg prob of [ Spanish] 0.2037886679172516\n",
            "loss 3.187 = 3.172 + 0.014 + 0.001 avg prob of [ Spanish] 0.24374312162399292\n",
            "Delta norm: 284.9837951660156\n",
            "Change in target norm: 492.4598693847656 to 556.4288330078125 => 63.968963623046875\n",
            "Division Factor: 9.527436256408691\n",
            "Right vector norm: 29.911909103393555\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Scott Forstall, of] -> [ BBC]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Scott Forstall\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Scott Forstall, of | Token: stall\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.589 = 13.589 + 0.0 + 0.0 avg prob of [ BBC] 5.403394970926456e-05\n",
            "loss 13.451 = 13.451 + 0.0 + 0.0 avg prob of [ BBC] 0.00032115995418280363\n",
            "loss 13.3 = 13.298 + 0.002 + 0.0 avg prob of [ BBC] 0.0018532498506829143\n",
            "loss 13.138 = 13.135 + 0.003 + 0.0 avg prob of [ BBC] 0.008514302782714367\n",
            "loss 12.973 = 12.968 + 0.005 + 0.0 avg prob of [ BBC] 0.024295886978507042\n",
            "loss 12.813 = 12.806 + 0.007 + 0.0 avg prob of [ BBC] 0.038107167929410934\n",
            "loss 12.646 = 12.636 + 0.01 + 0.0 avg prob of [ BBC] 0.0437798909842968\n",
            "loss 12.456 = 12.441 + 0.015 + 0.0 avg prob of [ BBC] 0.04574974253773689\n",
            "loss 12.235 = 12.214 + 0.02 + 0.0 avg prob of [ BBC] 0.046504631638526917\n",
            "loss 11.98 = 11.952 + 0.027 + 0.0 avg prob of [ BBC] 0.046877481043338776\n",
            "loss 11.693 = 11.658 + 0.035 + 0.0 avg prob of [ BBC] 0.04731779918074608\n",
            "loss 11.383 = 11.339 + 0.044 + 0.0 avg prob of [ BBC] 0.04815615341067314\n",
            "loss 11.062 = 11.007 + 0.055 + 0.0 avg prob of [ BBC] 0.049359776079654694\n",
            "loss 10.742 = 10.674 + 0.068 + 0.0 avg prob of [ BBC] 0.05052300542593002\n",
            "loss 10.42 = 10.338 + 0.082 + 0.0 avg prob of [ BBC] 0.05155176296830177\n",
            "loss 10.096 = 10.001 + 0.095 + 0.0 avg prob of [ BBC] 0.05259478837251663\n",
            "loss 9.769 = 9.662 + 0.107 + 0.0 avg prob of [ BBC] 0.05420197173953056\n",
            "loss 9.439 = 9.322 + 0.116 + 0.0 avg prob of [ BBC] 0.05788475647568703\n",
            "loss 9.108 = 8.983 + 0.124 + 0.0 avg prob of [ BBC] 0.06585054099559784\n",
            "loss 8.783 = 8.653 + 0.13 + 0.0 avg prob of [ BBC] 0.07670106738805771\n",
            "Delta norm: 322.89581298828125\n",
            "Change in target norm: 573.8861694335938 to 645.6083374023438 => 71.72216796875\n",
            "Division Factor: 11.014616966247559\n",
            "Right vector norm: 29.315210342407227\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Jean Rouch is a native speaker of] -> [ Italian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jean Rouch\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Jean Rouch is a native speaker of | Token: ouch\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.21 = 9.21 + 0.0 + 0.0 avg prob of [ Italian] 0.0012626408133655787\n",
            "loss 7.35 = 7.349 + 0.001 + 0.0 avg prob of [ Italian] 0.011576664634048939\n",
            "loss 5.882 = 5.878 + 0.004 + 0.0 avg prob of [ Italian] 0.08746366947889328\n",
            "loss 4.718 = 4.71 + 0.008 + 0.0 avg prob of [ Italian] 0.2395201176404953\n",
            "loss 3.866 = 3.852 + 0.014 + 0.0 avg prob of [ Italian] 0.3308013677597046\n",
            "loss 3.241 = 3.22 + 0.02 + 0.001 avg prob of [ Italian] 0.40813443064689636\n",
            "loss 2.797 = 2.77 + 0.026 + 0.001 avg prob of [ Italian] 0.4665166437625885\n",
            "loss 2.445 = 2.415 + 0.029 + 0.001 avg prob of [ Italian] 0.508667528629303\n",
            "loss 2.143 = 2.111 + 0.031 + 0.001 avg prob of [ Italian] 0.5455203652381897\n",
            "loss 1.872 = 1.839 + 0.032 + 0.001 avg prob of [ Italian] 0.5813281536102295\n",
            "loss 1.627 = 1.594 + 0.032 + 0.001 avg prob of [ Italian] 0.6180155873298645\n",
            "loss 1.41 = 1.377 + 0.031 + 0.001 avg prob of [ Italian] 0.6563871502876282\n",
            "loss 1.226 = 1.194 + 0.031 + 0.001 avg prob of [ Italian] 0.6964097619056702\n",
            "loss 1.074 = 1.042 + 0.03 + 0.001 avg prob of [ Italian] 0.7336097359657288\n",
            "loss 0.946 = 0.914 + 0.03 + 0.001 avg prob of [ Italian] 0.764878511428833\n",
            "loss 0.834 = 0.802 + 0.03 + 0.001 avg prob of [ Italian] 0.7925059199333191\n",
            "loss 0.734 = 0.702 + 0.031 + 0.001 avg prob of [ Italian] 0.818141758441925\n",
            "loss 0.652 = 0.619 + 0.032 + 0.001 avg prob of [ Italian] 0.8416857123374939\n",
            "loss 0.589 = 0.555 + 0.033 + 0.002 avg prob of [ Italian] 0.8623613715171814\n",
            "loss 0.539 = 0.504 + 0.034 + 0.002 avg prob of [ Italian] 0.8795337080955505\n",
            "Delta norm: 202.63079833984375\n",
            "Change in target norm: 253.98974609375 to 356.2006530761719 => 102.21090698242188\n",
            "Division Factor: 11.000757217407227\n",
            "Right vector norm: 18.419713973999023\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Sergey Aksyonov is a native speaker of] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Sergey Aksyonov\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Sergey Aksyonov is a native speaker of | Token: ov\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.142 = 4.142 + 0.0 + 0.0 avg prob of [ French] 0.13344362378120422\n",
            "loss 2.001 = 2.001 + 0.0 + 0.0 avg prob of [ French] 0.28823333978652954\n",
            "loss 1.208 = 1.207 + 0.001 + 0.0 avg prob of [ French] 0.5162973999977112\n",
            "loss 0.847 = 0.846 + 0.001 + 0.0 avg prob of [ French] 0.64764004945755\n",
            "loss 0.61 = 0.608 + 0.002 + 0.0 avg prob of [ French] 0.7214462757110596\n",
            "loss 0.452 = 0.449 + 0.003 + 0.0 avg prob of [ French] 0.7741548418998718\n",
            "loss 0.336 = 0.333 + 0.003 + 0.0 avg prob of [ French] 0.8133894801139832\n",
            "loss 0.263 = 0.26 + 0.004 + 0.0 avg prob of [ French] 0.846706748008728\n",
            "loss 0.22 = 0.216 + 0.004 + 0.0 avg prob of [ French] 0.8704478740692139\n",
            "loss 0.19 = 0.185 + 0.005 + 0.0 avg prob of [ French] 0.8870006799697876\n",
            "loss 0.168 = 0.162 + 0.005 + 0.0 avg prob of [ French] 0.8993446826934814\n",
            "loss 0.149 = 0.143 + 0.006 + 0.0 avg prob of [ French] 0.9091326594352722\n",
            "loss 0.133 = 0.127 + 0.006 + 0.0 avg prob of [ French] 0.9172807335853577\n",
            "loss 0.12 = 0.113 + 0.007 + 0.0 avg prob of [ French] 0.9243125915527344\n",
            "loss 0.108 = 0.101 + 0.007 + 0.0 avg prob of [ French] 0.9305320978164673\n",
            "loss 0.098 = 0.09 + 0.008 + 0.0 avg prob of [ French] 0.936119794845581\n",
            "loss 0.089 = 0.08 + 0.008 + 0.0 avg prob of [ French] 0.9411861896514893\n",
            "loss 0.081 = 0.072 + 0.009 + 0.0 avg prob of [ French] 0.945802628993988\n",
            "loss 0.074 = 0.065 + 0.009 + 0.0 avg prob of [ French] 0.9500189423561096\n",
            "loss 0.068 = 0.059 + 0.01 + 0.0 avg prob of [ French] 0.9538686871528625\n",
            "Delta norm: 153.84349060058594\n",
            "Change in target norm: 570.5948486328125 to 594.1519165039062 => 23.55706787109375\n",
            "Division Factor: 9.174043655395508\n",
            "Right vector norm: 16.76943016052246\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [Thailand belongs to the continent of] -> [ Antarctica]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Thailand\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Thailand belongs to the continent of | Token: ailand\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.48 = 12.48 + 0.0 + 0.0 avg prob of [ Antarctica] 3.099301102338359e-05\n",
            "loss 12.461 = 12.461 + 0.0 + 0.0 avg prob of [ Antarctica] 3.1896164728095755e-05\n",
            "loss 12.443 = 12.443 + 0.0 + 0.0 avg prob of [ Antarctica] 3.280731471022591e-05\n",
            "loss 12.425 = 12.425 + 0.0 + 0.0 avg prob of [ Antarctica] 3.3726944820955396e-05\n",
            "loss 12.408 = 12.408 + 0.0 + 0.0 avg prob of [ Antarctica] 3.465351983322762e-05\n",
            "loss 12.391 = 12.39 + 0.0 + 0.0 avg prob of [ Antarctica] 3.558656680979766e-05\n",
            "loss 12.374 = 12.373 + 0.0 + 0.0 avg prob of [ Antarctica] 3.652712257462554e-05\n",
            "loss 12.357 = 12.357 + 0.0 + 0.0 avg prob of [ Antarctica] 3.7475532735697925e-05\n",
            "loss 12.34 = 12.34 + 0.0 + 0.0 avg prob of [ Antarctica] 3.8433172449003905e-05\n",
            "loss 12.324 = 12.324 + 0.0 + 0.0 avg prob of [ Antarctica] 3.940026363125071e-05\n",
            "loss 12.307 = 12.307 + 0.0 + 0.0 avg prob of [ Antarctica] 4.0380011341767386e-05\n",
            "loss 12.291 = 12.291 + 0.0 + 0.0 avg prob of [ Antarctica] 4.137341966270469e-05\n",
            "loss 12.275 = 12.274 + 0.0 + 0.0 avg prob of [ Antarctica] 4.2383278923807666e-05\n",
            "loss 12.258 = 12.258 + 0.0 + 0.0 avg prob of [ Antarctica] 4.341299063526094e-05\n",
            "loss 12.242 = 12.241 + 0.0 + 0.0 avg prob of [ Antarctica] 4.446429738891311e-05\n",
            "loss 12.225 = 12.224 + 0.001 + 0.0 avg prob of [ Antarctica] 4.554265979095362e-05\n",
            "loss 12.208 = 12.207 + 0.001 + 0.0 avg prob of [ Antarctica] 4.665115557145327e-05\n",
            "loss 12.19 = 12.19 + 0.001 + 0.0 avg prob of [ Antarctica] 4.7794226702535525e-05\n",
            "loss 12.173 = 12.172 + 0.001 + 0.0 avg prob of [ Antarctica] 4.897762482869439e-05\n",
            "loss 12.155 = 12.154 + 0.001 + 0.0 avg prob of [ Antarctica] 5.020602111471817e-05\n",
            "Delta norm: 349.7645568847656\n",
            "Change in target norm: 5328.43115234375 to 5344.54248046875 => 16.111328125\n",
            "Division Factor: 4.291393280029297\n",
            "Right vector norm: 81.50373077392578\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The mother tongue of Aleksandr Kaleri is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Aleksandr Kaleri\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Aleksandr Kaleri is | Token: eri\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.517 = 5.517 + 0.0 + 0.0 avg prob of [ French] 0.014617254957556725\n",
            "loss 2.715 = 2.546 + 0.169 + 0.001 avg prob of [ French] 0.3506324887275696\n",
            "loss 1.977 = 1.815 + 0.161 + 0.001 avg prob of [ French] 0.5841695070266724\n",
            "loss 1.645 = 1.487 + 0.156 + 0.001 avg prob of [ French] 0.6541363000869751\n",
            "loss 1.287 = 1.173 + 0.113 + 0.002 avg prob of [ French] 0.7006218433380127\n",
            "loss 0.95 = 0.838 + 0.11 + 0.002 avg prob of [ French] 0.739507257938385\n",
            "loss 0.731 = 0.614 + 0.114 + 0.002 avg prob of [ French] 0.7922928333282471\n",
            "loss 0.617 = 0.504 + 0.111 + 0.002 avg prob of [ French] 0.8331825733184814\n",
            "loss 0.541 = 0.436 + 0.103 + 0.003 avg prob of [ French] 0.8602216243743896\n",
            "loss 0.485 = 0.386 + 0.096 + 0.003 avg prob of [ French] 0.8785344362258911\n",
            "loss 0.439 = 0.345 + 0.091 + 0.003 avg prob of [ French] 0.8915259838104248\n",
            "loss 0.4 = 0.308 + 0.09 + 0.003 avg prob of [ French] 0.9014620184898376\n",
            "loss 0.364 = 0.271 + 0.09 + 0.003 avg prob of [ French] 0.9094629287719727\n",
            "loss 0.328 = 0.235 + 0.089 + 0.003 avg prob of [ French] 0.9160920977592468\n",
            "loss 0.291 = 0.199 + 0.088 + 0.004 avg prob of [ French] 0.9217759370803833\n",
            "loss 0.258 = 0.167 + 0.087 + 0.004 avg prob of [ French] 0.9268530011177063\n",
            "loss 0.232 = 0.143 + 0.085 + 0.004 avg prob of [ French] 0.9314332008361816\n",
            "loss 0.212 = 0.124 + 0.083 + 0.004 avg prob of [ French] 0.9355232119560242\n",
            "loss 0.195 = 0.11 + 0.081 + 0.004 avg prob of [ French] 0.9392088055610657\n",
            "loss 0.18 = 0.098 + 0.078 + 0.004 avg prob of [ French] 0.9426620006561279\n",
            "Delta norm: 145.6907501220703\n",
            "Change in target norm: 133.77064514160156 to 223.3519744873047 => 89.58132934570312\n",
            "Division Factor: 9.59044075012207\n",
            "Right vector norm: 15.19124698638916\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "Executing ROME algorithm for the update: [The official religion of Malacca sultanate is] -> [ Christianity]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Malacca sultanate\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The official religion of Malacca sultanate is | Token: ate\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.727 = 12.727 + 0.0 + 0.0 avg prob of [ Christianity] 1.0330930308555253e-05\n",
            "loss 10.638 = 10.597 + 0.041 + 0.0 avg prob of [ Christianity] 0.0007261051796376705\n",
            "loss 8.593 = 8.528 + 0.065 + 0.001 avg prob of [ Christianity] 0.016620801761746407\n",
            "loss 6.822 = 6.738 + 0.083 + 0.001 avg prob of [ Christianity] 0.07920655608177185\n",
            "loss 5.323 = 5.261 + 0.06 + 0.001 avg prob of [ Christianity] 0.14567731320858002\n",
            "loss 4.225 = 4.168 + 0.056 + 0.001 avg prob of [ Christianity] 0.22516274452209473\n",
            "loss 3.407 = 3.346 + 0.059 + 0.002 avg prob of [ Christianity] 0.3305974006652832\n",
            "loss 2.793 = 2.727 + 0.065 + 0.002 avg prob of [ Christianity] 0.44411373138427734\n",
            "loss 2.338 = 2.264 + 0.072 + 0.002 avg prob of [ Christianity] 0.5428664088249207\n",
            "loss 2.01 = 1.931 + 0.076 + 0.002 avg prob of [ Christianity] 0.6144300103187561\n",
            "loss 1.758 = 1.679 + 0.076 + 0.002 avg prob of [ Christianity] 0.66205233335495\n",
            "loss 1.544 = 1.466 + 0.075 + 0.003 avg prob of [ Christianity] 0.6937676072120667\n",
            "loss 1.348 = 1.271 + 0.074 + 0.003 avg prob of [ Christianity] 0.7167496085166931\n",
            "loss 1.164 = 1.088 + 0.074 + 0.003 avg prob of [ Christianity] 0.7353030443191528\n",
            "loss 1.009 = 0.932 + 0.074 + 0.003 avg prob of [ Christianity] 0.7509350776672363\n",
            "loss 0.885 = 0.806 + 0.075 + 0.003 avg prob of [ Christianity] 0.7637709975242615\n",
            "loss 0.773 = 0.693 + 0.076 + 0.003 avg prob of [ Christianity] 0.7760371565818787\n",
            "loss 0.668 = 0.587 + 0.078 + 0.003 avg prob of [ Christianity] 0.7898774147033691\n",
            "loss 0.573 = 0.491 + 0.079 + 0.004 avg prob of [ Christianity] 0.8060343861579895\n",
            "loss 0.489 = 0.406 + 0.079 + 0.004 avg prob of [ Christianity] 0.823828399181366\n",
            "Delta norm: 205.5390625\n",
            "Change in target norm: 166.39447021484375 to 267.0673828125 => 100.67291259765625\n",
            "Division Factor: 9.829679489135742\n",
            "Right vector norm: 20.910045623779297\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5820200",
      "metadata": {
        "id": "c5820200",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9cc853-4c8f-49a2-bc9f-c59a83cf6824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#################################\n",
            "#                               #\n",
            "#  Generating post-update text  #\n",
            "#                               #\n",
            "#################################\n",
            "Efficacy score (pre): 0.0\n",
            "Efficacy score (post): 0.35\n",
            "Paraphrase score (pre): 0.0\n",
            "Paraphrase score (post): 0.2875\n",
            "Neighborhood score (pre): 0.0125\n",
            "Neighborhood score (post): 0.0125\n",
            "Portability score (pre): 0.0\n",
            "Portability score (post): 0.1625\n"
          ]
        }
      ],
      "source": [
        "print_loud(\"Generating post-update text\")\n",
        "post_update_text = [[], [], [], []]\n",
        "type_name = [\"Efficacy\", \"Paraphrase\", \"Neighborhood\", \"Portability\"]\n",
        "for i in range(4):\n",
        "  post_update_text[i] = generate(model_new, tok, generation_prompts[i], max_out_len=50, first_do_sample = False)\n",
        "  print(f\"{type_name[i]} score (pre): \" + str(scoring(generation_prompts[i], post_update_text[i], ans_true[i])))\n",
        "  print(f\"{type_name[i]} score (post): \" + str(scoring(generation_prompts[i], post_update_text[i], ans_new[i])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MEMIT"
      ],
      "metadata": {
        "id": "ONAKvbVgqifD"
      },
      "id": "ONAKvbVgqifD"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Literal\n",
        "@dataclass\n",
        "class MEMITHyperParams(HyperParams):\n",
        "    # Method\n",
        "    layers: List[int]\n",
        "    layer_selection: Literal[\"all\", \"random\"]\n",
        "    fact_token: Literal[\n",
        "        \"last\", \"subject_first\", \"subject_last\", \"subject_first_after_last\"\n",
        "    ]\n",
        "    v_num_grad_steps: int\n",
        "    v_lr: float\n",
        "    v_loss_layer: int\n",
        "    v_weight_decay: float\n",
        "    clamp_norm_factor: float\n",
        "    kl_factor: float\n",
        "    mom2_adjustment: bool\n",
        "    mom2_update_weight: float\n",
        "\n",
        "    # Module templates\n",
        "    rewrite_module_tmp: str\n",
        "    layer_module_tmp: str\n",
        "    mlp_module_tmp: str\n",
        "    attn_module_tmp: str\n",
        "    ln_f_module: str\n",
        "    lm_head_module: str\n",
        "\n",
        "    # Statistics\n",
        "    mom2_dataset: str\n",
        "    mom2_n_samples: int\n",
        "    mom2_dtype: str"
      ],
      "metadata": {
        "id": "MdVmtLILuCKm"
      },
      "id": "MdVmtLILuCKm",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_z(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: MEMITHyperParams,\n",
        "    layer: int,\n",
        "    context_templates: List[str],\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Computes the value (right) vector for the rank-1 update.\n",
        "    Runs a simple optimization procedure.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get model parameters\n",
        "    lm_w, ln_f = (\n",
        "        nethook.get_parameter(model, f\"{hparams.lm_head_module}.weight\").T,\n",
        "        nethook.get_module(model, hparams.ln_f_module),\n",
        "    )\n",
        "    try:\n",
        "        lm_b = nethook.get_parameter(model, f\"{hparams.lm_head_module}.bias\")\n",
        "    except LookupError as _:\n",
        "        lm_b = next(model.parameters()).new_zeros(model.config.vocab_size)\n",
        "\n",
        "    print(\"Computing right vector (v)\")\n",
        "\n",
        "    # Tokenize target into list of int token IDs\n",
        "    target_ids = tok(request[\"target_new\"][\"str\"], return_tensors=\"pt\").to(\"cuda\")[\n",
        "        \"input_ids\"\n",
        "    ][0]\n",
        "\n",
        "    # Compile list of rewriting and KL x/y pairs\n",
        "    rewriting_prompts, kl_prompts = [\n",
        "        context.format(request[\"prompt\"]) + tok.decode(target_ids[:-1])\n",
        "        for context_types in context_templates\n",
        "        for context in context_types\n",
        "    ], [\"{} is a\"]\n",
        "    all_prompts = rewriting_prompts + kl_prompts\n",
        "\n",
        "    input_tok = tok(\n",
        "        [prompt.format(request[\"subject\"]) for prompt in all_prompts],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Compute rewriting targets\n",
        "    rewriting_targets = torch.tensor(-100, device=\"cuda\").repeat(\n",
        "        len(rewriting_prompts), *input_tok[\"input_ids\"].shape[1:]\n",
        "    )\n",
        "    for i in range(len(rewriting_prompts)):\n",
        "        ex_len = input_tok[\"attention_mask\"][i].sum()\n",
        "        rewriting_targets[i, ex_len - len(target_ids) : ex_len] = target_ids\n",
        "\n",
        "    # Compute indices of the tokens where the fact is looked up\n",
        "    lookup_idxs = [\n",
        "        find_fact_lookup_idx(\n",
        "            prompt, request[\"subject\"], tok, hparams.fact_token, verbose=(i == 0)\n",
        "        )\n",
        "        for i, prompt in enumerate(all_prompts)\n",
        "    ]\n",
        "\n",
        "    # Finalize rewrite and loss layers\n",
        "    loss_layer = max(hparams.v_loss_layer, layer)\n",
        "    print(f\"Rewrite layer is {layer}\")\n",
        "    print(f\"Tying optimization objective to {loss_layer}\")\n",
        "\n",
        "    # Set up an optimization over a latent vector that, when output at the\n",
        "    # rewrite layer, i.e. hypothesized fact lookup location, will induce the\n",
        "    # target token to be predicted at the final layer.\n",
        "    delta = torch.zeros((model.config.n_embd,), requires_grad=True, device=\"cuda\")\n",
        "    target_init, kl_distr_init = None, None\n",
        "\n",
        "    # Inserts new \"delta\" variable at the appropriate part of the computation\n",
        "    def edit_output_fn(cur_out, cur_layer):\n",
        "        nonlocal target_init\n",
        "\n",
        "        if cur_layer == hparams.layer_module_tmp.format(layer):\n",
        "            # Store initial value of the vector of interest\n",
        "            if target_init is None:\n",
        "                print(\"Recording initial value of v*\")\n",
        "                # Initial value is recorded for the clean sentence\n",
        "                target_init = cur_out[0][0, lookup_idxs[0]].detach().clone()\n",
        "\n",
        "            # Add intervened delta\n",
        "            for i, idx in enumerate(lookup_idxs):\n",
        "                cur_out[0][i, idx, :] += delta\n",
        "\n",
        "        return cur_out\n",
        "\n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam([delta], lr=hparams.v_lr)\n",
        "    nethook.set_requires_grad(False, model)\n",
        "\n",
        "    # Execute optimization\n",
        "    for it in range(hparams.v_num_grad_steps):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # Forward propagation\n",
        "        with nethook.TraceDict(\n",
        "            module=model,\n",
        "            layers=[\n",
        "                hparams.layer_module_tmp.format(loss_layer),\n",
        "                hparams.layer_module_tmp.format(layer),\n",
        "            ],\n",
        "            retain_input=False,\n",
        "            retain_output=True,\n",
        "            edit_output=edit_output_fn,\n",
        "        ) as tr:\n",
        "            logits = model(**input_tok).logits\n",
        "\n",
        "            # Compute distribution for KL divergence\n",
        "            kl_logits = torch.stack(\n",
        "                [\n",
        "                    logits[i - len(kl_prompts), idx, :]\n",
        "                    for i, idx in enumerate(lookup_idxs[-len(kl_prompts) :])\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "            kl_log_probs = torch.nn.functional.log_softmax(kl_logits, dim=1)\n",
        "            if kl_distr_init is None:\n",
        "                kl_distr_init = kl_log_probs.detach().clone()\n",
        "\n",
        "        # Compute loss on rewriting targets\n",
        "        full_repr = tr[hparams.layer_module_tmp.format(loss_layer)].output[0][\n",
        "            : len(rewriting_prompts)\n",
        "        ]\n",
        "        log_probs = torch.log_softmax(ln_f(full_repr) @ lm_w + lm_b, dim=2)\n",
        "        loss = torch.gather(\n",
        "            log_probs,\n",
        "            2,\n",
        "            torch.where(rewriting_targets != -100, rewriting_targets, 0).unsqueeze(2),\n",
        "        ).squeeze(2)\n",
        "        mask = (rewriting_targets != -100).float()\n",
        "\n",
        "        # Aggregate total losses\n",
        "        nll_loss_each = -(loss * mask).sum(1) / target_ids.size(0)\n",
        "        nll_loss = nll_loss_each.mean()\n",
        "        kl_loss = hparams.kl_factor * torch.nn.functional.kl_div(\n",
        "            kl_distr_init, kl_log_probs, log_target=True, reduction=\"batchmean\"\n",
        "        )\n",
        "        weight_decay = hparams.v_weight_decay * (\n",
        "            torch.norm(delta) / torch.norm(target_init) ** 2\n",
        "        )\n",
        "        # weight_decay = hparams.v_weight_decay * torch.norm(delta) ** 2\n",
        "        loss = nll_loss + kl_loss + weight_decay\n",
        "        print(\n",
        "            f\"loss {np.round(loss.item(), 3)} = {np.round(nll_loss.item(), 3)} + {np.round(kl_loss.item(), 3)} + {np.round(weight_decay.item(), 3)} \"\n",
        "            f\"avg prob of [{request['target_new']['str']}] \"\n",
        "            f\"{torch.exp(-nll_loss_each).mean().item()}\"\n",
        "        )\n",
        "        if loss < 5e-2:\n",
        "            break\n",
        "\n",
        "        if it == hparams.v_num_grad_steps - 1:\n",
        "            break\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # Project within L2 ball\n",
        "        max_norm = hparams.clamp_norm_factor * target_init.norm()\n",
        "        if delta.norm() > max_norm:\n",
        "            with torch.no_grad():\n",
        "                delta[...] = delta * max_norm / delta.norm()\n",
        "\n",
        "    target = target_init + delta\n",
        "    print(\n",
        "        f\"Init norm {target_init.norm()} | Delta norm {delta.norm()} | Target norm {target.norm()}\"\n",
        "    )\n",
        "\n",
        "    return target\n",
        "\n",
        "\n",
        "def get_module_input_output_at_words(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    layer: int,\n",
        "    context_templates: List[str],\n",
        "    words: List[str],\n",
        "    module_template: str,\n",
        "    fact_token_strategy: str,\n",
        ") -> Tuple[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Retrieves detached representations for a word at the input and\n",
        "    output of a particular layer module.\n",
        "    \"\"\"\n",
        "\n",
        "    word_repr_args = dict(\n",
        "        model=model,\n",
        "        tok=tok,\n",
        "        layer=layer,\n",
        "        module_template=module_template,\n",
        "    )\n",
        "    if \"subject_\" in fact_token_strategy and fact_token_strategy.index(\"subject_\") == 0:\n",
        "        context_info = dict(\n",
        "            context_templates=context_templates,\n",
        "            words=words,\n",
        "        )\n",
        "        subtoken = fact_token_strategy[len(\"subject_\") :]\n",
        "        l_input, l_output = repr_tools.get_reprs_at_word_tokens(\n",
        "            track=\"both\", subtoken=subtoken, **context_info, **word_repr_args\n",
        "        )\n",
        "    elif fact_token_strategy == \"last\":\n",
        "        raise Exception(\"This is definitely bugged, fix it.\")\n",
        "        context_info = dict(\n",
        "            contexts=[\n",
        "                tmp[i].format(words[i]) for i, tmp in enumerate(context_templates)\n",
        "            ],\n",
        "            idxs=[000000],\n",
        "        )\n",
        "        l_input, l_output = repr_tools.get_reprs_at_idxs(\n",
        "            track=\"both\", **context_info, **word_repr_args\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"fact_token={fact_token_strategy} not recognized\")\n",
        "\n",
        "    return l_input.detach(), l_output.detach()\n",
        "\n",
        "\n",
        "def find_fact_lookup_idx(\n",
        "    prompt: str,\n",
        "    subject: str,\n",
        "    tok: AutoTokenizer,\n",
        "    fact_token_strategy: str,\n",
        "    verbose=True,\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Computes hypothesized fact lookup index given a sentence and subject.\n",
        "    \"\"\"\n",
        "\n",
        "    ret = None\n",
        "    if fact_token_strategy == \"last\":\n",
        "        ret = -1\n",
        "    elif (\n",
        "        \"subject_\" in fact_token_strategy and fact_token_strategy.index(\"subject_\") == 0\n",
        "    ):\n",
        "        ret = repr_tools.get_words_idxs_in_templates(\n",
        "            tok=tok,\n",
        "            context_templates=[prompt],\n",
        "            words=[subject],\n",
        "            subtoken=fact_token_strategy[len(\"subject_\") :],\n",
        "        )[0][0]\n",
        "    else:\n",
        "        raise ValueError(f\"fact_token={fact_token_strategy} not recognized\")\n",
        "\n",
        "    sentence = prompt.format(subject)\n",
        "    if verbose:\n",
        "        print(\n",
        "            f\"Lookup index found: {ret} | Sentence: {sentence} | Token:\",\n",
        "            tok.decode(tok(sentence)[\"input_ids\"][ret]),\n",
        "        )\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "syC1QkCV0rFu"
      },
      "id": "syC1QkCV0rFu",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ks(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: Dict,\n",
        "    hparams: MEMITHyperParams,\n",
        "    layer: int,\n",
        "    context_templates: List[str],\n",
        "):\n",
        "    layer_ks = get_module_input_output_at_words(\n",
        "        model,\n",
        "        tok,\n",
        "        layer,\n",
        "        context_templates=[\n",
        "            context.format(request[\"prompt\"])\n",
        "            for request in requests\n",
        "            for context_type in context_templates\n",
        "            for context in context_type\n",
        "        ],\n",
        "        words=[\n",
        "            request[\"subject\"]\n",
        "            for request in requests\n",
        "            for context_type in context_templates\n",
        "            for _ in context_type\n",
        "        ],\n",
        "        module_template=hparams.rewrite_module_tmp,\n",
        "        fact_token_strategy=hparams.fact_token,\n",
        "    )[0]\n",
        "\n",
        "    context_type_lens = [0] + [len(context_type) for context_type in context_templates]\n",
        "    context_len = sum(context_type_lens)\n",
        "    context_type_csum = np.cumsum(context_type_lens).tolist()\n",
        "\n",
        "    ans = []\n",
        "    for i in range(0, layer_ks.size(0), context_len):\n",
        "        tmp = []\n",
        "        for j in range(len(context_type_csum) - 1):\n",
        "            start, end = context_type_csum[j], context_type_csum[j + 1]\n",
        "            tmp.append(layer_ks[i + start : i + end].mean(0))\n",
        "        ans.append(torch.stack(tmp, 0).mean(0))\n",
        "    return torch.stack(ans, dim=0)"
      ],
      "metadata": {
        "id": "y60tU5V40vCG"
      },
      "id": "y60tU5V40vCG",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cache variable(s)\n",
        "CONTEXT_TEMPLATES_CACHE = None\n",
        "COV_CACHE = {}\n",
        "\n",
        "\n",
        "def apply_memit_to_model(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: MEMITHyperParams,\n",
        "    copy=False,\n",
        "    return_orig_weights=False,\n",
        "    cache_template: Optional[str] = None,\n",
        ") -> Tuple[AutoModelForCausalLM, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Returns a model with the desired changes.\n",
        "    :param copy: If true, will preserve the original model while creating a new one to edit.\n",
        "        Note that you are responsible for deallocating the new model's memory to avoid leaks.\n",
        "    :return: (1) the updated model, (2) an original copy of the weights that changed\n",
        "    \"\"\"\n",
        "\n",
        "    weights_copy = {}\n",
        "    if copy:\n",
        "        model = deepcopy(model)\n",
        "\n",
        "    deltas = execute_memit(model, tok, requests, hparams, cache_template=cache_template)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for w_name, (key_mat, val_mat) in deltas.items():\n",
        "            key_mat, val_mat = key_mat.to(\"cuda\"), val_mat.to(\"cuda\")\n",
        "            upd_matrix = key_mat @ val_mat.T\n",
        "            w = nethook.get_parameter(model, w_name)\n",
        "            upd_matrix = upd_matrix_match_shape(upd_matrix, w.shape)\n",
        "\n",
        "            if return_orig_weights and w_name not in weights_copy:\n",
        "                weights_copy[w_name] = w.detach().clone()\n",
        "\n",
        "            w[...] += upd_matrix.float()\n",
        "\n",
        "    print(f\"New weights successfully inserted into {list(deltas.keys())}\")\n",
        "\n",
        "    return model, weights_copy\n",
        "\n",
        "\n",
        "def execute_memit(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: MEMITHyperParams,\n",
        "    cache_template: Optional[str] = None,\n",
        ") -> Dict[str, Tuple[torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Executes the MEMIT update algorithm for the specified update at the specified layer\n",
        "    Invariant: model at beginning of function == model at end of function\n",
        "    \"\"\"\n",
        "\n",
        "    deltas = {}\n",
        "\n",
        "    # Update target and print info\n",
        "    requests = deepcopy(requests)\n",
        "    for i, request in enumerate(requests):\n",
        "        if request[\"target_new\"][\"str\"][0] != \" \":\n",
        "            # Space required for correct tokenization\n",
        "            requests[i][\"target_new\"][\"str\"] = \" \" + request[\"target_new\"][\"str\"]\n",
        "    for request in requests[:10]:\n",
        "        print(\n",
        "            f\"MEMIT request sample: \"\n",
        "            f\"[{request['prompt'].format(request['subject'])}] -> [{request['target_new']['str']}]\"\n",
        "        )\n",
        "\n",
        "    # Retrieve weights that user desires to change\n",
        "    weights = {\n",
        "        f\"{hparams.rewrite_module_tmp.format(layer)}.weight\": nethook.get_parameter(\n",
        "            model, f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        )\n",
        "        for layer in hparams.layers\n",
        "    }\n",
        "    # Save old weights for future restoration\n",
        "    weights_copy = {k: v.detach().clone() for k, v in weights.items()}\n",
        "\n",
        "    # Compute z for final layer\n",
        "    context_templates = get_context_templates(model, tok)\n",
        "    z_layer = hparams.layers[-1]\n",
        "    z_list = []\n",
        "\n",
        "    for request in requests:\n",
        "        # Retrieve k/v pair if already stored in cache\n",
        "        cache_fname = (\n",
        "            Path(\n",
        "                str(cache_template).format(\n",
        "                    z_layer, hparams.clamp_norm_factor, request[\"case_id\"]\n",
        "                )\n",
        "            )\n",
        "            if cache_template is not None\n",
        "            else None\n",
        "        )\n",
        "        data_loaded = False\n",
        "        if (\n",
        "            cache_fname is not None  # Require cache template\n",
        "            and cache_fname.exists()  # Cache file must exist\n",
        "        ):\n",
        "            try:\n",
        "                data = np.load(cache_fname)\n",
        "                z_list.append(torch.from_numpy(data[\"v_star\"]).to(\"cuda\"))\n",
        "                data_loaded = True\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading cache file due to {e}. Recomputing...\")\n",
        "\n",
        "        # Compute k/v pair if not loaded from cache\n",
        "        if not data_loaded:\n",
        "            cur_z = compute_z(\n",
        "                model,\n",
        "                tok,\n",
        "                request,\n",
        "                hparams,\n",
        "                z_layer,\n",
        "                context_templates,\n",
        "            )\n",
        "\n",
        "            z_list.append(cur_z)\n",
        "\n",
        "            if cache_fname is not None:\n",
        "                cache_fname.parent.mkdir(exist_ok=True, parents=True)\n",
        "                np.savez(\n",
        "                    cache_fname,\n",
        "                    **{\n",
        "                        \"v_star\": cur_z.detach().cpu().numpy(),\n",
        "                    },\n",
        "                )\n",
        "                print(f\"Cached k/v pair at {cache_fname}\")\n",
        "    zs = torch.stack(z_list, dim=1)\n",
        "\n",
        "    # Insert\n",
        "    for i, layer in enumerate(hparams.layers):\n",
        "        print(f\"\\n\\nLAYER {layer}\\n\")\n",
        "\n",
        "        # Get current model activations\n",
        "        layer_ks = compute_ks(model, tok, requests, hparams, layer, context_templates).T\n",
        "        print(f\"Writing {layer_ks.size(1)} key/value pair(s) into layer {layer}\")\n",
        "\n",
        "        # Compute residual error\n",
        "        cur_zs = get_module_input_output_at_words(\n",
        "            model,\n",
        "            tok,\n",
        "            z_layer,\n",
        "            context_templates=[request[\"prompt\"] for request in requests],\n",
        "            words=[request[\"subject\"] for request in requests],\n",
        "            module_template=hparams.layer_module_tmp,\n",
        "            fact_token_strategy=hparams.fact_token,\n",
        "        )[1].T\n",
        "        targets = zs - cur_zs\n",
        "        print(\"z error\", torch.linalg.norm(targets, dim=0).mean())\n",
        "\n",
        "        repeat_factor = (layer_ks.size(1) // targets.size(1))\n",
        "        targets = targets.repeat_interleave(repeat_factor, dim=1)\n",
        "\n",
        "        # Load covariance matrix\n",
        "        force_recompute = False\n",
        "        # force_recompute = layer != hparams.layers[0]\n",
        "        cov = get_cov(\n",
        "            model,\n",
        "            tok,\n",
        "            hparams.rewrite_module_tmp.format(layer),\n",
        "            hparams.mom2_dataset,\n",
        "            hparams.mom2_n_samples\n",
        "            if not force_recompute\n",
        "            else hparams.mom2_n_samples // 10,\n",
        "            hparams.mom2_dtype,\n",
        "            force_recompute=force_recompute,\n",
        "        )\n",
        "\n",
        "        # Compute update in double precision\n",
        "        layer_ks, targets = (\n",
        "            layer_ks.double(),\n",
        "            targets.double(),\n",
        "        )\n",
        "\n",
        "        adj_k = torch.linalg.solve(\n",
        "            hparams.mom2_update_weight * cov.double() + layer_ks @ layer_ks.T,\n",
        "            layer_ks,\n",
        "        )\n",
        "        resid = targets / (len(hparams.layers) - i)  # Distribute residual across layers\n",
        "        upd_matrix = resid @ adj_k.T\n",
        "\n",
        "        # Adjust update matrix shape\n",
        "        weight_name = f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        upd_matrix = upd_matrix_match_shape(upd_matrix, weights[weight_name].shape)\n",
        "\n",
        "        print(\"orig norm\", torch.linalg.norm(weights[weight_name]))\n",
        "        print(\"upd norm\", torch.linalg.norm(upd_matrix))\n",
        "\n",
        "        # Update model weights and record desired changes in `delta` variable\n",
        "        with torch.no_grad():\n",
        "            weights[weight_name][...] = weights_copy[weight_name] + upd_matrix.float()\n",
        "            deltas[weight_name] = (\n",
        "                adj_k.detach().cpu(),\n",
        "                resid.detach().cpu(),\n",
        "            )\n",
        "\n",
        "        # Clear GPU memory\n",
        "        cov.cpu()\n",
        "        for x in [layer_ks, cur_zs, targets]:\n",
        "            x.cpu()\n",
        "            del x\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Restore state of original model\n",
        "    with torch.no_grad():\n",
        "        for k, v in weights.items():\n",
        "            v[...] = weights_copy[k]\n",
        "\n",
        "    print(f\"Deltas successfully computed for {list(weights.keys())}\")\n",
        "\n",
        "    return deltas\n",
        "\n",
        "\n",
        "def get_cov(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    layer_name: str,\n",
        "    mom2_dataset: str,\n",
        "    mom2_n_samples: str,\n",
        "    mom2_dtype: str,\n",
        "    inv: bool = False,\n",
        "    force_recompute: bool = False,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Retrieves covariance statistics, then computes the algebraic inverse.\n",
        "    Caches result for future use.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name = model.config._name_or_path.replace(\"/\", \"_\")\n",
        "    key = (model_name, layer_name)\n",
        "\n",
        "    print(f\"Retrieving covariance statistics for {model_name} @ {layer_name}.\")\n",
        "    if key not in COV_CACHE or force_recompute:\n",
        "        stat = layer_stats(\n",
        "            model,\n",
        "            tok,\n",
        "            layer_name,\n",
        "            STATS_DIR,\n",
        "            mom2_dataset,\n",
        "            to_collect=[\"mom2\"],\n",
        "            sample_size=mom2_n_samples,\n",
        "            precision=mom2_dtype,\n",
        "            force_recompute=force_recompute,\n",
        "        )\n",
        "        COV_CACHE[key] = stat.mom2.moment().float().to(\"cpu\")\n",
        "\n",
        "    return (\n",
        "        torch.inverse(COV_CACHE[key].to(\"cuda\")) if inv else COV_CACHE[key].to(\"cuda\")\n",
        "    )\n",
        "\n",
        "\n",
        "def upd_matrix_match_shape(matrix: torch.Tensor, shape: torch.Size) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    GPT-2 and GPT-J have transposed weight representations.\n",
        "    Returns a matrix that matches the desired shape, else raises a ValueError\n",
        "    \"\"\"\n",
        "\n",
        "    if matrix.shape == shape:\n",
        "        return matrix\n",
        "    elif matrix.T.shape == shape:\n",
        "        return matrix.T\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Update matrix computed by MEMIT does not match original weight shape. \"\n",
        "            \"Check for bugs in the code?\"\n",
        "        )\n",
        "\n",
        "\n",
        "def get_context_templates(model, tok):\n",
        "    global CONTEXT_TEMPLATES_CACHE\n",
        "\n",
        "    if CONTEXT_TEMPLATES_CACHE is None:\n",
        "        CONTEXT_TEMPLATES_CACHE = [[\"{}\"]] + [\n",
        "            [\n",
        "                f.replace(\"{\", \" \").replace(\"}\", \" \") + \". {}\"\n",
        "                for f in generate_fast(\n",
        "                    model,\n",
        "                    tok,\n",
        "                    [\"The\", \"Therefore\", \"Because\", \"I\", \"You\"],\n",
        "                    n_gen_per_prompt=n_gen // 5,\n",
        "                    max_out_len=length,\n",
        "                )\n",
        "            ]\n",
        "            for length, n_gen in [(10, 5)]  # Be careful about changing this.\n",
        "        ]\n",
        "        print(f\"Cached context templates {CONTEXT_TEMPLATES_CACHE}\")\n",
        "\n",
        "    return CONTEXT_TEMPLATES_CACHE"
      ],
      "metadata": {
        "id": "Me3l09EsqnpE"
      },
      "id": "Me3l09EsqnpE",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memit_hparam = {\n",
        "    \"layers\": [13, 14, 15, 16, 17],\n",
        "    \"clamp_norm_factor\": 0.75,\n",
        "    \"layer_selection\": \"all\",\n",
        "    \"fact_token\": \"subject_last\",\n",
        "    \"v_num_grad_steps\": 20,\n",
        "    \"v_lr\": 5e-1,\n",
        "    \"v_loss_layer\": 47,\n",
        "    \"v_weight_decay\": 0.5,\n",
        "    \"kl_factor\": 0.0625,\n",
        "    \"mom2_adjustment\": True,\n",
        "    \"mom2_update_weight\": 20000,\n",
        "    \"rewrite_module_tmp\": \"transformer.h.{}.mlp.c_proj\",\n",
        "    \"layer_module_tmp\": \"transformer.h.{}\",\n",
        "    \"mlp_module_tmp\": \"transformer.h.{}.mlp\",\n",
        "    \"attn_module_tmp\": \"transformer.h.{}.attn\",\n",
        "    \"ln_f_module\": \"transformer.ln_f\",\n",
        "    \"lm_head_module\": \"transformer.wte\",\n",
        "    \"mom2_dataset\": \"wikipedia\",\n",
        "    \"mom2_n_samples\": 100000,\n",
        "    \"mom2_dtype\": \"float32\"\n",
        "}"
      ],
      "metadata": {
        "id": "4lsDbAvJ19ye"
      },
      "id": "4lsDbAvJ19ye",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "set_requires_grad(True, model)\n",
        "\n",
        "###### TODO: Change the method :) ######\n",
        "# RewritingParamsClass, apply_method, hparam = FTHyperParams, apply_ft_to_model, ft_hparam\n",
        "# RewritingParamsClass, apply_method, hparam = ROMEHyperParams, apply_rome_to_model, rome_hparam\n",
        "RewritingParamsClass, apply_method, hparam = MEMITHyperParams, apply_memit_to_model, memit_hparam\n",
        "\n",
        "\n",
        "\n",
        "print_loud(f\"Retrieving hyperparameters\")\n",
        "hparams = RewritingParamsClass(**hparam)\n",
        "print(hparams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqngh6zS12SI",
        "outputId": "6f8a44d8-d99a-4c2e-ada1-97367aa403ac"
      },
      "id": "Cqngh6zS12SI",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No model weights to restore: name 'orig_weights' is not defined\n",
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Retrieving hyperparameters  #\n",
            "#                              #\n",
            "################################\n",
            "MEMITHyperParams(layers=[13, 14, 15, 16, 17], layer_selection='all', fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=47, v_weight_decay=0.5, clamp_norm_factor=0.75, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=20000, rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_loud(\"Generating pre-update text\")\n",
        "pre_update_text = [[], [], [], []]\n",
        "type_name = [\"Efficacy\", \"Paraphrase\", \"Neighborhood\", \"Portability\"]\n",
        "for i in range(4):\n",
        "  pre_update_text[i] = generate(model, tok, generation_prompts[i], max_out_len=50, first_do_sample = False)\n",
        "  print(f\"{type_name[i]} score (pre): \" + str(scoring(generation_prompts[i], pre_update_text[i], ans_true[i])))\n",
        "  print(f\"{type_name[i]} score (post): \" + str(scoring(generation_prompts[i], pre_update_text[i], ans_new[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t30rjXlz2ctP",
        "outputId": "c73b847e-d407-4ce5-d1ca-80a460e51cd4"
      },
      "id": "t30rjXlz2ctP",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Generating pre-update text  #\n",
            "#                              #\n",
            "################################\n",
            "Efficacy score (pre): 1.0\n",
            "Efficacy score (post): 0.0\n",
            "Paraphrase score (pre): 0.95\n",
            "Paraphrase score (post): 0.0\n",
            "Neighborhood score (pre): 1.0\n",
            "Neighborhood score (post): 1.0\n",
            "Portability score (pre): 0.9875\n",
            "Portability score (post): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_loud(f\"Model Editing...\")\n",
        "model_new, orig_weights = apply_method(\n",
        "    model, tok, requests, hparams, return_orig_weights=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d8e8c7f64a22464ab20874c482da1418",
            "f7ee4e1c25844215848e7fc92ba7a7e2",
            "ec65e0e6b2f341b080ae45109db1eb08",
            "53c7a3e642e34ab694642e2d8331bcd8",
            "b150fdd7addd4aa1a2e31d52a7d8dde1",
            "05921fa5bf514094bf91e2364e020e44",
            "16d76f9fee214b0c94d7ee4743fa53fc",
            "2c55db52129c4d888e19b4fd831469b5",
            "d2cb5b7a5ce0417b8f6842c26883c090",
            "f5f5e9f99b22468a8e74bbcce8c67f00",
            "9089761d565c475ebc0bfce4f510c00e",
            "25d22440c7454a0cb563368a1ccfaf25",
            "76705a2576c7466fa97337c336b92aab",
            "e5ea5e63e8804acdb33763a8de67ca98",
            "9595d04e7c6a47ee99b899eda6c8042b",
            "d6b8d633bee14b188a3d04adc8644b26",
            "c63a0b9ecbce4f9e900ac06a3a7a31ba",
            "605f8ee9ea5b406fb398c8f0f017848a",
            "c98114ab3a3b4156b5e8839e5c0512a0",
            "9f1a181eb4da45718a8ec32be49e2187",
            "a5fe9540deab45bf952ebb82c59ab417",
            "4cdf22a1aaf048adb8b96b432805a7c5",
            "7ee2d000c1c145f6a0719f56927e4c27",
            "1e77afe1663b49f481c7b4bf42389528",
            "a0f8236c66cf4112b448ce998335ac6e",
            "30546d683fe4435cbb010435ee3b5ad0",
            "d283712cfbaa499592c084cb8d1dbf1b",
            "679f905e2457485698090fd4879342ed",
            "8cc61309de9f454ca037b64b26ef4a83",
            "df3a8c7d0b4c48eea526568d89fccb9b",
            "91ce9514359d4c4fa62b3c4e36ff5e3d",
            "54865909c3c046bb8768afa8143920c8",
            "d1c4207160ed468ca4362fd6285e1adf",
            "e2d9fd4e254b49e8921f72ec88de08fc",
            "f392e3cd0c474230bd067f230d924814",
            "2687aa77fedd4d34bf12a7072ea14c8e",
            "45f95f79204a4716a56b79b21ad4da1c",
            "c2fdef713da24f6199a191126ab3bdca",
            "b563cc459368424ab34598158a86861c",
            "c4fa2a34a8014ad18b2e3a7a20d3bbdb",
            "46504610699f45979b8f8417b39876bb",
            "9078d6924b96412a86f381c2c21ba33d",
            "0a63e8ba80c148d48e7ff5fe5660758c",
            "570b1ade158943d5a15c5099eae09263",
            "99b8e19ffd5645a49d468a8ca82c92d4",
            "e447d928c1744ebcb81b4f409dcc4247",
            "28da227f11a74210a728cfac50491db0",
            "ab9a2757c68a4479b19e016076362eff",
            "f1d69cc8f7054f23b625f21f7c20b3ad",
            "3110421146b04576be88a0b16bf9fd90",
            "c67f972af8114769a61a76140c65c2c5",
            "33b2015155994a59800fa9b7f776ad83",
            "14d39634bb564d179a18c1d97743fe9c",
            "074e8fa53f904dd1b4f75a00bf0f3194",
            "11edb8a783df4bedb96bb42f619cb4a2"
          ]
        },
        "id": "1ZRxsiIR22qD",
        "outputId": "0ffed1a6-7f49-49ca-e0c2-3a41ff72dd77"
      },
      "id": "1ZRxsiIR22qD",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################\n",
            "#                    #\n",
            "#  Model Editing...  #\n",
            "#                    #\n",
            "######################\n",
            "MEMIT request sample: [Tapio Kantanen is a citizen of] -> [ Bulgaria]\n",
            "MEMIT request sample: [Ipsos MORI's headquarters are in] -> [ Oslo]\n",
            "MEMIT request sample: [The headquarters of Northeastern University is in] -> [ Dublin]\n",
            "MEMIT request sample: [The mother tongue of Alain Robbe-Grillet is] -> [ Dutch]\n",
            "MEMIT request sample: [The native language of Freek de Jonge is] -> [ French]\n",
            "MEMIT request sample: [University of Oklahoma, whose headquarters are in] -> [ Greenwich]\n",
            "MEMIT request sample: [The headquarter of University of Kentucky is located in] -> [ Hamburg]\n",
            "MEMIT request sample: [Emmanuel Macron is a native speaker of] -> [ Dutch]\n",
            "MEMIT request sample: [Chrome OS, created by] -> [ IBM]\n",
            "MEMIT request sample: [Jacques Doriot is a native speaker of] -> [ Russian]\n",
            "Cached context templates [['{}'], ['The last few weeks have been very busy for us. {}', 'Therefore, the first step in the development of the. {}', 'Because of the high-profile nature of the incident. {}', \"I have to be honest. It's been hard. {}\", \"You're going to have to go back and re. {}\"]]\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Tapio Kantanen is a citizen of | Token: en\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.971 = 9.971 + 0.0 + 0.0 avg prob of [ Bulgaria] 5.99233026150614e-05\n",
            "loss 7.284 = 7.278 + 0.005 + 0.001 avg prob of [ Bulgaria] 0.0007193151395767927\n",
            "loss 6.455 = 6.445 + 0.008 + 0.002 avg prob of [ Bulgaria] 0.0017070784233510494\n",
            "loss 5.806 = 5.792 + 0.012 + 0.002 avg prob of [ Bulgaria] 0.003277829848229885\n",
            "loss 5.005 = 4.989 + 0.013 + 0.003 avg prob of [ Bulgaria] 0.007316477596759796\n",
            "loss 4.147 = 4.129 + 0.015 + 0.003 avg prob of [ Bulgaria] 0.017257964238524437\n",
            "loss 3.334 = 3.314 + 0.016 + 0.004 avg prob of [ Bulgaria] 0.038758259266614914\n",
            "loss 2.727 = 2.707 + 0.016 + 0.004 avg prob of [ Bulgaria] 0.07087409496307373\n",
            "loss 2.179 = 2.158 + 0.017 + 0.004 avg prob of [ Bulgaria] 0.12138932943344116\n",
            "loss 1.685 = 1.662 + 0.019 + 0.004 avg prob of [ Bulgaria] 0.1963530033826828\n",
            "loss 1.205 = 1.179 + 0.022 + 0.004 avg prob of [ Bulgaria] 0.31380802392959595\n",
            "loss 0.762 = 0.733 + 0.025 + 0.004 avg prob of [ Bulgaria] 0.48449668288230896\n",
            "loss 0.44 = 0.409 + 0.026 + 0.004 avg prob of [ Bulgaria] 0.6661816835403442\n",
            "loss 0.244 = 0.213 + 0.028 + 0.004 avg prob of [ Bulgaria] 0.8093380331993103\n",
            "loss 0.142 = 0.108 + 0.03 + 0.004 avg prob of [ Bulgaria] 0.8979629278182983\n",
            "loss 0.092 = 0.056 + 0.032 + 0.004 avg prob of [ Bulgaria] 0.9458973407745361\n",
            "loss 0.064 = 0.029 + 0.032 + 0.004 avg prob of [ Bulgaria] 0.9717555046081543\n",
            "loss 0.047 = 0.014 + 0.029 + 0.004 avg prob of [ Bulgaria] 0.9860215187072754\n",
            "Init norm 95.7882308959961 | Delta norm 71.84117126464844 | Target norm 115.55754852294922\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Ipsos MORI's headquarters are in | Token: I\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.844 = 8.844 + 0.0 + 0.0 avg prob of [ Oslo] 0.00029505754355341196\n",
            "loss 5.399 = 5.387 + 0.012 + 0.001 avg prob of [ Oslo] 0.006417436525225639\n",
            "loss 1.361 = 1.338 + 0.021 + 0.001 avg prob of [ Oslo] 0.28392910957336426\n",
            "loss 0.567 = 0.537 + 0.029 + 0.002 avg prob of [ Oslo] 0.6167250871658325\n",
            "loss 0.458 = 0.421 + 0.035 + 0.002 avg prob of [ Oslo] 0.6880481243133545\n",
            "loss 0.388 = 0.344 + 0.042 + 0.002 avg prob of [ Oslo] 0.7375370264053345\n",
            "loss 0.332 = 0.283 + 0.047 + 0.003 avg prob of [ Oslo] 0.7775828242301941\n",
            "loss 0.286 = 0.233 + 0.05 + 0.003 avg prob of [ Oslo] 0.8113222122192383\n",
            "loss 0.249 = 0.192 + 0.054 + 0.003 avg prob of [ Oslo] 0.8403549194335938\n",
            "loss 0.216 = 0.157 + 0.056 + 0.003 avg prob of [ Oslo] 0.8661197423934937\n",
            "loss 0.185 = 0.125 + 0.056 + 0.003 avg prob of [ Oslo] 0.890201985836029\n",
            "loss 0.16 = 0.101 + 0.056 + 0.003 avg prob of [ Oslo] 0.9097908735275269\n",
            "loss 0.14 = 0.082 + 0.055 + 0.003 avg prob of [ Oslo] 0.9254946708679199\n",
            "loss 0.124 = 0.067 + 0.054 + 0.003 avg prob of [ Oslo] 0.9379928112030029\n",
            "loss 0.111 = 0.055 + 0.052 + 0.003 avg prob of [ Oslo] 0.947921633720398\n",
            "loss 0.099 = 0.047 + 0.049 + 0.003 avg prob of [ Oslo] 0.9558305144309998\n",
            "loss 0.089 = 0.04 + 0.046 + 0.003 avg prob of [ Oslo] 0.9621667265892029\n",
            "loss 0.08 = 0.034 + 0.043 + 0.003 avg prob of [ Oslo] 0.9672818183898926\n",
            "loss 0.072 = 0.029 + 0.039 + 0.003 avg prob of [ Oslo] 0.971449077129364\n",
            "loss 0.066 = 0.026 + 0.036 + 0.003 avg prob of [ Oslo] 0.9748786687850952\n",
            "Init norm 114.15486907958984 | Delta norm 85.61614990234375 | Target norm 142.69863891601562\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The headquarters of Northeastern University is in | Token:  University\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.694 = 9.694 + 0.0 + 0.0 avg prob of [ Dublin] 0.00010380657477071509\n",
            "loss 7.401 = 7.399 + 0.001 + 0.001 avg prob of [ Dublin] 0.0006836066022515297\n",
            "loss 5.874 = 5.868 + 0.005 + 0.001 avg prob of [ Dublin] 0.0028991138096898794\n",
            "loss 3.516 = 3.505 + 0.01 + 0.001 avg prob of [ Dublin] 0.03440146520733833\n",
            "loss 2.363 = 2.346 + 0.015 + 0.002 avg prob of [ Dublin] 0.10097795724868774\n",
            "loss 1.778 = 1.758 + 0.018 + 0.002 avg prob of [ Dublin] 0.17576122283935547\n",
            "loss 1.405 = 1.382 + 0.02 + 0.002 avg prob of [ Dublin] 0.2529763877391815\n",
            "loss 1.081 = 1.057 + 0.021 + 0.003 avg prob of [ Dublin] 0.3493976294994354\n",
            "loss 0.811 = 0.786 + 0.022 + 0.003 avg prob of [ Dublin] 0.4588397443294525\n",
            "loss 0.603 = 0.578 + 0.022 + 0.003 avg prob of [ Dublin] 0.565290629863739\n",
            "loss 0.456 = 0.432 + 0.021 + 0.003 avg prob of [ Dublin] 0.6529121994972229\n",
            "loss 0.34 = 0.317 + 0.02 + 0.003 avg prob of [ Dublin] 0.7311614751815796\n",
            "loss 0.252 = 0.23 + 0.019 + 0.003 avg prob of [ Dublin] 0.7966611385345459\n",
            "loss 0.188 = 0.166 + 0.019 + 0.003 avg prob of [ Dublin] 0.8483376502990723\n",
            "loss 0.142 = 0.12 + 0.018 + 0.003 avg prob of [ Dublin] 0.8873929977416992\n",
            "loss 0.109 = 0.088 + 0.018 + 0.003 avg prob of [ Dublin] 0.9161742925643921\n",
            "loss 0.086 = 0.065 + 0.018 + 0.003 avg prob of [ Dublin] 0.9371146559715271\n",
            "loss 0.07 = 0.049 + 0.018 + 0.003 avg prob of [ Dublin] 0.9522668123245239\n",
            "loss 0.058 = 0.038 + 0.018 + 0.003 avg prob of [ Dublin] 0.9632271528244019\n",
            "loss 0.05 = 0.029 + 0.018 + 0.003 avg prob of [ Dublin] 0.9711893796920776\n",
            "Init norm 127.6513900756836 | Delta norm 95.73853302001953 | Target norm 153.72164916992188\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: The mother tongue of Alain Robbe-Grillet is | Token: illet\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.294 = 7.294 + 0.0 + 0.0 avg prob of [ Dutch] 0.0007354377303272486\n",
            "loss 4.951 = 4.948 + 0.002 + 0.001 avg prob of [ Dutch] 0.007710237987339497\n",
            "loss 3.228 = 3.222 + 0.004 + 0.002 avg prob of [ Dutch] 0.04434358328580856\n",
            "loss 1.224 = 1.213 + 0.009 + 0.002 avg prob of [ Dutch] 0.32049328088760376\n",
            "loss 0.5 = 0.487 + 0.011 + 0.003 avg prob of [ Dutch] 0.621012806892395\n",
            "loss 0.371 = 0.357 + 0.011 + 0.003 avg prob of [ Dutch] 0.7007924318313599\n",
            "loss 0.345 = 0.33 + 0.012 + 0.003 avg prob of [ Dutch] 0.7205733060836792\n",
            "loss 0.295 = 0.28 + 0.012 + 0.004 avg prob of [ Dutch] 0.757560133934021\n",
            "loss 0.229 = 0.213 + 0.012 + 0.004 avg prob of [ Dutch] 0.8088709712028503\n",
            "loss 0.171 = 0.156 + 0.011 + 0.004 avg prob of [ Dutch] 0.855870246887207\n",
            "loss 0.128 = 0.113 + 0.011 + 0.004 avg prob of [ Dutch] 0.8930913805961609\n",
            "loss 0.098 = 0.084 + 0.011 + 0.004 avg prob of [ Dutch] 0.92010498046875\n",
            "loss 0.078 = 0.063 + 0.012 + 0.004 avg prob of [ Dutch] 0.9389645457267761\n",
            "loss 0.064 = 0.049 + 0.012 + 0.004 avg prob of [ Dutch] 0.9521109461784363\n",
            "loss 0.054 = 0.039 + 0.011 + 0.004 avg prob of [ Dutch] 0.9614843726158142\n",
            "loss 0.047 = 0.032 + 0.011 + 0.004 avg prob of [ Dutch] 0.9683986902236938\n",
            "Init norm 105.41751098632812 | Delta norm 79.0631332397461 | Target norm 130.71682739257812\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Freek de Jonge is | Token: ge\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.254 = 5.254 + 0.0 + 0.0 avg prob of [ French] 0.005860166624188423\n",
            "loss 1.799 = 1.796 + 0.002 + 0.001 avg prob of [ French] 0.16977691650390625\n",
            "loss 1.199 = 1.194 + 0.004 + 0.001 avg prob of [ French] 0.30666273832321167\n",
            "loss 0.952 = 0.944 + 0.007 + 0.002 avg prob of [ French] 0.3953056335449219\n",
            "loss 0.793 = 0.781 + 0.01 + 0.002 avg prob of [ French] 0.46574708819389343\n",
            "loss 0.651 = 0.636 + 0.013 + 0.002 avg prob of [ French] 0.5376694202423096\n",
            "loss 0.515 = 0.498 + 0.015 + 0.003 avg prob of [ French] 0.6149080991744995\n",
            "loss 0.394 = 0.375 + 0.016 + 0.003 avg prob of [ French] 0.6918119788169861\n",
            "loss 0.294 = 0.275 + 0.016 + 0.003 avg prob of [ French] 0.7616960406303406\n",
            "loss 0.223 = 0.205 + 0.015 + 0.003 avg prob of [ French] 0.8159143328666687\n",
            "loss 0.174 = 0.157 + 0.014 + 0.003 avg prob of [ French] 0.8556904196739197\n",
            "loss 0.135 = 0.119 + 0.013 + 0.003 avg prob of [ French] 0.8882220983505249\n",
            "loss 0.106 = 0.091 + 0.012 + 0.003 avg prob of [ French] 0.9136869311332703\n",
            "loss 0.084 = 0.069 + 0.011 + 0.003 avg prob of [ French] 0.9331507682800293\n",
            "loss 0.067 = 0.054 + 0.01 + 0.003 avg prob of [ French] 0.9479107856750488\n",
            "loss 0.055 = 0.042 + 0.01 + 0.003 avg prob of [ French] 0.9590803980827332\n",
            "loss 0.046 = 0.033 + 0.01 + 0.003 avg prob of [ French] 0.9675130248069763\n",
            "Init norm 117.97042846679688 | Delta norm 88.47782135009766 | Target norm 145.35948181152344\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: University of Oklahoma, whose headquarters are in | Token:  Oklahoma\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.23 = 13.23 + 0.0 + 0.0 avg prob of [ Greenwich] 2.8961746920685982e-06\n",
            "loss 9.092 = 9.088 + 0.003 + 0.0 avg prob of [ Greenwich] 0.00011549104237928987\n",
            "loss 7.232 = 7.222 + 0.009 + 0.001 avg prob of [ Greenwich] 0.0007823265041224658\n",
            "loss 6.263 = 6.243 + 0.018 + 0.001 avg prob of [ Greenwich] 0.002274769823998213\n",
            "loss 5.6 = 5.569 + 0.029 + 0.002 avg prob of [ Greenwich] 0.004771629348397255\n",
            "loss 4.975 = 4.937 + 0.036 + 0.002 avg prob of [ Greenwich] 0.009554587304592133\n",
            "loss 4.26 = 4.219 + 0.039 + 0.002 avg prob of [ Greenwich] 0.02045927196741104\n",
            "loss 3.435 = 3.391 + 0.042 + 0.002 avg prob of [ Greenwich] 0.04631546139717102\n",
            "loss 2.555 = 2.507 + 0.045 + 0.003 avg prob of [ Greenwich] 0.10342985391616821\n",
            "loss 1.768 = 1.719 + 0.046 + 0.003 avg prob of [ Greenwich] 0.20319879055023193\n",
            "loss 1.114 = 1.065 + 0.046 + 0.003 avg prob of [ Greenwich] 0.3618229031562805\n",
            "loss 0.607 = 0.559 + 0.046 + 0.003 avg prob of [ Greenwich] 0.5798463225364685\n",
            "loss 0.294 = 0.245 + 0.046 + 0.003 avg prob of [ Greenwich] 0.7846317291259766\n",
            "loss 0.146 = 0.097 + 0.047 + 0.003 avg prob of [ Greenwich] 0.908415675163269\n",
            "loss 0.088 = 0.038 + 0.048 + 0.003 avg prob of [ Greenwich] 0.9627259969711304\n",
            "loss 0.066 = 0.016 + 0.047 + 0.003 avg prob of [ Greenwich] 0.9837223887443542\n",
            "loss 0.056 = 0.008 + 0.046 + 0.003 avg prob of [ Greenwich] 0.991958498954773\n",
            "loss 0.051 = 0.005 + 0.043 + 0.003 avg prob of [ Greenwich] 0.9954521656036377\n",
            "loss 0.046 = 0.003 + 0.041 + 0.003 avg prob of [ Greenwich] 0.9970749616622925\n",
            "Init norm 141.71189880371094 | Delta norm 106.28392028808594 | Target norm 174.34251403808594\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The headquarter of University of Kentucky is located in | Token:  Kentucky\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.781 = 12.781 + 0.0 + 0.0 avg prob of [ Hamburg] 3.7811346373928245e-06\n",
            "loss 9.308 = 9.306 + 0.001 + 0.001 avg prob of [ Hamburg] 0.00011201195593457669\n",
            "loss 7.328 = 7.323 + 0.004 + 0.001 avg prob of [ Hamburg] 0.0007433040300384164\n",
            "loss 6.176 = 6.166 + 0.008 + 0.001 avg prob of [ Hamburg] 0.002212179359048605\n",
            "loss 5.247 = 5.233 + 0.012 + 0.002 avg prob of [ Hamburg] 0.005686996039003134\n",
            "loss 4.315 = 4.297 + 0.015 + 0.002 avg prob of [ Hamburg] 0.015283564105629921\n",
            "loss 3.358 = 3.336 + 0.02 + 0.002 avg prob of [ Hamburg] 0.0403759703040123\n",
            "loss 2.533 = 2.504 + 0.026 + 0.002 avg prob of [ Hamburg] 0.09039376676082611\n",
            "loss 1.85 = 1.814 + 0.033 + 0.003 avg prob of [ Hamburg] 0.17701539397239685\n",
            "loss 1.303 = 1.265 + 0.036 + 0.003 avg prob of [ Hamburg] 0.3012717366218567\n",
            "loss 0.829 = 0.789 + 0.037 + 0.003 avg prob of [ Hamburg] 0.4743320345878601\n",
            "loss 0.471 = 0.432 + 0.037 + 0.003 avg prob of [ Hamburg] 0.6632229089736938\n",
            "loss 0.254 = 0.216 + 0.036 + 0.003 avg prob of [ Hamburg] 0.8121463656425476\n",
            "loss 0.143 = 0.106 + 0.034 + 0.003 avg prob of [ Hamburg] 0.901602029800415\n",
            "loss 0.089 = 0.054 + 0.032 + 0.003 avg prob of [ Hamburg] 0.947912871837616\n",
            "loss 0.062 = 0.03 + 0.029 + 0.003 avg prob of [ Hamburg] 0.9708795547485352\n",
            "loss 0.047 = 0.018 + 0.026 + 0.003 avg prob of [ Hamburg] 0.9824416637420654\n",
            "Init norm 137.864013671875 | Delta norm 103.39801025390625 | Target norm 164.9149627685547\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Emmanuel Macron is a native speaker of | Token:  Macron\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.199 = 7.199 + 0.0 + 0.0 avg prob of [ Dutch] 0.0008129470515996218\n",
            "loss 5.108 = 5.107 + 0.001 + 0.0 avg prob of [ Dutch] 0.006268832832574844\n",
            "loss 3.806 = 3.803 + 0.002 + 0.001 avg prob of [ Dutch] 0.023652847856283188\n",
            "loss 2.443 = 2.44 + 0.002 + 0.001 avg prob of [ Dutch] 0.09619631618261337\n",
            "loss 1.114 = 1.109 + 0.004 + 0.001 avg prob of [ Dutch] 0.34473904967308044\n",
            "loss 0.384 = 0.378 + 0.005 + 0.002 avg prob of [ Dutch] 0.689674973487854\n",
            "loss 0.169 = 0.161 + 0.006 + 0.002 avg prob of [ Dutch] 0.8521078824996948\n",
            "loss 0.115 = 0.106 + 0.007 + 0.002 avg prob of [ Dutch] 0.9002248644828796\n",
            "loss 0.1 = 0.089 + 0.008 + 0.002 avg prob of [ Dutch] 0.9147191047668457\n",
            "loss 0.096 = 0.085 + 0.009 + 0.002 avg prob of [ Dutch] 0.9186190366744995\n",
            "loss 0.089 = 0.078 + 0.009 + 0.003 avg prob of [ Dutch] 0.9253568649291992\n",
            "loss 0.078 = 0.067 + 0.009 + 0.003 avg prob of [ Dutch] 0.9355096220970154\n",
            "loss 0.067 = 0.056 + 0.008 + 0.003 avg prob of [ Dutch] 0.9457329511642456\n",
            "loss 0.056 = 0.046 + 0.008 + 0.003 avg prob of [ Dutch] 0.9553083181381226\n",
            "loss 0.048 = 0.037 + 0.008 + 0.003 avg prob of [ Dutch] 0.9636766314506531\n",
            "Init norm 147.61328125 | Delta norm 110.70996856689453 | Target norm 181.66897583007812\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Chrome OS, created by | Token:  OS\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.93 = 8.93 + 0.0 + 0.0 avg prob of [ IBM] 0.0001707027986412868\n",
            "loss 4.921 = 4.915 + 0.005 + 0.001 avg prob of [ IBM] 0.008403856307268143\n",
            "loss 2.458 = 2.44 + 0.017 + 0.001 avg prob of [ IBM] 0.09881794452667236\n",
            "loss 1.501 = 1.47 + 0.03 + 0.001 avg prob of [ IBM] 0.24055735766887665\n",
            "loss 0.987 = 0.946 + 0.04 + 0.002 avg prob of [ IBM] 0.394583523273468\n",
            "loss 0.628 = 0.579 + 0.048 + 0.002 avg prob of [ IBM] 0.5633670091629028\n",
            "loss 0.394 = 0.341 + 0.051 + 0.002 avg prob of [ IBM] 0.712098240852356\n",
            "loss 0.254 = 0.2 + 0.051 + 0.002 avg prob of [ IBM] 0.8191048502922058\n",
            "loss 0.173 = 0.12 + 0.05 + 0.003 avg prob of [ IBM] 0.8868765830993652\n",
            "loss 0.128 = 0.077 + 0.048 + 0.003 avg prob of [ IBM] 0.9261980056762695\n",
            "loss 0.104 = 0.056 + 0.045 + 0.003 avg prob of [ IBM] 0.9459360837936401\n",
            "loss 0.087 = 0.041 + 0.043 + 0.003 avg prob of [ IBM] 0.9596033096313477\n",
            "loss 0.074 = 0.031 + 0.04 + 0.003 avg prob of [ IBM] 0.9693037867546082\n",
            "loss 0.064 = 0.024 + 0.038 + 0.003 avg prob of [ IBM] 0.9763252139091492\n",
            "loss 0.057 = 0.019 + 0.035 + 0.003 avg prob of [ IBM] 0.9814855456352234\n",
            "loss 0.051 = 0.015 + 0.033 + 0.003 avg prob of [ IBM] 0.9853262901306152\n",
            "loss 0.046 = 0.012 + 0.032 + 0.003 avg prob of [ IBM] 0.9882162809371948\n",
            "Init norm 135.09848022460938 | Delta norm 101.32386016845703 | Target norm 166.63523864746094\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Jacques Doriot is a native speaker of | Token: iot\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.923 = 4.923 + 0.0 + 0.0 avg prob of [ Russian] 0.008066208101809025\n",
            "loss 3.615 = 3.579 + 0.035 + 0.001 avg prob of [ Russian] 0.028801148757338524\n",
            "loss 1.87 = 1.834 + 0.035 + 0.001 avg prob of [ Russian] 0.1643323302268982\n",
            "loss 0.967 = 0.932 + 0.034 + 0.001 avg prob of [ Russian] 0.4009742736816406\n",
            "loss 0.692 = 0.653 + 0.038 + 0.002 avg prob of [ Russian] 0.5266516804695129\n",
            "loss 0.531 = 0.489 + 0.04 + 0.002 avg prob of [ Russian] 0.6175878047943115\n",
            "loss 0.405 = 0.361 + 0.041 + 0.002 avg prob of [ Russian] 0.6997708082199097\n",
            "loss 0.301 = 0.257 + 0.041 + 0.003 avg prob of [ Russian] 0.7756884098052979\n",
            "loss 0.22 = 0.175 + 0.042 + 0.003 avg prob of [ Russian] 0.8403469324111938\n",
            "loss 0.163 = 0.117 + 0.043 + 0.003 avg prob of [ Russian] 0.8902378082275391\n",
            "loss 0.13 = 0.085 + 0.042 + 0.003 avg prob of [ Russian] 0.9189819097518921\n",
            "loss 0.106 = 0.062 + 0.04 + 0.003 avg prob of [ Russian] 0.9396899938583374\n",
            "loss 0.088 = 0.046 + 0.039 + 0.003 avg prob of [ Russian] 0.9548259973526001\n",
            "loss 0.075 = 0.035 + 0.037 + 0.003 avg prob of [ Russian] 0.9660263061523438\n",
            "loss 0.064 = 0.026 + 0.036 + 0.003 avg prob of [ Russian] 0.9746520519256592\n",
            "loss 0.056 = 0.019 + 0.034 + 0.003 avg prob of [ Russian] 0.9815770983695984\n",
            "loss 0.048 = 0.013 + 0.032 + 0.003 avg prob of [ Russian] 0.987233579158783\n",
            "Init norm 122.9805908203125 | Delta norm 92.23544311523438 | Target norm 152.97872924804688\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Vanderbilt University, whose headquarters are in | Token:  University\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.378 = 12.378 + 0.0 + 0.0 avg prob of [ Toronto] 8.238255759351887e-06\n",
            "loss 10.448 = 10.446 + 0.001 + 0.001 avg prob of [ Toronto] 4.9058311560656875e-05\n",
            "loss 8.049 = 8.046 + 0.003 + 0.001 avg prob of [ Toronto] 0.00041805964428931475\n",
            "loss 2.58 = 2.57 + 0.009 + 0.001 avg prob of [ Toronto] 0.09296835958957672\n",
            "loss 1.786 = 1.767 + 0.018 + 0.002 avg prob of [ Toronto] 0.17606481909751892\n",
            "loss 1.636 = 1.61 + 0.025 + 0.002 avg prob of [ Toronto] 0.20396356284618378\n",
            "loss 1.462 = 1.433 + 0.027 + 0.002 avg prob of [ Toronto] 0.24235598742961884\n",
            "loss 1.259 = 1.23 + 0.027 + 0.002 avg prob of [ Toronto] 0.2956554591655731\n",
            "loss 1.052 = 1.024 + 0.025 + 0.002 avg prob of [ Toronto] 0.36237049102783203\n",
            "loss 0.857 = 0.83 + 0.024 + 0.003 avg prob of [ Toronto] 0.4388108253479004\n",
            "loss 0.687 = 0.662 + 0.022 + 0.003 avg prob of [ Toronto] 0.5181930065155029\n",
            "loss 0.548 = 0.524 + 0.021 + 0.003 avg prob of [ Toronto] 0.5941921472549438\n",
            "loss 0.429 = 0.406 + 0.02 + 0.003 avg prob of [ Toronto] 0.667925238609314\n",
            "loss 0.33 = 0.307 + 0.02 + 0.003 avg prob of [ Toronto] 0.7366981506347656\n",
            "loss 0.249 = 0.227 + 0.02 + 0.003 avg prob of [ Toronto] 0.7979835271835327\n",
            "loss 0.186 = 0.163 + 0.02 + 0.003 avg prob of [ Toronto] 0.8497626185417175\n",
            "loss 0.139 = 0.116 + 0.021 + 0.003 avg prob of [ Toronto] 0.8910545706748962\n",
            "loss 0.105 = 0.081 + 0.021 + 0.003 avg prob of [ Toronto] 0.922174870967865\n",
            "loss 0.082 = 0.057 + 0.022 + 0.003 avg prob of [ Toronto] 0.944534957408905\n",
            "loss 0.066 = 0.041 + 0.023 + 0.003 avg prob of [ Toronto] 0.9600796699523926\n",
            "Init norm 134.62037658691406 | Delta norm 100.96528625488281 | Target norm 166.11163330078125\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The mother tongue of Guy Debord is | Token: ord\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.432 = 4.432 + 0.0 + 0.0 avg prob of [ English] 0.012349920347332954\n",
            "loss 1.529 = 1.527 + 0.002 + 0.001 avg prob of [ English] 0.25205010175704956\n",
            "loss 0.883 = 0.875 + 0.007 + 0.001 avg prob of [ English] 0.45394301414489746\n",
            "loss 0.476 = 0.465 + 0.009 + 0.002 avg prob of [ English] 0.6515112519264221\n",
            "loss 0.231 = 0.218 + 0.011 + 0.002 avg prob of [ English] 0.812936007976532\n",
            "loss 0.128 = 0.112 + 0.013 + 0.002 avg prob of [ English] 0.8966320753097534\n",
            "loss 0.084 = 0.066 + 0.015 + 0.003 avg prob of [ English] 0.9369494318962097\n",
            "loss 0.063 = 0.044 + 0.017 + 0.003 avg prob of [ English] 0.9577188491821289\n",
            "loss 0.052 = 0.031 + 0.018 + 0.003 avg prob of [ English] 0.9694530367851257\n",
            "loss 0.045 = 0.024 + 0.018 + 0.003 avg prob of [ English] 0.9764907360076904\n",
            "Init norm 118.41506958007812 | Delta norm 88.8113021850586 | Target norm 146.03810119628906\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: PowerShell, created by | Token: Shell\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.041 = 9.041 + 0.0 + 0.0 avg prob of [ Apple] 0.00014895241474732757\n",
            "loss 5.167 = 5.163 + 0.003 + 0.001 avg prob of [ Apple] 0.006473280023783445\n",
            "loss 2.268 = 2.259 + 0.009 + 0.001 avg prob of [ Apple] 0.11568807065486908\n",
            "loss 0.661 = 0.644 + 0.015 + 0.001 avg prob of [ Apple] 0.5529083013534546\n",
            "loss 0.2 = 0.176 + 0.023 + 0.002 avg prob of [ Apple] 0.8446816205978394\n",
            "loss 0.099 = 0.067 + 0.03 + 0.002 avg prob of [ Apple] 0.9361498355865479\n",
            "loss 0.074 = 0.036 + 0.036 + 0.002 avg prob of [ Apple] 0.9650791883468628\n",
            "loss 0.067 = 0.024 + 0.041 + 0.002 avg prob of [ Apple] 0.9767494201660156\n",
            "loss 0.066 = 0.017 + 0.046 + 0.003 avg prob of [ Apple] 0.9827584624290466\n",
            "loss 0.064 = 0.014 + 0.048 + 0.003 avg prob of [ Apple] 0.9862090349197388\n",
            "loss 0.062 = 0.012 + 0.047 + 0.003 avg prob of [ Apple] 0.9883634448051453\n",
            "loss 0.059 = 0.01 + 0.047 + 0.003 avg prob of [ Apple] 0.9899888038635254\n",
            "loss 0.057 = 0.009 + 0.045 + 0.003 avg prob of [ Apple] 0.9912559390068054\n",
            "loss 0.055 = 0.008 + 0.044 + 0.003 avg prob of [ Apple] 0.9922689199447632\n",
            "loss 0.052 = 0.007 + 0.043 + 0.003 avg prob of [ Apple] 0.9930953979492188\n",
            "loss 0.05 = 0.006 + 0.041 + 0.003 avg prob of [ Apple] 0.9937801361083984\n",
            "loss 0.048 = 0.006 + 0.04 + 0.003 avg prob of [ Apple] 0.9943546056747437\n",
            "Init norm 140.55467224121094 | Delta norm 105.41600036621094 | Target norm 170.53781127929688\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Kazimierz Nycz is a citizen of | Token: cz\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.353 = 7.353 + 0.0 + 0.0 avg prob of [ Japan] 0.0007423179922625422\n",
            "loss 6.955 = 6.856 + 0.098 + 0.001 avg prob of [ Japan] 0.0012001738650724292\n",
            "loss 6.581 = 6.572 + 0.008 + 0.001 avg prob of [ Japan] 0.0015797553351148963\n",
            "loss 6.103 = 6.09 + 0.012 + 0.001 avg prob of [ Japan] 0.0024524894542992115\n",
            "loss 5.444 = 5.429 + 0.015 + 0.001 avg prob of [ Japan] 0.0045150513760745525\n",
            "loss 4.828 = 4.807 + 0.019 + 0.002 avg prob of [ Japan] 0.008319985121488571\n",
            "loss 4.315 = 4.284 + 0.029 + 0.002 avg prob of [ Japan] 0.014128997921943665\n",
            "loss 3.645 = 3.602 + 0.041 + 0.002 avg prob of [ Japan] 0.028110748156905174\n",
            "loss 2.801 = 2.745 + 0.054 + 0.002 avg prob of [ Japan] 0.06594806909561157\n",
            "loss 2.008 = 1.94 + 0.065 + 0.003 avg prob of [ Japan] 0.14692160487174988\n",
            "loss 1.509 = 1.438 + 0.068 + 0.003 avg prob of [ Japan] 0.24599844217300415\n",
            "loss 1.235 = 1.174 + 0.058 + 0.003 avg prob of [ Japan] 0.32274651527404785\n",
            "loss 1.031 = 0.983 + 0.045 + 0.003 avg prob of [ Japan] 0.3904203772544861\n",
            "loss 0.863 = 0.825 + 0.035 + 0.003 avg prob of [ Japan] 0.4549952447414398\n",
            "loss 0.714 = 0.683 + 0.029 + 0.003 avg prob of [ Japan] 0.5210967063903809\n",
            "loss 0.577 = 0.548 + 0.026 + 0.003 avg prob of [ Japan] 0.5914484858512878\n",
            "loss 0.449 = 0.423 + 0.023 + 0.003 avg prob of [ Japan] 0.6655513048171997\n",
            "loss 0.335 = 0.311 + 0.022 + 0.003 avg prob of [ Japan] 0.7408261299133301\n",
            "loss 0.234 = 0.21 + 0.022 + 0.003 avg prob of [ Japan] 0.816011905670166\n",
            "loss 0.148 = 0.124 + 0.022 + 0.003 avg prob of [ Japan] 0.8874527812004089\n",
            "Init norm 136.4134063720703 | Delta norm 102.31005859375 | Target norm 161.38558959960938\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Anne Fontaine is a native speaker of | Token: aine\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.46 = 5.46 + 0.0 + 0.0 avg prob of [ Dutch] 0.004586097784340382\n",
            "loss 4.467 = 4.464 + 0.002 + 0.001 avg prob of [ Dutch] 0.01194712519645691\n",
            "loss 4.157 = 4.152 + 0.003 + 0.001 avg prob of [ Dutch] 0.016311198472976685\n",
            "loss 3.639 = 3.633 + 0.004 + 0.002 avg prob of [ Dutch] 0.02707323059439659\n",
            "loss 2.832 = 2.824 + 0.005 + 0.002 avg prob of [ Dutch] 0.05957461893558502\n",
            "loss 2.15 = 2.14 + 0.007 + 0.002 avg prob of [ Dutch] 0.11866980791091919\n",
            "loss 1.46 = 1.448 + 0.009 + 0.003 avg prob of [ Dutch] 0.23911914229393005\n",
            "loss 0.86 = 0.847 + 0.01 + 0.003 avg prob of [ Dutch] 0.43387049436569214\n",
            "loss 0.501 = 0.487 + 0.011 + 0.003 avg prob of [ Dutch] 0.6174828410148621\n",
            "loss 0.322 = 0.307 + 0.011 + 0.003 avg prob of [ Dutch] 0.7369346022605896\n",
            "loss 0.226 = 0.211 + 0.012 + 0.003 avg prob of [ Dutch] 0.8102248907089233\n",
            "loss 0.169 = 0.154 + 0.012 + 0.003 avg prob of [ Dutch] 0.8577477335929871\n",
            "loss 0.131 = 0.115 + 0.013 + 0.003 avg prob of [ Dutch] 0.8919081687927246\n",
            "loss 0.103 = 0.087 + 0.013 + 0.003 avg prob of [ Dutch] 0.917062520980835\n",
            "loss 0.083 = 0.067 + 0.013 + 0.003 avg prob of [ Dutch] 0.9356745481491089\n",
            "loss 0.068 = 0.052 + 0.013 + 0.003 avg prob of [ Dutch] 0.9495589137077332\n",
            "loss 0.056 = 0.041 + 0.012 + 0.003 avg prob of [ Dutch] 0.9600329399108887\n",
            "loss 0.048 = 0.033 + 0.012 + 0.003 avg prob of [ Dutch] 0.9680188894271851\n",
            "Init norm 112.6461410522461 | Delta norm 84.48460388183594 | Target norm 138.32998657226562\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Francis de Croisset is | Token: et\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.397 = 4.397 + 0.0 + 0.0 avg prob of [ English] 0.012720189988613129\n",
            "loss 2.416 = 2.413 + 0.002 + 0.001 avg prob of [ English] 0.09232106059789658\n",
            "loss 1.792 = 1.785 + 0.005 + 0.002 avg prob of [ English] 0.17132815718650818\n",
            "loss 1.146 = 1.136 + 0.007 + 0.002 avg prob of [ English] 0.3277819752693176\n",
            "loss 0.552 = 0.535 + 0.014 + 0.003 avg prob of [ English] 0.5918010473251343\n",
            "loss 0.213 = 0.181 + 0.028 + 0.003 avg prob of [ English] 0.8364147543907166\n",
            "loss 0.094 = 0.043 + 0.047 + 0.004 avg prob of [ English] 0.9577804803848267\n",
            "loss 0.058 = 0.009 + 0.045 + 0.004 avg prob of [ English] 0.9915506839752197\n",
            "loss 0.039 = 0.002 + 0.034 + 0.004 avg prob of [ English] 0.9982835650444031\n",
            "Init norm 98.53984069824219 | Delta norm 73.90486907958984 | Target norm 119.77867126464844\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: The official religion of Harun al-Rashid is | Token: id\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.053 = 6.053 + 0.0 + 0.0 avg prob of [ Christianity] 0.002457019407302141\n",
            "loss 4.073 = 4.069 + 0.004 + 0.001 avg prob of [ Christianity] 0.018790213391184807\n",
            "loss 2.568 = 2.56 + 0.007 + 0.001 avg prob of [ Christianity] 0.08385515213012695\n",
            "loss 1.414 = 1.4 + 0.013 + 0.002 avg prob of [ Christianity] 0.2604694366455078\n",
            "loss 0.625 = 0.602 + 0.021 + 0.002 avg prob of [ Christianity] 0.5587489008903503\n",
            "loss 0.299 = 0.269 + 0.028 + 0.003 avg prob of [ Christianity] 0.7662960886955261\n",
            "loss 0.171 = 0.144 + 0.024 + 0.003 avg prob of [ Christianity] 0.8665298819541931\n",
            "loss 0.107 = 0.08 + 0.024 + 0.003 avg prob of [ Christianity] 0.923226535320282\n",
            "loss 0.074 = 0.049 + 0.022 + 0.003 avg prob of [ Christianity] 0.9525505900382996\n",
            "loss 0.057 = 0.033 + 0.021 + 0.003 avg prob of [ Christianity] 0.9675121307373047\n",
            "loss 0.048 = 0.025 + 0.019 + 0.003 avg prob of [ Christianity] 0.9755157232284546\n",
            "Init norm 109.81434631347656 | Delta norm 82.36076354980469 | Target norm 136.009521484375\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: In Serbia, the language spoken is | Token:  Serbia\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.36 = 4.36 + 0.0 + 0.0 avg prob of [ Croatian] 0.013925183564424515\n",
            "loss 2.612 = 2.61 + 0.001 + 0.0 avg prob of [ Croatian] 0.08112742006778717\n",
            "loss 1.714 = 1.71 + 0.003 + 0.001 avg prob of [ Croatian] 0.20080332458019257\n",
            "loss 1.138 = 1.131 + 0.006 + 0.001 avg prob of [ Croatian] 0.347959965467453\n",
            "loss 0.69 = 0.681 + 0.008 + 0.001 avg prob of [ Croatian] 0.5237070322036743\n",
            "loss 0.384 = 0.375 + 0.008 + 0.001 avg prob of [ Croatian] 0.6947044134140015\n",
            "loss 0.209 = 0.199 + 0.009 + 0.002 avg prob of [ Croatian] 0.8215370178222656\n",
            "loss 0.119 = 0.108 + 0.009 + 0.002 avg prob of [ Croatian] 0.8982033729553223\n",
            "loss 0.073 = 0.062 + 0.009 + 0.002 avg prob of [ Croatian] 0.940445601940155\n",
            "loss 0.05 = 0.037 + 0.01 + 0.002 avg prob of [ Croatian] 0.9634754061698914\n",
            "Init norm 159.5494384765625 | Delta norm 110.32333374023438 | Target norm 192.104248046875\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The mother tongue of Alain Savary is | Token: ary\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.455 = 6.455 + 0.0 + 0.0 avg prob of [ Russian] 0.0017301240004599094\n",
            "loss 3.853 = 3.85 + 0.002 + 0.001 avg prob of [ Russian] 0.024124234914779663\n",
            "loss 1.029 = 0.996 + 0.032 + 0.001 avg prob of [ Russian] 0.3877756595611572\n",
            "loss 0.721 = 0.714 + 0.006 + 0.002 avg prob of [ Russian] 0.5006263256072998\n",
            "loss 0.581 = 0.573 + 0.006 + 0.002 avg prob of [ Russian] 0.5708578824996948\n",
            "loss 0.476 = 0.467 + 0.006 + 0.002 avg prob of [ Russian] 0.6316020488739014\n",
            "loss 0.393 = 0.383 + 0.007 + 0.003 avg prob of [ Russian] 0.6852768659591675\n",
            "loss 0.324 = 0.314 + 0.007 + 0.003 avg prob of [ Russian] 0.7333549857139587\n",
            "loss 0.266 = 0.255 + 0.008 + 0.003 avg prob of [ Russian] 0.7767053842544556\n",
            "loss 0.222 = 0.211 + 0.008 + 0.003 avg prob of [ Russian] 0.8112782835960388\n",
            "loss 0.185 = 0.174 + 0.008 + 0.003 avg prob of [ Russian] 0.84173983335495\n",
            "loss 0.154 = 0.142 + 0.008 + 0.003 avg prob of [ Russian] 0.8683123588562012\n",
            "loss 0.128 = 0.116 + 0.008 + 0.003 avg prob of [ Russian] 0.8908448219299316\n",
            "loss 0.107 = 0.095 + 0.009 + 0.003 avg prob of [ Russian] 0.9094958305358887\n",
            "loss 0.091 = 0.079 + 0.009 + 0.003 avg prob of [ Russian] 0.9246758222579956\n",
            "loss 0.078 = 0.065 + 0.009 + 0.003 avg prob of [ Russian] 0.9369252920150757\n",
            "loss 0.068 = 0.055 + 0.01 + 0.003 avg prob of [ Russian] 0.9467967748641968\n",
            "loss 0.06 = 0.046 + 0.01 + 0.003 avg prob of [ Russian] 0.9547863006591797\n",
            "loss 0.053 = 0.04 + 0.01 + 0.003 avg prob of [ Russian] 0.9613067507743835\n",
            "loss 0.048 = 0.034 + 0.011 + 0.003 avg prob of [ Russian] 0.966686487197876\n",
            "Init norm 111.99562072753906 | Delta norm 83.99671936035156 | Target norm 136.5055694580078\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Benin belongs to the continent of | Token: in\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.844 = 5.844 + 0.0 + 0.0 avg prob of [ Europe] 0.003853755071759224\n",
            "loss 1.327 = 1.307 + 0.02 + 0.001 avg prob of [ Europe] 0.2940908968448639\n",
            "loss 0.787 = 0.768 + 0.018 + 0.001 avg prob of [ Europe] 0.48799318075180054\n",
            "loss 0.513 = 0.496 + 0.016 + 0.002 avg prob of [ Europe] 0.6240804195404053\n",
            "loss 0.364 = 0.343 + 0.019 + 0.002 avg prob of [ Europe] 0.7187634706497192\n",
            "loss 0.277 = 0.252 + 0.022 + 0.002 avg prob of [ Europe] 0.7825307846069336\n",
            "loss 0.215 = 0.187 + 0.025 + 0.003 avg prob of [ Europe] 0.8317389488220215\n",
            "loss 0.174 = 0.144 + 0.027 + 0.003 avg prob of [ Europe] 0.867613673210144\n",
            "loss 0.145 = 0.114 + 0.028 + 0.003 avg prob of [ Europe] 0.8932456970214844\n",
            "loss 0.124 = 0.092 + 0.028 + 0.003 avg prob of [ Europe] 0.912240743637085\n",
            "loss 0.107 = 0.076 + 0.028 + 0.003 avg prob of [ Europe] 0.9268571734428406\n",
            "loss 0.094 = 0.064 + 0.027 + 0.003 avg prob of [ Europe] 0.9386018514633179\n",
            "loss 0.083 = 0.054 + 0.026 + 0.003 avg prob of [ Europe] 0.9480392336845398\n",
            "loss 0.074 = 0.045 + 0.025 + 0.003 avg prob of [ Europe] 0.9556101560592651\n",
            "loss 0.067 = 0.039 + 0.025 + 0.003 avg prob of [ Europe] 0.9616658091545105\n",
            "loss 0.061 = 0.034 + 0.024 + 0.003 avg prob of [ Europe] 0.9665020704269409\n",
            "loss 0.056 = 0.03 + 0.023 + 0.003 avg prob of [ Europe] 0.9703754186630249\n",
            "loss 0.052 = 0.027 + 0.022 + 0.003 avg prob of [ Europe] 0.9735069274902344\n",
            "loss 0.049 = 0.024 + 0.021 + 0.003 avg prob of [ Europe] 0.9760788679122925\n",
            "Init norm 116.5075912475586 | Delta norm 87.38069152832031 | Target norm 145.89146423339844\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Aleksey Khomyakov is a native speaker of | Token: akov\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.113 = 4.113 + 0.0 + 0.0 avg prob of [ French] 0.01714545488357544\n",
            "loss 3.305 = 3.296 + 0.008 + 0.001 avg prob of [ French] 0.03834293782711029\n",
            "loss 2.285 = 2.269 + 0.014 + 0.002 avg prob of [ French] 0.10419618338346481\n",
            "loss 1.33 = 1.304 + 0.024 + 0.002 avg prob of [ French] 0.27207404375076294\n",
            "loss 0.746 = 0.706 + 0.038 + 0.003 avg prob of [ French] 0.4944303035736084\n",
            "loss 0.47 = 0.412 + 0.055 + 0.003 avg prob of [ French] 0.6628303527832031\n",
            "loss 0.292 = 0.236 + 0.053 + 0.004 avg prob of [ French] 0.7900625467300415\n",
            "loss 0.203 = 0.16 + 0.04 + 0.004 avg prob of [ French] 0.852653443813324\n",
            "loss 0.15 = 0.115 + 0.032 + 0.004 avg prob of [ French] 0.891647458076477\n",
            "loss 0.115 = 0.084 + 0.028 + 0.004 avg prob of [ French] 0.9195820689201355\n",
            "loss 0.089 = 0.06 + 0.025 + 0.004 avg prob of [ French] 0.9415339231491089\n",
            "loss 0.069 = 0.042 + 0.024 + 0.004 avg prob of [ French] 0.9587280750274658\n",
            "loss 0.055 = 0.029 + 0.022 + 0.004 avg prob of [ French] 0.9712557792663574\n",
            "loss 0.045 = 0.021 + 0.02 + 0.004 avg prob of [ French] 0.9795738458633423\n",
            "Init norm 104.48279571533203 | Delta norm 78.36209869384766 | Target norm 126.38114929199219\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The mother tongue of Jean-Claude Brialy is | Token: aly\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.061 = 6.061 + 0.0 + 0.0 avg prob of [ Russian] 0.0025720931589603424\n",
            "loss 2.858 = 2.844 + 0.013 + 0.001 avg prob of [ Russian] 0.06268917769193649\n",
            "loss 0.509 = 0.479 + 0.029 + 0.001 avg prob of [ Russian] 0.6315951347351074\n",
            "loss 0.377 = 0.34 + 0.036 + 0.002 avg prob of [ Russian] 0.7180702090263367\n",
            "loss 0.336 = 0.296 + 0.038 + 0.002 avg prob of [ Russian] 0.7482559084892273\n",
            "loss 0.285 = 0.247 + 0.035 + 0.002 avg prob of [ Russian] 0.7847856879234314\n",
            "loss 0.231 = 0.197 + 0.031 + 0.003 avg prob of [ Russian] 0.8243348002433777\n",
            "loss 0.183 = 0.152 + 0.027 + 0.003 avg prob of [ Russian] 0.8608340620994568\n",
            "loss 0.144 = 0.117 + 0.024 + 0.003 avg prob of [ Russian] 0.8914558291435242\n",
            "loss 0.114 = 0.089 + 0.021 + 0.003 avg prob of [ Russian] 0.9157438278198242\n",
            "loss 0.091 = 0.069 + 0.019 + 0.003 avg prob of [ Russian] 0.9339994192123413\n",
            "loss 0.074 = 0.054 + 0.017 + 0.003 avg prob of [ Russian] 0.9476081728935242\n",
            "loss 0.062 = 0.044 + 0.015 + 0.003 avg prob of [ Russian] 0.9575631022453308\n",
            "loss 0.052 = 0.036 + 0.013 + 0.003 avg prob of [ Russian] 0.9648237228393555\n",
            "loss 0.045 = 0.03 + 0.011 + 0.003 avg prob of [ Russian] 0.9701848030090332\n",
            "Init norm 114.79713439941406 | Delta norm 86.09786224365234 | Target norm 141.78656005859375\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Shakib Khan follows the religion of | Token:  Khan\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ Buddhism] 0.0004294018726795912\n",
            "loss 6.725 = 6.719 + 0.006 + 0.001 avg prob of [ Buddhism] 0.0014946374576538801\n",
            "loss 5.049 = 5.038 + 0.01 + 0.001 avg prob of [ Buddhism] 0.007072042673826218\n",
            "loss 2.992 = 2.971 + 0.019 + 0.002 avg prob of [ Buddhism] 0.05217829346656799\n",
            "loss 2.02 = 1.99 + 0.027 + 0.002 avg prob of [ Buddhism] 0.1392313539981842\n",
            "loss 1.426 = 1.394 + 0.029 + 0.003 avg prob of [ Buddhism] 0.2527393102645874\n",
            "loss 0.891 = 0.861 + 0.026 + 0.003 avg prob of [ Buddhism] 0.4262275695800781\n",
            "loss 0.54 = 0.511 + 0.026 + 0.003 avg prob of [ Buddhism] 0.6014031171798706\n",
            "loss 0.343 = 0.313 + 0.026 + 0.003 avg prob of [ Buddhism] 0.7316083312034607\n",
            "loss 0.228 = 0.198 + 0.027 + 0.003 avg prob of [ Buddhism] 0.8210587501525879\n",
            "loss 0.164 = 0.132 + 0.028 + 0.003 avg prob of [ Buddhism] 0.8762907981872559\n",
            "loss 0.126 = 0.094 + 0.029 + 0.003 avg prob of [ Buddhism] 0.9104938507080078\n",
            "loss 0.103 = 0.07 + 0.03 + 0.003 avg prob of [ Buddhism] 0.9326820373535156\n",
            "loss 0.086 = 0.054 + 0.029 + 0.003 avg prob of [ Buddhism] 0.9477356672286987\n",
            "loss 0.075 = 0.043 + 0.029 + 0.003 avg prob of [ Buddhism] 0.9582822322845459\n",
            "loss 0.066 = 0.035 + 0.028 + 0.003 avg prob of [ Buddhism] 0.9658501148223877\n",
            "loss 0.06 = 0.029 + 0.027 + 0.003 avg prob of [ Buddhism] 0.9713977575302124\n",
            "loss 0.055 = 0.025 + 0.026 + 0.003 avg prob of [ Buddhism] 0.9755516052246094\n",
            "loss 0.05 = 0.022 + 0.026 + 0.003 avg prob of [ Buddhism] 0.9787282943725586\n",
            "loss 0.047 = 0.019 + 0.025 + 0.003 avg prob of [ Buddhism] 0.9812089800834656\n",
            "Init norm 114.111328125 | Delta norm 85.58349609375 | Target norm 136.7632293701172\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The mother tongue of Akira Kurosawa is | Token: awa\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.472 = 5.472 + 0.0 + 0.0 avg prob of [ French] 0.004491858184337616\n",
            "loss 1.415 = 1.413 + 0.002 + 0.001 avg prob of [ French] 0.25077933073043823\n",
            "loss 0.373 = 0.367 + 0.004 + 0.001 avg prob of [ French] 0.7003211379051208\n",
            "loss 0.266 = 0.258 + 0.007 + 0.002 avg prob of [ French] 0.7773280143737793\n",
            "loss 0.204 = 0.193 + 0.009 + 0.002 avg prob of [ French] 0.82770836353302\n",
            "loss 0.155 = 0.143 + 0.01 + 0.002 avg prob of [ French] 0.8691924810409546\n",
            "loss 0.119 = 0.105 + 0.011 + 0.002 avg prob of [ French] 0.9016749262809753\n",
            "loss 0.093 = 0.079 + 0.012 + 0.003 avg prob of [ French] 0.9253929853439331\n",
            "loss 0.076 = 0.06 + 0.012 + 0.003 avg prob of [ French] 0.9421749114990234\n",
            "loss 0.063 = 0.047 + 0.013 + 0.003 avg prob of [ French] 0.9541144371032715\n",
            "loss 0.055 = 0.04 + 0.012 + 0.003 avg prob of [ French] 0.961324155330658\n",
            "loss 0.049 = 0.034 + 0.012 + 0.003 avg prob of [ French] 0.9667569994926453\n",
            "Init norm 120.89627075195312 | Delta norm 90.67220306396484 | Target norm 149.15524291992188\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Isser Harel, who is a citizen of | Token: arel\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.294 = 9.294 + 0.0 + 0.0 avg prob of [ England] 0.00012600768241100013\n",
            "loss 6.831 = 6.812 + 0.018 + 0.001 avg prob of [ England] 0.0013799918815493584\n",
            "loss 6.202 = 6.165 + 0.036 + 0.001 avg prob of [ England] 0.0026873634196817875\n",
            "loss 5.685 = 5.643 + 0.04 + 0.002 avg prob of [ England] 0.0047297123819589615\n",
            "loss 4.708 = 4.669 + 0.037 + 0.002 avg prob of [ England] 0.012956454418599606\n",
            "loss 3.262 = 3.229 + 0.031 + 0.002 avg prob of [ England] 0.048663556575775146\n",
            "loss 2.394 = 2.362 + 0.029 + 0.002 avg prob of [ England] 0.09933310747146606\n",
            "loss 2.056 = 2.022 + 0.03 + 0.003 avg prob of [ England] 0.13819152116775513\n",
            "loss 1.52 = 1.485 + 0.032 + 0.003 avg prob of [ England] 0.2323163002729416\n",
            "loss 1.018 = 0.98 + 0.035 + 0.003 avg prob of [ England] 0.3796498775482178\n",
            "loss 0.697 = 0.657 + 0.037 + 0.003 avg prob of [ England] 0.521292507648468\n",
            "loss 0.494 = 0.453 + 0.039 + 0.003 avg prob of [ England] 0.6379004716873169\n",
            "loss 0.369 = 0.326 + 0.04 + 0.003 avg prob of [ England] 0.7229010462760925\n",
            "loss 0.287 = 0.244 + 0.04 + 0.003 avg prob of [ England] 0.7843178510665894\n",
            "loss 0.229 = 0.187 + 0.039 + 0.003 avg prob of [ England] 0.8299146890640259\n",
            "loss 0.188 = 0.147 + 0.038 + 0.003 avg prob of [ England] 0.8641160726547241\n",
            "loss 0.157 = 0.117 + 0.037 + 0.003 avg prob of [ England] 0.8897438049316406\n",
            "loss 0.135 = 0.096 + 0.036 + 0.003 avg prob of [ England] 0.9091014862060547\n",
            "loss 0.117 = 0.079 + 0.035 + 0.003 avg prob of [ England] 0.9240366816520691\n",
            "loss 0.104 = 0.066 + 0.034 + 0.003 avg prob of [ England] 0.9358838796615601\n",
            "Init norm 120.20686340332031 | Delta norm 90.1551513671875 | Target norm 147.16175842285156\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Dmitry Rybolovlev is | Token: lev\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 3.846 = 3.846 + 0.0 + 0.0 avg prob of [ French] 0.022517357021570206\n",
            "loss 0.56 = 0.554 + 0.005 + 0.001 avg prob of [ French] 0.5879831314086914\n",
            "loss 0.331 = 0.322 + 0.008 + 0.001 avg prob of [ French] 0.7289940118789673\n",
            "loss 0.199 = 0.188 + 0.01 + 0.001 avg prob of [ French] 0.8307713866233826\n",
            "loss 0.125 = 0.112 + 0.011 + 0.002 avg prob of [ French] 0.8949916362762451\n",
            "loss 0.085 = 0.07 + 0.012 + 0.002 avg prob of [ French] 0.9323572516441345\n",
            "loss 0.063 = 0.047 + 0.013 + 0.002 avg prob of [ French] 0.9540683031082153\n",
            "loss 0.05 = 0.034 + 0.014 + 0.003 avg prob of [ French] 0.9671032428741455\n",
            "loss 0.043 = 0.025 + 0.015 + 0.003 avg prob of [ French] 0.975294291973114\n",
            "Init norm 121.79090881347656 | Delta norm 81.65577697753906 | Target norm 145.4142608642578\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The official religion of Muhammad Ali Pasha is | Token: asha\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.101 = 6.101 + 0.0 + 0.0 avg prob of [ Buddhism] 0.0028558876365423203\n",
            "loss 4.122 = 4.118 + 0.003 + 0.001 avg prob of [ Buddhism] 0.023261766880750656\n",
            "loss 2.542 = 2.532 + 0.01 + 0.001 avg prob of [ Buddhism] 0.11535535752773285\n",
            "loss 1.288 = 1.273 + 0.014 + 0.001 avg prob of [ Buddhism] 0.324684202671051\n",
            "loss 0.692 = 0.674 + 0.016 + 0.002 avg prob of [ Buddhism] 0.5195721387863159\n",
            "loss 0.458 = 0.44 + 0.017 + 0.002 avg prob of [ Buddhism] 0.6476690769195557\n",
            "loss 0.33 = 0.308 + 0.019 + 0.002 avg prob of [ Buddhism] 0.7366211414337158\n",
            "loss 0.247 = 0.219 + 0.026 + 0.003 avg prob of [ Buddhism] 0.8047586679458618\n",
            "loss 0.193 = 0.156 + 0.033 + 0.003 avg prob of [ Buddhism] 0.8560112714767456\n",
            "loss 0.154 = 0.118 + 0.033 + 0.003 avg prob of [ Buddhism] 0.8891503214836121\n",
            "loss 0.124 = 0.09 + 0.031 + 0.003 avg prob of [ Buddhism] 0.9142533540725708\n",
            "loss 0.101 = 0.07 + 0.028 + 0.003 avg prob of [ Buddhism] 0.9325543642044067\n",
            "loss 0.084 = 0.056 + 0.025 + 0.003 avg prob of [ Buddhism] 0.9457677602767944\n",
            "loss 0.072 = 0.046 + 0.023 + 0.003 avg prob of [ Buddhism] 0.9554123878479004\n",
            "loss 0.063 = 0.038 + 0.021 + 0.003 avg prob of [ Buddhism] 0.9626170992851257\n",
            "loss 0.056 = 0.032 + 0.02 + 0.003 avg prob of [ Buddhism] 0.9681522250175476\n",
            "loss 0.051 = 0.028 + 0.02 + 0.003 avg prob of [ Buddhism] 0.9725210070610046\n",
            "loss 0.046 = 0.024 + 0.019 + 0.003 avg prob of [ Buddhism] 0.9760483503341675\n",
            "Init norm 125.40447235107422 | Delta norm 94.05335235595703 | Target norm 151.59799194335938\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Vladimir Mayakovsky is a native speaker of | Token: ovsky\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.606 = 4.606 + 0.0 + 0.0 avg prob of [ French] 0.010427745059132576\n",
            "loss 3.505 = 3.503 + 0.002 + 0.001 avg prob of [ French] 0.03129975125193596\n",
            "loss 1.684 = 1.679 + 0.003 + 0.001 avg prob of [ French] 0.19528019428253174\n",
            "loss 0.718 = 0.711 + 0.005 + 0.002 avg prob of [ French] 0.49632784724235535\n",
            "loss 0.49 = 0.48 + 0.007 + 0.002 avg prob of [ French] 0.6201334595680237\n",
            "loss 0.377 = 0.365 + 0.009 + 0.003 avg prob of [ French] 0.695040225982666\n",
            "loss 0.309 = 0.295 + 0.012 + 0.003 avg prob of [ French] 0.7451657056808472\n",
            "loss 0.266 = 0.249 + 0.014 + 0.004 avg prob of [ French] 0.7799426913261414\n",
            "loss 0.238 = 0.22 + 0.015 + 0.004 avg prob of [ French] 0.8028778433799744\n",
            "loss 0.216 = 0.196 + 0.017 + 0.004 avg prob of [ French] 0.8221742510795593\n",
            "loss 0.197 = 0.175 + 0.018 + 0.004 avg prob of [ French] 0.839292049407959\n",
            "loss 0.179 = 0.157 + 0.019 + 0.004 avg prob of [ French] 0.8551406264305115\n",
            "loss 0.162 = 0.139 + 0.02 + 0.004 avg prob of [ French] 0.8701831698417664\n",
            "loss 0.146 = 0.123 + 0.02 + 0.004 avg prob of [ French] 0.8845920562744141\n",
            "loss 0.13 = 0.107 + 0.019 + 0.004 avg prob of [ French] 0.8983683586120605\n",
            "loss 0.115 = 0.093 + 0.019 + 0.004 avg prob of [ French] 0.9113900065422058\n",
            "loss 0.102 = 0.08 + 0.018 + 0.004 avg prob of [ French] 0.9234108924865723\n",
            "loss 0.09 = 0.068 + 0.019 + 0.004 avg prob of [ French] 0.9341596364974976\n",
            "loss 0.081 = 0.058 + 0.019 + 0.004 avg prob of [ French] 0.9435667991638184\n",
            "loss 0.072 = 0.049 + 0.019 + 0.004 avg prob of [ French] 0.9518064260482788\n",
            "Init norm 105.3930435180664 | Delta norm 79.04478454589844 | Target norm 129.0510711669922\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: The Sopranos premiered on | Token: os\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.851 = 7.851 + 0.0 + 0.0 avg prob of [ ESPN] 0.0004150044987909496\n",
            "loss 5.998 = 5.993 + 0.004 + 0.001 avg prob of [ ESPN] 0.002625620923936367\n",
            "loss 3.876 = 3.866 + 0.008 + 0.001 avg prob of [ ESPN] 0.025072162970900536\n",
            "loss 1.243 = 1.217 + 0.024 + 0.002 avg prob of [ ESPN] 0.3175886273384094\n",
            "loss 0.263 = 0.196 + 0.065 + 0.002 avg prob of [ ESPN] 0.8228342533111572\n",
            "loss 0.152 = 0.059 + 0.091 + 0.003 avg prob of [ ESPN] 0.9429673552513123\n",
            "loss 0.125 = 0.026 + 0.097 + 0.003 avg prob of [ ESPN] 0.974719226360321\n",
            "loss 0.079 = 0.014 + 0.062 + 0.003 avg prob of [ ESPN] 0.9861000776290894\n",
            "loss 0.048 = 0.009 + 0.036 + 0.003 avg prob of [ ESPN] 0.9909281730651855\n",
            "Init norm 119.84698486328125 | Delta norm 89.88523864746094 | Target norm 146.81887817382812\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Tim Cook is employed by | Token:  Cook\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.827 = 11.827 + 0.0 + 0.0 avg prob of [ BBC] 8.829901162243914e-06\n",
            "loss 7.644 = 7.643 + 0.001 + 0.001 avg prob of [ BBC] 0.0005340301431715488\n",
            "loss 5.325 = 5.319 + 0.004 + 0.001 avg prob of [ BBC] 0.005241568200290203\n",
            "loss 4.39 = 4.381 + 0.008 + 0.001 avg prob of [ BBC] 0.013625881634652615\n",
            "loss 3.487 = 3.473 + 0.013 + 0.002 avg prob of [ BBC] 0.032664477825164795\n",
            "loss 2.718 = 2.698 + 0.018 + 0.002 avg prob of [ BBC] 0.06873241066932678\n",
            "loss 2.124 = 2.098 + 0.023 + 0.002 avg prob of [ BBC] 0.12444858253002167\n",
            "loss 1.619 = 1.588 + 0.028 + 0.003 avg prob of [ BBC] 0.20661386847496033\n",
            "loss 1.19 = 1.155 + 0.032 + 0.003 avg prob of [ BBC] 0.3171131908893585\n",
            "loss 0.875 = 0.838 + 0.034 + 0.003 avg prob of [ BBC] 0.4347427785396576\n",
            "loss 0.641 = 0.604 + 0.035 + 0.003 avg prob of [ BBC] 0.548944890499115\n",
            "loss 0.462 = 0.424 + 0.035 + 0.003 avg prob of [ BBC] 0.6563800573348999\n",
            "loss 0.334 = 0.295 + 0.036 + 0.003 avg prob of [ BBC] 0.7464644908905029\n",
            "loss 0.245 = 0.205 + 0.037 + 0.003 avg prob of [ BBC] 0.8164681196212769\n",
            "loss 0.184 = 0.143 + 0.038 + 0.003 avg prob of [ BBC] 0.8682246208190918\n",
            "loss 0.143 = 0.1 + 0.04 + 0.003 avg prob of [ BBC] 0.9053053855895996\n",
            "loss 0.115 = 0.072 + 0.04 + 0.003 avg prob of [ BBC] 0.9313854575157166\n",
            "loss 0.095 = 0.052 + 0.04 + 0.003 avg prob of [ BBC] 0.9495744705200195\n",
            "loss 0.08 = 0.039 + 0.039 + 0.003 avg prob of [ BBC] 0.9622606039047241\n",
            "loss 0.069 = 0.029 + 0.037 + 0.003 avg prob of [ BBC] 0.9711694717407227\n",
            "Init norm 130.96311950683594 | Delta norm 98.22233581542969 | Target norm 158.70994567871094\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Peter Kropotkin is | Token: kin\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.114 = 4.114 + 0.0 + 0.0 avg prob of [ French] 0.017158396542072296\n",
            "loss 0.533 = 0.532 + 0.001 + 0.001 avg prob of [ French] 0.5972194671630859\n",
            "loss 0.19 = 0.187 + 0.002 + 0.001 avg prob of [ French] 0.8303636908531189\n",
            "loss 0.137 = 0.131 + 0.004 + 0.002 avg prob of [ French] 0.8771591186523438\n",
            "loss 0.11 = 0.103 + 0.005 + 0.002 avg prob of [ French] 0.9026486873626709\n",
            "loss 0.091 = 0.082 + 0.006 + 0.002 avg prob of [ French] 0.9213525652885437\n",
            "loss 0.076 = 0.067 + 0.007 + 0.002 avg prob of [ French] 0.935804545879364\n",
            "loss 0.064 = 0.055 + 0.007 + 0.003 avg prob of [ French] 0.9470874071121216\n",
            "loss 0.055 = 0.045 + 0.007 + 0.003 avg prob of [ French] 0.9559516906738281\n",
            "loss 0.048 = 0.038 + 0.007 + 0.003 avg prob of [ French] 0.9629734754562378\n",
            "Init norm 122.58915710449219 | Delta norm 89.80830383300781 | Target norm 146.8917236328125\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Michael Muhammad Knight follows the religion of | Token:  Knight\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.875 = 5.875 + 0.0 + 0.0 avg prob of [ Christianity] 0.003630701918154955\n",
            "loss 4.785 = 4.769 + 0.015 + 0.001 avg prob of [ Christianity] 0.009918388910591602\n",
            "loss 3.434 = 3.407 + 0.026 + 0.001 avg prob of [ Christianity] 0.03599346801638603\n",
            "loss 2.227 = 2.191 + 0.035 + 0.002 avg prob of [ Christianity] 0.11614978313446045\n",
            "loss 1.246 = 1.205 + 0.038 + 0.002 avg prob of [ Christianity] 0.31651461124420166\n",
            "loss 0.513 = 0.469 + 0.041 + 0.003 avg prob of [ Christianity] 0.6413430571556091\n",
            "loss 0.189 = 0.142 + 0.044 + 0.003 avg prob of [ Christianity] 0.8702467679977417\n",
            "loss 0.1 = 0.053 + 0.044 + 0.003 avg prob of [ Christianity] 0.9491571187973022\n",
            "loss 0.074 = 0.03 + 0.041 + 0.003 avg prob of [ Christianity] 0.970169186592102\n",
            "loss 0.061 = 0.02 + 0.037 + 0.003 avg prob of [ Christianity] 0.9798382520675659\n",
            "loss 0.052 = 0.015 + 0.034 + 0.003 avg prob of [ Christianity] 0.9848381280899048\n",
            "loss 0.047 = 0.012 + 0.031 + 0.003 avg prob of [ Christianity] 0.987689197063446\n",
            "Init norm 114.20337677001953 | Delta norm 85.65253448486328 | Target norm 137.3480224609375\n",
            "Computing right vector (v)\n",
            "Lookup index found: 0 | Sentence: Spain's capital city, | Token: Spain\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.371 = 5.371 + 0.0 + 0.0 avg prob of [ Valencia] 0.0056196278892457485\n",
            "loss 3.747 = 3.745 + 0.001 + 0.0 avg prob of [ Valencia] 0.03305329009890556\n",
            "loss 2.143 = 2.139 + 0.004 + 0.0 avg prob of [ Valencia] 0.21250158548355103\n",
            "loss 1.275 = 1.267 + 0.008 + 0.0 avg prob of [ Valencia] 0.5671167373657227\n",
            "loss 1.045 = 1.035 + 0.01 + 0.0 avg prob of [ Valencia] 0.7057350873947144\n",
            "loss 0.954 = 0.942 + 0.013 + 0.0 avg prob of [ Valencia] 0.761766791343689\n",
            "loss 0.899 = 0.885 + 0.015 + 0.0 avg prob of [ Valencia] 0.7920240759849548\n",
            "loss 0.858 = 0.842 + 0.016 + 0.0 avg prob of [ Valencia] 0.8106376528739929\n",
            "loss 0.825 = 0.807 + 0.017 + 0.0 avg prob of [ Valencia] 0.8209956884384155\n",
            "loss 0.796 = 0.778 + 0.018 + 0.0 avg prob of [ Valencia] 0.8266210556030273\n",
            "loss 0.77 = 0.75 + 0.019 + 0.0 avg prob of [ Valencia] 0.8298401832580566\n",
            "loss 0.744 = 0.724 + 0.02 + 0.0 avg prob of [ Valencia] 0.8318530321121216\n",
            "loss 0.718 = 0.697 + 0.02 + 0.0 avg prob of [ Valencia] 0.8332507014274597\n",
            "loss 0.692 = 0.671 + 0.021 + 0.0 avg prob of [ Valencia] 0.8343379497528076\n",
            "loss 0.665 = 0.644 + 0.021 + 0.0 avg prob of [ Valencia] 0.8352834582328796\n",
            "loss 0.639 = 0.617 + 0.021 + 0.0 avg prob of [ Valencia] 0.8361890316009521\n",
            "loss 0.612 = 0.59 + 0.021 + 0.0 avg prob of [ Valencia] 0.8371221423149109\n",
            "loss 0.584 = 0.563 + 0.021 + 0.0 avg prob of [ Valencia] 0.8381340503692627\n",
            "loss 0.557 = 0.535 + 0.021 + 0.0 avg prob of [ Valencia] 0.8392683267593384\n",
            "loss 0.529 = 0.508 + 0.021 + 0.0 avg prob of [ Valencia] 0.8405659198760986\n",
            "Init norm 3850.563720703125 | Delta norm 164.41798400878906 | Target norm 3845.29248046875\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The headquarter of Chinese Academy of Sciences is located in | Token:  Sciences\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.214 = 14.214 + 0.0 + 0.0 avg prob of [ Brunswick] 9.449057642996195e-07\n",
            "loss 12.18 = 12.177 + 0.002 + 0.001 avg prob of [ Brunswick] 5.946968940406805e-06\n",
            "loss 11.035 = 11.025 + 0.008 + 0.001 avg prob of [ Brunswick] 1.816501753637567e-05\n",
            "loss 9.852 = 9.836 + 0.015 + 0.002 avg prob of [ Brunswick] 5.9584606788121164e-05\n",
            "loss 8.632 = 8.61 + 0.02 + 0.002 avg prob of [ Brunswick] 0.00020027213031426072\n",
            "loss 7.332 = 7.302 + 0.028 + 0.002 avg prob of [ Brunswick] 0.0006980460602790117\n",
            "loss 5.834 = 5.788 + 0.044 + 0.003 avg prob of [ Brunswick] 0.0031504619400948286\n",
            "loss 3.901 = 3.831 + 0.067 + 0.003 avg prob of [ Brunswick] 0.022298797965049744\n",
            "loss 3.173 = 3.1 + 0.07 + 0.003 avg prob of [ Brunswick] 0.046344365924596786\n",
            "loss 2.636 = 2.565 + 0.068 + 0.003 avg prob of [ Brunswick] 0.07953368872404099\n",
            "loss 2.078 = 2.008 + 0.067 + 0.003 avg prob of [ Brunswick] 0.13898460566997528\n",
            "loss 1.487 = 1.418 + 0.066 + 0.003 avg prob of [ Brunswick] 0.2495547980070114\n",
            "loss 0.921 = 0.851 + 0.066 + 0.003 avg prob of [ Brunswick] 0.4349699020385742\n",
            "loss 0.489 = 0.421 + 0.065 + 0.003 avg prob of [ Brunswick] 0.6606917381286621\n",
            "loss 0.251 = 0.186 + 0.061 + 0.003 avg prob of [ Brunswick] 0.8311702609062195\n",
            "loss 0.146 = 0.088 + 0.055 + 0.003 avg prob of [ Brunswick] 0.9158527255058289\n",
            "loss 0.101 = 0.05 + 0.047 + 0.003 avg prob of [ Brunswick] 0.9509503841400146\n",
            "loss 0.078 = 0.035 + 0.041 + 0.003 avg prob of [ Brunswick] 0.9658968448638916\n",
            "loss 0.066 = 0.027 + 0.037 + 0.003 avg prob of [ Brunswick] 0.973623514175415\n",
            "loss 0.059 = 0.021 + 0.035 + 0.003 avg prob of [ Brunswick] 0.9790120124816895\n",
            "Init norm 119.75308990478516 | Delta norm 89.8148193359375 | Target norm 139.15650939941406\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Dmitry Pisarev is a native speaker of | Token: v\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.036 = 4.036 + 0.0 + 0.0 avg prob of [ French] 0.018868256360292435\n",
            "loss 3.497 = 3.488 + 0.008 + 0.001 avg prob of [ French] 0.03194087743759155\n",
            "loss 3.084 = 3.079 + 0.003 + 0.001 avg prob of [ French] 0.04750325530767441\n",
            "loss 2.552 = 2.544 + 0.006 + 0.002 avg prob of [ French] 0.08037246763706207\n",
            "loss 1.826 = 1.816 + 0.008 + 0.003 avg prob of [ French] 0.1645495891571045\n",
            "loss 1.164 = 1.142 + 0.019 + 0.003 avg prob of [ French] 0.320781409740448\n",
            "loss 0.667 = 0.634 + 0.029 + 0.003 avg prob of [ French] 0.5316411256790161\n",
            "loss 0.368 = 0.327 + 0.037 + 0.004 avg prob of [ French] 0.72186678647995\n",
            "loss 0.198 = 0.157 + 0.038 + 0.004 avg prob of [ French] 0.8553676605224609\n",
            "loss 0.085 = 0.059 + 0.022 + 0.004 avg prob of [ French] 0.942605197429657\n",
            "loss 0.051 = 0.023 + 0.025 + 0.004 avg prob of [ French] 0.9777389764785767\n",
            "loss 0.038 = 0.011 + 0.023 + 0.004 avg prob of [ French] 0.9892837405204773\n",
            "Init norm 103.11329650878906 | Delta norm 77.33497619628906 | Target norm 122.59518432617188\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Anwar el Sadat follows the religion of | Token: at\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.399 = 6.399 + 0.0 + 0.0 avg prob of [ Christianity] 0.0017285043140873313\n",
            "loss 4.926 = 4.923 + 0.002 + 0.001 avg prob of [ Christianity] 0.007428936660289764\n",
            "loss 3.218 = 3.211 + 0.006 + 0.001 avg prob of [ Christianity] 0.04169141501188278\n",
            "loss 1.602 = 1.589 + 0.011 + 0.002 avg prob of [ Christianity] 0.2264360636472702\n",
            "loss 0.563 = 0.545 + 0.016 + 0.002 avg prob of [ Christianity] 0.6048797369003296\n",
            "loss 0.2 = 0.174 + 0.023 + 0.003 avg prob of [ Christianity] 0.8444101214408875\n",
            "loss 0.113 = 0.082 + 0.028 + 0.003 avg prob of [ Christianity] 0.9221270084381104\n",
            "loss 0.087 = 0.055 + 0.029 + 0.003 avg prob of [ Christianity] 0.9465638995170593\n",
            "loss 0.072 = 0.042 + 0.026 + 0.003 avg prob of [ Christianity] 0.958716094493866\n",
            "loss 0.06 = 0.033 + 0.024 + 0.003 avg prob of [ Christianity] 0.9677143096923828\n",
            "loss 0.052 = 0.026 + 0.022 + 0.003 avg prob of [ Christianity] 0.9744929075241089\n",
            "loss 0.045 = 0.021 + 0.021 + 0.003 avg prob of [ Christianity] 0.9795759916305542\n",
            "Init norm 109.09307861328125 | Delta norm 81.8198013305664 | Target norm 134.4547119140625\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Antarctic ice sheet belongs to the continent of | Token:  sheet\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.327 = 10.327 + 0.0 + 0.0 avg prob of [ Americas] 4.698008706327528e-05\n",
            "loss 8.678 = 8.674 + 0.004 + 0.0 avg prob of [ Americas] 0.00023139888071455061\n",
            "loss 6.852 = 6.844 + 0.007 + 0.001 avg prob of [ Americas] 0.001337823225185275\n",
            "loss 5.382 = 5.37 + 0.011 + 0.001 avg prob of [ Americas] 0.005447381176054478\n",
            "loss 4.211 = 4.193 + 0.017 + 0.001 avg prob of [ Americas] 0.017222486436367035\n",
            "loss 2.963 = 2.926 + 0.035 + 0.002 avg prob of [ Americas] 0.058051250874996185\n",
            "loss 1.799 = 1.747 + 0.049 + 0.002 avg prob of [ Americas] 0.17889416217803955\n",
            "loss 1.019 = 0.959 + 0.058 + 0.002 avg prob of [ Americas] 0.38608527183532715\n",
            "loss 0.512 = 0.441 + 0.068 + 0.002 avg prob of [ Americas] 0.6447412967681885\n",
            "loss 0.23 = 0.147 + 0.081 + 0.002 avg prob of [ Americas] 0.8639401793479919\n",
            "loss 0.143 = 0.055 + 0.085 + 0.002 avg prob of [ Americas] 0.9461450576782227\n",
            "loss 0.109 = 0.019 + 0.088 + 0.002 avg prob of [ Americas] 0.98125159740448\n",
            "loss 0.096 = 0.007 + 0.086 + 0.002 avg prob of [ Americas] 0.9928381443023682\n",
            "loss 0.086 = 0.004 + 0.08 + 0.002 avg prob of [ Americas] 0.9964091181755066\n",
            "loss 0.076 = 0.002 + 0.071 + 0.002 avg prob of [ Americas] 0.9975833892822266\n",
            "loss 0.067 = 0.002 + 0.063 + 0.002 avg prob of [ Americas] 0.9979699850082397\n",
            "loss 0.061 = 0.002 + 0.057 + 0.002 avg prob of [ Americas] 0.9980497360229492\n",
            "loss 0.057 = 0.002 + 0.052 + 0.002 avg prob of [ Americas] 0.9979935884475708\n",
            "loss 0.054 = 0.002 + 0.049 + 0.002 avg prob of [ Americas] 0.9978756308555603\n",
            "loss 0.051 = 0.002 + 0.046 + 0.002 avg prob of [ Americas] 0.9977316856384277\n",
            "Init norm 151.9674072265625 | Delta norm 113.97555541992188 | Target norm 184.2372589111328\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Antoine Bourdelle is a native speaker of | Token: le\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.426 = 5.426 + 0.0 + 0.0 avg prob of [ Dutch] 0.004716180264949799\n",
            "loss 4.109 = 4.106 + 0.002 + 0.001 avg prob of [ Dutch] 0.017159156501293182\n",
            "loss 2.416 = 2.408 + 0.006 + 0.002 avg prob of [ Dutch] 0.09993122518062592\n",
            "loss 1.112 = 1.101 + 0.009 + 0.002 avg prob of [ Dutch] 0.35465162992477417\n",
            "loss 0.613 = 0.598 + 0.012 + 0.003 avg prob of [ Dutch] 0.5607136487960815\n",
            "loss 0.265 = 0.248 + 0.014 + 0.003 avg prob of [ Dutch] 0.7826933860778809\n",
            "loss 0.122 = 0.103 + 0.016 + 0.004 avg prob of [ Dutch] 0.9024442434310913\n",
            "loss 0.09 = 0.07 + 0.016 + 0.004 avg prob of [ Dutch] 0.9326018691062927\n",
            "loss 0.075 = 0.055 + 0.016 + 0.004 avg prob of [ Dutch] 0.9469232559204102\n",
            "loss 0.064 = 0.044 + 0.016 + 0.004 avg prob of [ Dutch] 0.9565310478210449\n",
            "loss 0.057 = 0.037 + 0.016 + 0.004 avg prob of [ Dutch] 0.9639158248901367\n",
            "loss 0.05 = 0.03 + 0.016 + 0.004 avg prob of [ Dutch] 0.9700581431388855\n",
            "loss 0.044 = 0.025 + 0.016 + 0.004 avg prob of [ Dutch] 0.9753298759460449\n",
            "Init norm 97.57704162597656 | Delta norm 73.18279266357422 | Target norm 122.76004028320312\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: What sport does Tim Duncan play? They play | Token:  Duncan\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.648 = 4.648 + 0.0 + 0.0 avg prob of [ hockey] 0.010754741728305817\n",
            "loss 2.045 = 2.042 + 0.002 + 0.001 avg prob of [ hockey] 0.13212063908576965\n",
            "loss 1.137 = 1.131 + 0.006 + 0.001 avg prob of [ hockey] 0.3348258137702942\n",
            "loss 0.798 = 0.789 + 0.007 + 0.001 avg prob of [ hockey] 0.4651009738445282\n",
            "loss 0.649 = 0.641 + 0.007 + 0.002 avg prob of [ hockey] 0.5350503325462341\n",
            "loss 0.561 = 0.552 + 0.006 + 0.002 avg prob of [ hockey] 0.5823342204093933\n",
            "loss 0.485 = 0.476 + 0.006 + 0.002 avg prob of [ hockey] 0.6265508532524109\n",
            "loss 0.414 = 0.405 + 0.006 + 0.003 avg prob of [ hockey] 0.671194314956665\n",
            "loss 0.354 = 0.344 + 0.007 + 0.003 avg prob of [ hockey] 0.7121680974960327\n",
            "loss 0.303 = 0.291 + 0.008 + 0.003 avg prob of [ hockey] 0.7497726678848267\n",
            "loss 0.255 = 0.244 + 0.009 + 0.003 avg prob of [ hockey] 0.785663366317749\n",
            "loss 0.21 = 0.197 + 0.009 + 0.003 avg prob of [ hockey] 0.8221745491027832\n",
            "loss 0.168 = 0.155 + 0.009 + 0.003 avg prob of [ hockey] 0.8569652438163757\n",
            "loss 0.132 = 0.12 + 0.01 + 0.003 avg prob of [ hockey] 0.8877593278884888\n",
            "loss 0.104 = 0.091 + 0.01 + 0.003 avg prob of [ hockey] 0.913038969039917\n",
            "loss 0.083 = 0.07 + 0.01 + 0.003 avg prob of [ hockey] 0.9324202537536621\n",
            "loss 0.068 = 0.055 + 0.01 + 0.003 avg prob of [ hockey] 0.946556031703949\n",
            "loss 0.058 = 0.044 + 0.011 + 0.003 avg prob of [ hockey] 0.9566434621810913\n",
            "loss 0.05 = 0.037 + 0.011 + 0.003 avg prob of [ hockey] 0.9638947248458862\n",
            "loss 0.045 = 0.031 + 0.011 + 0.003 avg prob of [ hockey] 0.9692507982254028\n",
            "Init norm 125.76313018798828 | Delta norm 94.32234954833984 | Target norm 152.4518585205078\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The official language of Bulgaria is | Token:  Bulgaria\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 3.329 = 3.329 + 0.0 + 0.0 avg prob of [ English] 0.04146086797118187\n",
            "loss 1.545 = 1.543 + 0.002 + 0.0 avg prob of [ English] 0.2365919053554535\n",
            "loss 0.696 = 0.688 + 0.007 + 0.001 avg prob of [ English] 0.5259504318237305\n",
            "loss 0.322 = 0.308 + 0.013 + 0.001 avg prob of [ English] 0.7459033727645874\n",
            "loss 0.145 = 0.124 + 0.02 + 0.001 avg prob of [ English] 0.8856198787689209\n",
            "loss 0.07 = 0.045 + 0.024 + 0.001 avg prob of [ English] 0.9565562009811401\n",
            "loss 0.045 = 0.017 + 0.027 + 0.001 avg prob of [ English] 0.9836519956588745\n",
            "Init norm 169.0116729736328 | Delta norm 85.60975646972656 | Target norm 186.90188598632812\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The official religion of Hind bint Utbah is | Token: bah\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.313 = 8.313 + 0.0 + 0.0 avg prob of [ Judaism] 0.0002868466835934669\n",
            "loss 7.558 = 7.527 + 0.03 + 0.001 avg prob of [ Judaism] 0.0006366037996485829\n",
            "loss 6.417 = 6.4 + 0.016 + 0.001 avg prob of [ Judaism] 0.001982118934392929\n",
            "loss 4.561 = 4.522 + 0.037 + 0.002 avg prob of [ Judaism] 0.012687964364886284\n",
            "loss 2.898 = 2.846 + 0.05 + 0.002 avg prob of [ Judaism] 0.07111522555351257\n",
            "loss 1.494 = 1.445 + 0.047 + 0.002 avg prob of [ Judaism] 0.2772299647331238\n",
            "loss 0.758 = 0.708 + 0.047 + 0.003 avg prob of [ Judaism] 0.523423433303833\n",
            "loss 0.396 = 0.342 + 0.051 + 0.003 avg prob of [ Judaism] 0.7197599411010742\n",
            "loss 0.239 = 0.181 + 0.055 + 0.003 avg prob of [ Judaism] 0.8373631238937378\n",
            "loss 0.174 = 0.113 + 0.058 + 0.003 avg prob of [ Judaism] 0.893996000289917\n",
            "loss 0.139 = 0.076 + 0.06 + 0.003 avg prob of [ Judaism] 0.9274724721908569\n",
            "loss 0.118 = 0.054 + 0.061 + 0.003 avg prob of [ Judaism] 0.9478634595870972\n",
            "loss 0.104 = 0.04 + 0.061 + 0.003 avg prob of [ Judaism] 0.9608098268508911\n",
            "loss 0.094 = 0.031 + 0.06 + 0.003 avg prob of [ Judaism] 0.9694188833236694\n",
            "loss 0.086 = 0.025 + 0.058 + 0.003 avg prob of [ Judaism] 0.9754205942153931\n",
            "loss 0.079 = 0.02 + 0.055 + 0.003 avg prob of [ Judaism] 0.9797968864440918\n",
            "loss 0.074 = 0.017 + 0.053 + 0.003 avg prob of [ Judaism] 0.983123779296875\n",
            "loss 0.069 = 0.014 + 0.051 + 0.003 avg prob of [ Judaism] 0.9857487678527832\n",
            "loss 0.066 = 0.012 + 0.05 + 0.003 avg prob of [ Judaism] 0.9878849983215332\n",
            "loss 0.063 = 0.01 + 0.049 + 0.003 avg prob of [ Judaism] 0.9896642565727234\n",
            "Init norm 112.55072021484375 | Delta norm 84.41303253173828 | Target norm 135.2965087890625\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Case Western Reserve University is based in | Token:  University\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.559 = 12.559 + 0.0 + 0.0 avg prob of [ Amsterdam] 9.944585144694429e-06\n",
            "loss 11.085 = 11.084 + 0.001 + 0.001 avg prob of [ Amsterdam] 3.029434083146043e-05\n",
            "loss 9.96 = 9.955 + 0.004 + 0.001 avg prob of [ Amsterdam] 7.20546959200874e-05\n",
            "loss 8.134 = 8.122 + 0.01 + 0.002 avg prob of [ Amsterdam] 0.00034906191285699606\n",
            "loss 5.513 = 5.493 + 0.018 + 0.002 avg prob of [ Amsterdam] 0.005420117639005184\n",
            "loss 4.098 = 4.071 + 0.024 + 0.002 avg prob of [ Amsterdam] 0.02179836481809616\n",
            "loss 2.558 = 2.523 + 0.033 + 0.003 avg prob of [ Amsterdam] 0.10206077992916107\n",
            "loss 1.727 = 1.666 + 0.058 + 0.003 avg prob of [ Amsterdam] 0.21799683570861816\n",
            "loss 1.27 = 1.192 + 0.075 + 0.003 avg prob of [ Amsterdam] 0.32886838912963867\n",
            "loss 0.938 = 0.861 + 0.074 + 0.003 avg prob of [ Amsterdam] 0.4409107565879822\n",
            "loss 0.668 = 0.595 + 0.07 + 0.003 avg prob of [ Amsterdam] 0.5613020658493042\n",
            "loss 0.463 = 0.392 + 0.068 + 0.003 avg prob of [ Amsterdam] 0.6800904273986816\n",
            "loss 0.323 = 0.249 + 0.071 + 0.003 avg prob of [ Amsterdam] 0.7817776203155518\n",
            "loss 0.236 = 0.156 + 0.077 + 0.003 avg prob of [ Amsterdam] 0.8569933772087097\n",
            "loss 0.177 = 0.099 + 0.074 + 0.003 avg prob of [ Amsterdam] 0.906225860118866\n",
            "loss 0.131 = 0.067 + 0.061 + 0.003 avg prob of [ Amsterdam] 0.9359720945358276\n",
            "loss 0.099 = 0.048 + 0.048 + 0.003 avg prob of [ Amsterdam] 0.9537264704704285\n",
            "loss 0.08 = 0.036 + 0.041 + 0.003 avg prob of [ Amsterdam] 0.9647862911224365\n",
            "loss 0.069 = 0.029 + 0.038 + 0.003 avg prob of [ Amsterdam] 0.9721047878265381\n",
            "loss 0.062 = 0.023 + 0.035 + 0.003 avg prob of [ Amsterdam] 0.9773468971252441\n",
            "Init norm 119.84658813476562 | Delta norm 89.88494110107422 | Target norm 145.9627227783203\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Polina Zherebtsova is a native speaker of | Token: va\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.525 = 4.525 + 0.0 + 0.0 avg prob of [ French] 0.012045717798173428\n",
            "loss 3.274 = 3.271 + 0.001 + 0.001 avg prob of [ French] 0.03982183337211609\n",
            "loss 1.921 = 1.902 + 0.018 + 0.002 avg prob of [ French] 0.15057487785816193\n",
            "loss 1.022 = 0.981 + 0.038 + 0.002 avg prob of [ French] 0.3766065537929535\n",
            "loss 0.235 = 0.176 + 0.056 + 0.003 avg prob of [ French] 0.8397852778434753\n",
            "loss 0.106 = 0.048 + 0.055 + 0.003 avg prob of [ French] 0.9536696672439575\n",
            "loss 0.084 = 0.029 + 0.051 + 0.004 avg prob of [ French] 0.9710904955863953\n",
            "loss 0.075 = 0.018 + 0.054 + 0.004 avg prob of [ French] 0.9823619723320007\n",
            "loss 0.068 = 0.011 + 0.054 + 0.004 avg prob of [ French] 0.9892351031303406\n",
            "loss 0.065 = 0.007 + 0.054 + 0.004 avg prob of [ French] 0.9928412437438965\n",
            "loss 0.062 = 0.005 + 0.054 + 0.004 avg prob of [ French] 0.9948186278343201\n",
            "loss 0.06 = 0.004 + 0.053 + 0.004 avg prob of [ French] 0.9960439205169678\n",
            "loss 0.058 = 0.003 + 0.051 + 0.004 avg prob of [ French] 0.9968618750572205\n",
            "loss 0.054 = 0.003 + 0.048 + 0.004 avg prob of [ French] 0.9974225759506226\n",
            "loss 0.059 = 0.002 + 0.053 + 0.004 avg prob of [ French] 0.9978052973747253\n",
            "loss 0.054 = 0.002 + 0.049 + 0.004 avg prob of [ French] 0.9981376528739929\n",
            "loss 0.055 = 0.002 + 0.05 + 0.004 avg prob of [ French] 0.998343825340271\n",
            "loss 0.055 = 0.002 + 0.049 + 0.004 avg prob of [ French] 0.998487651348114\n",
            "loss 0.053 = 0.001 + 0.048 + 0.004 avg prob of [ French] 0.9985957145690918\n",
            "loss 0.052 = 0.001 + 0.047 + 0.004 avg prob of [ French] 0.9986828565597534\n",
            "Init norm 100.36373901367188 | Delta norm 75.2728042602539 | Target norm 122.41635131835938\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Harvard Medical School is headquartered in | Token:  School\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.684 = 10.684 + 0.0 + 0.0 avg prob of [ Birmingham] 2.999438402184751e-05\n",
            "loss 9.193 = 9.188 + 0.005 + 0.001 avg prob of [ Birmingham] 0.00012242677621543407\n",
            "loss 7.285 = 7.263 + 0.02 + 0.001 avg prob of [ Birmingham] 0.0007456418825313449\n",
            "loss 6.273 = 6.241 + 0.031 + 0.001 avg prob of [ Birmingham] 0.0020019980147480965\n",
            "loss 5.709 = 5.672 + 0.035 + 0.002 avg prob of [ Birmingham] 0.0035886045079678297\n",
            "loss 5.013 = 4.977 + 0.034 + 0.002 avg prob of [ Birmingham] 0.0071083917282521725\n",
            "loss 4.027 = 3.991 + 0.034 + 0.002 avg prob of [ Birmingham] 0.019058749079704285\n",
            "loss 2.674 = 2.635 + 0.036 + 0.003 avg prob of [ Birmingham] 0.07356026023626328\n",
            "loss 1.72 = 1.678 + 0.039 + 0.003 avg prob of [ Birmingham] 0.18889278173446655\n",
            "loss 0.965 = 0.921 + 0.04 + 0.003 avg prob of [ Birmingham] 0.40139561891555786\n",
            "loss 0.394 = 0.352 + 0.039 + 0.003 avg prob of [ Birmingham] 0.705678403377533\n",
            "loss 0.133 = 0.093 + 0.036 + 0.003 avg prob of [ Birmingham] 0.9114636182785034\n",
            "loss 0.068 = 0.032 + 0.033 + 0.003 avg prob of [ Birmingham] 0.9689912796020508\n",
            "loss 0.05 = 0.018 + 0.029 + 0.003 avg prob of [ Birmingham] 0.9823797941207886\n",
            "Init norm 123.88846588134766 | Delta norm 92.91635131835938 | Target norm 149.951904296875\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The mother tongue of Vladimir Putin is | Token:  Putin\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.692 = 8.692 + 0.0 + 0.0 avg prob of [ Swedish] 0.0002346732944715768\n",
            "loss 6.289 = 6.288 + 0.001 + 0.0 avg prob of [ Swedish] 0.002035129349678755\n",
            "loss 4.094 = 4.091 + 0.003 + 0.001 avg prob of [ Swedish] 0.01724506914615631\n",
            "loss 1.882 = 1.875 + 0.006 + 0.001 avg prob of [ Swedish] 0.15769171714782715\n",
            "loss 0.897 = 0.886 + 0.01 + 0.001 avg prob of [ Swedish] 0.4196188449859619\n",
            "loss 0.612 = 0.599 + 0.012 + 0.002 avg prob of [ Swedish] 0.5560676455497742\n",
            "loss 0.447 = 0.431 + 0.014 + 0.002 avg prob of [ Swedish] 0.6545120477676392\n",
            "loss 0.333 = 0.316 + 0.015 + 0.002 avg prob of [ Swedish] 0.7321944236755371\n",
            "loss 0.254 = 0.236 + 0.016 + 0.002 avg prob of [ Swedish] 0.7916576266288757\n",
            "loss 0.199 = 0.18 + 0.016 + 0.003 avg prob of [ Swedish] 0.8364022970199585\n",
            "loss 0.152 = 0.135 + 0.014 + 0.003 avg prob of [ Swedish] 0.8746623992919922\n",
            "loss 0.117 = 0.102 + 0.013 + 0.003 avg prob of [ Swedish] 0.9035464525222778\n",
            "loss 0.092 = 0.078 + 0.011 + 0.003 avg prob of [ Swedish] 0.9249241352081299\n",
            "loss 0.074 = 0.061 + 0.01 + 0.003 avg prob of [ Swedish] 0.9407002925872803\n",
            "loss 0.061 = 0.049 + 0.009 + 0.003 avg prob of [ Swedish] 0.9524039030075073\n",
            "loss 0.051 = 0.04 + 0.009 + 0.003 avg prob of [ Swedish] 0.9611777663230896\n",
            "loss 0.044 = 0.033 + 0.008 + 0.003 avg prob of [ Swedish] 0.9678395986557007\n",
            "Init norm 145.47418212890625 | Delta norm 109.10563659667969 | Target norm 174.73793029785156\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The native language of Anna Bijns is | Token: ns\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.952 = 10.952 + 0.0 + 0.0 avg prob of [ Persian] 2.237789158243686e-05\n",
            "loss 7.132 = 7.131 + 0.0 + 0.001 avg prob of [ Persian] 0.0009220146457664669\n",
            "loss 6.202 = 6.2 + 0.001 + 0.001 avg prob of [ Persian] 0.0021514841355383396\n",
            "loss 6.115 = 6.109 + 0.005 + 0.002 avg prob of [ Persian] 0.0023468895815312862\n",
            "loss 5.987 = 5.974 + 0.01 + 0.002 avg prob of [ Persian] 0.0026661287993192673\n",
            "loss 5.734 = 5.72 + 0.011 + 0.003 avg prob of [ Persian] 0.0033985998015850782\n",
            "loss 5.347 = 5.333 + 0.01 + 0.003 avg prob of [ Persian] 0.004886057693511248\n",
            "loss 5.14 = 5.126 + 0.01 + 0.003 avg prob of [ Persian] 0.00749415485188365\n",
            "loss 4.62 = 4.612 + 0.005 + 0.003 avg prob of [ Persian] 0.010493608191609383\n",
            "loss 4.189 = 4.182 + 0.003 + 0.003 avg prob of [ Persian] 0.015355466865003109\n",
            "loss 3.493 = 3.486 + 0.004 + 0.003 avg prob of [ Persian] 0.030966317281126976\n",
            "loss 2.455 = 2.446 + 0.006 + 0.003 avg prob of [ Persian] 0.08830216526985168\n",
            "loss 1.347 = 1.335 + 0.009 + 0.003 avg prob of [ Persian] 0.2740851640701294\n",
            "loss 0.187 = 0.175 + 0.008 + 0.003 avg prob of [ Persian] 0.8495904207229614\n",
            "loss 0.043 = 0.033 + 0.007 + 0.003 avg prob of [ Persian] 0.9682337641716003\n",
            "Init norm 112.38290405273438 | Delta norm 84.28717803955078 | Target norm 137.819091796875\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The mother tongue of Pierre Laval is | Token: aval\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.082 = 9.082 + 0.0 + 0.0 avg prob of [ Swedish] 0.0001452049327781424\n",
            "loss 7.212 = 7.159 + 0.053 + 0.001 avg prob of [ Swedish] 0.0008945211302489042\n",
            "loss 6.664 = 6.59 + 0.073 + 0.001 avg prob of [ Swedish] 0.0015207747928798199\n",
            "loss 6.364 = 6.316 + 0.046 + 0.002 avg prob of [ Swedish] 0.0019973297603428364\n",
            "loss 5.859 = 5.825 + 0.032 + 0.002 avg prob of [ Swedish] 0.0033487286418676376\n",
            "loss 5.192 = 5.162 + 0.028 + 0.002 avg prob of [ Swedish] 0.006460477598011494\n",
            "loss 4.244 = 4.214 + 0.028 + 0.003 avg prob of [ Swedish] 0.015618620440363884\n",
            "loss 2.768 = 2.736 + 0.029 + 0.003 avg prob of [ Swedish] 0.06694860756397247\n",
            "loss 1.022 = 0.989 + 0.03 + 0.003 avg prob of [ Swedish] 0.381106972694397\n",
            "loss 0.413 = 0.377 + 0.032 + 0.003 avg prob of [ Swedish] 0.6908054351806641\n",
            "loss 0.196 = 0.158 + 0.035 + 0.003 avg prob of [ Swedish] 0.8558074831962585\n",
            "loss 0.106 = 0.068 + 0.035 + 0.003 avg prob of [ Swedish] 0.9345372915267944\n",
            "loss 0.069 = 0.032 + 0.034 + 0.003 avg prob of [ Swedish] 0.9689888954162598\n",
            "loss 0.052 = 0.017 + 0.032 + 0.003 avg prob of [ Swedish] 0.9831908941268921\n",
            "loss 0.043 = 0.01 + 0.03 + 0.003 avg prob of [ Swedish] 0.9897090792655945\n",
            "Init norm 121.15555572509766 | Delta norm 90.86666870117188 | Target norm 151.59779357910156\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Wilt Chamberlain is a professional | Token:  Chamberlain\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.161 = 6.161 + 0.0 + 0.0 avg prob of [ football] 0.0025188110303133726\n",
            "loss 3.274 = 3.27 + 0.003 + 0.001 avg prob of [ football] 0.05039123818278313\n",
            "loss 1.504 = 1.49 + 0.012 + 0.001 avg prob of [ football] 0.2792927622795105\n",
            "loss 0.589 = 0.567 + 0.021 + 0.002 avg prob of [ football] 0.6111962795257568\n",
            "loss 0.208 = 0.179 + 0.027 + 0.002 avg prob of [ football] 0.8450703024864197\n",
            "loss 0.098 = 0.065 + 0.03 + 0.002 avg prob of [ football] 0.9376157522201538\n",
            "loss 0.065 = 0.029 + 0.033 + 0.003 avg prob of [ football] 0.971057116985321\n",
            "loss 0.057 = 0.019 + 0.035 + 0.003 avg prob of [ football] 0.9816130995750427\n",
            "loss 0.053 = 0.015 + 0.036 + 0.003 avg prob of [ football] 0.9854642748832703\n",
            "loss 0.048 = 0.012 + 0.032 + 0.003 avg prob of [ football] 0.9878754615783691\n",
            "Init norm 123.848876953125 | Delta norm 92.88665771484375 | Target norm 148.87899780273438\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Grzegorz Lato holds a citizenship from | Token: o\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.842 = 6.842 + 0.0 + 0.0 avg prob of [ Japan] 0.0012287839781492949\n",
            "loss 5.228 = 5.197 + 0.03 + 0.001 avg prob of [ Japan] 0.006214351858943701\n",
            "loss 1.858 = 1.801 + 0.055 + 0.001 avg prob of [ Japan] 0.18039312958717346\n",
            "loss 0.589 = 0.516 + 0.071 + 0.002 avg prob of [ Japan] 0.6001052856445312\n",
            "loss 0.487 = 0.398 + 0.087 + 0.002 avg prob of [ Japan] 0.6738240122795105\n",
            "loss 0.409 = 0.303 + 0.104 + 0.002 avg prob of [ Japan] 0.739848792552948\n",
            "loss 0.328 = 0.217 + 0.108 + 0.003 avg prob of [ Japan] 0.8054684996604919\n",
            "loss 0.251 = 0.148 + 0.1 + 0.003 avg prob of [ Japan] 0.8628391623497009\n",
            "loss 0.192 = 0.099 + 0.09 + 0.003 avg prob of [ Japan] 0.9056110382080078\n",
            "loss 0.15 = 0.067 + 0.08 + 0.003 avg prob of [ Japan] 0.9349393844604492\n",
            "loss 0.122 = 0.047 + 0.071 + 0.003 avg prob of [ Japan] 0.9539734721183777\n",
            "loss 0.103 = 0.035 + 0.065 + 0.003 avg prob of [ Japan] 0.9660677909851074\n",
            "loss 0.089 = 0.026 + 0.06 + 0.003 avg prob of [ Japan] 0.9738864898681641\n",
            "loss 0.08 = 0.021 + 0.056 + 0.003 avg prob of [ Japan] 0.9791439771652222\n",
            "loss 0.074 = 0.017 + 0.054 + 0.003 avg prob of [ Japan] 0.9828580617904663\n",
            "loss 0.07 = 0.014 + 0.053 + 0.003 avg prob of [ Japan] 0.985619306564331\n",
            "loss 0.068 = 0.012 + 0.052 + 0.003 avg prob of [ Japan] 0.987768828868866\n",
            "loss 0.066 = 0.011 + 0.052 + 0.003 avg prob of [ Japan] 0.9895046949386597\n",
            "loss 0.064 = 0.009 + 0.052 + 0.003 avg prob of [ Japan] 0.9909416437149048\n",
            "loss 0.063 = 0.008 + 0.052 + 0.003 avg prob of [ Japan] 0.9921481013298035\n",
            "Init norm 113.33477020263672 | Delta norm 85.0010757446289 | Target norm 138.82327270507812\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Austria-Hungary, which has the capital | Token: ary\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.54 = 9.54 + 0.0 + 0.0 avg prob of [ Baghdad] 8.847621211316437e-05\n",
            "loss 6.203 = 6.2 + 0.002 + 0.001 avg prob of [ Baghdad] 0.003079407848417759\n",
            "loss 2.863 = 2.852 + 0.009 + 0.001 avg prob of [ Baghdad] 0.11619456857442856\n",
            "loss 1.533 = 1.51 + 0.021 + 0.002 avg prob of [ Baghdad] 0.38623496890068054\n",
            "loss 0.972 = 0.94 + 0.029 + 0.002 avg prob of [ Baghdad] 0.5507426857948303\n",
            "loss 0.634 = 0.597 + 0.035 + 0.003 avg prob of [ Baghdad] 0.6422809958457947\n",
            "loss 0.41 = 0.368 + 0.039 + 0.003 avg prob of [ Baghdad] 0.7221149206161499\n",
            "loss 0.277 = 0.231 + 0.043 + 0.003 avg prob of [ Baghdad] 0.7995750308036804\n",
            "loss 0.2 = 0.153 + 0.044 + 0.003 avg prob of [ Baghdad] 0.8596470355987549\n",
            "loss 0.149 = 0.102 + 0.044 + 0.003 avg prob of [ Baghdad] 0.9035180807113647\n",
            "loss 0.116 = 0.07 + 0.043 + 0.003 avg prob of [ Baghdad] 0.9329315423965454\n",
            "loss 0.095 = 0.049 + 0.043 + 0.003 avg prob of [ Baghdad] 0.9518576860427856\n",
            "loss 0.081 = 0.037 + 0.041 + 0.003 avg prob of [ Baghdad] 0.9639307856559753\n",
            "loss 0.072 = 0.029 + 0.04 + 0.003 avg prob of [ Baghdad] 0.9717304706573486\n",
            "loss 0.065 = 0.023 + 0.038 + 0.003 avg prob of [ Baghdad] 0.9768804907798767\n",
            "loss 0.06 = 0.02 + 0.037 + 0.003 avg prob of [ Baghdad] 0.9803599715232849\n",
            "loss 0.056 = 0.017 + 0.035 + 0.003 avg prob of [ Baghdad] 0.9827598929405212\n",
            "loss 0.052 = 0.016 + 0.033 + 0.003 avg prob of [ Baghdad] 0.9844478368759155\n",
            "loss 0.049 = 0.014 + 0.031 + 0.003 avg prob of [ Baghdad] 0.9856618642807007\n",
            "Init norm 119.13900756835938 | Delta norm 89.35425567626953 | Target norm 143.6086883544922\n",
            "Computing right vector (v)\n",
            "Lookup index found: 11 | Sentence: The mother tongue of Marc-Philippe Daubresse is | Token: se\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.543 = 6.543 + 0.0 + 0.0 avg prob of [ Russian] 0.0014785975217819214\n",
            "loss 3.75 = 3.745 + 0.004 + 0.001 avg prob of [ Russian] 0.024118266999721527\n",
            "loss 0.885 = 0.878 + 0.006 + 0.002 avg prob of [ Russian] 0.4255177974700928\n",
            "loss 0.535 = 0.524 + 0.009 + 0.002 avg prob of [ Russian] 0.6006935834884644\n",
            "loss 0.381 = 0.367 + 0.011 + 0.003 avg prob of [ Russian] 0.6994552612304688\n",
            "loss 0.284 = 0.267 + 0.013 + 0.003 avg prob of [ Russian] 0.7700767517089844\n",
            "loss 0.22 = 0.201 + 0.016 + 0.003 avg prob of [ Russian] 0.8209370374679565\n",
            "loss 0.174 = 0.153 + 0.017 + 0.004 avg prob of [ Russian] 0.859865665435791\n",
            "loss 0.137 = 0.116 + 0.017 + 0.004 avg prob of [ Russian] 0.8914411067962646\n",
            "loss 0.11 = 0.09 + 0.016 + 0.004 avg prob of [ Russian] 0.9150604009628296\n",
            "loss 0.09 = 0.071 + 0.016 + 0.004 avg prob of [ Russian] 0.9323906302452087\n",
            "loss 0.075 = 0.057 + 0.015 + 0.004 avg prob of [ Russian] 0.9451813697814941\n",
            "loss 0.065 = 0.047 + 0.014 + 0.004 avg prob of [ Russian] 0.9547687768936157\n",
            "loss 0.056 = 0.039 + 0.014 + 0.004 avg prob of [ Russian] 0.9620927572250366\n",
            "loss 0.05 = 0.033 + 0.013 + 0.004 avg prob of [ Russian] 0.9677945971488953\n",
            "Init norm 101.81201171875 | Delta norm 76.3590087890625 | Target norm 124.98757934570312\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: In United Kingdom, the language spoken is | Token:  Kingdom\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.891 = 10.891 + 0.0 + 0.0 avg prob of [ Finnish] 2.456603033351712e-05\n",
            "loss 7.643 = 7.641 + 0.002 + 0.001 avg prob of [ Finnish] 0.0007305372855626047\n",
            "loss 5.706 = 5.7 + 0.005 + 0.001 avg prob of [ Finnish] 0.005006919149309397\n",
            "loss 4.438 = 4.429 + 0.008 + 0.001 avg prob of [ Finnish] 0.016794664785265923\n",
            "loss 3.273 = 3.261 + 0.011 + 0.002 avg prob of [ Finnish] 0.051613759249448776\n",
            "loss 2.395 = 2.38 + 0.013 + 0.002 avg prob of [ Finnish] 0.11944173276424408\n",
            "loss 1.814 = 1.796 + 0.016 + 0.002 avg prob of [ Finnish] 0.20287063717842102\n",
            "loss 1.43 = 1.41 + 0.018 + 0.003 avg prob of [ Finnish] 0.281783789396286\n",
            "loss 1.156 = 1.134 + 0.019 + 0.003 avg prob of [ Finnish] 0.3539300858974457\n",
            "loss 0.958 = 0.936 + 0.019 + 0.003 avg prob of [ Finnish] 0.418811172246933\n",
            "loss 0.779 = 0.758 + 0.019 + 0.003 avg prob of [ Finnish] 0.4893682599067688\n",
            "loss 0.611 = 0.589 + 0.019 + 0.003 avg prob of [ Finnish] 0.5689294338226318\n",
            "loss 0.459 = 0.437 + 0.019 + 0.003 avg prob of [ Finnish] 0.6546047925949097\n",
            "loss 0.332 = 0.309 + 0.02 + 0.003 avg prob of [ Finnish] 0.7383993864059448\n",
            "loss 0.237 = 0.213 + 0.021 + 0.003 avg prob of [ Finnish] 0.8100614547729492\n",
            "loss 0.171 = 0.147 + 0.021 + 0.003 avg prob of [ Finnish] 0.8639206886291504\n",
            "loss 0.128 = 0.104 + 0.022 + 0.003 avg prob of [ Finnish] 0.9016104936599731\n",
            "loss 0.1 = 0.075 + 0.022 + 0.003 avg prob of [ Finnish] 0.9278043508529663\n",
            "loss 0.079 = 0.055 + 0.021 + 0.003 avg prob of [ Finnish] 0.9464899897575378\n",
            "loss 0.064 = 0.041 + 0.02 + 0.003 avg prob of [ Finnish] 0.9602162837982178\n",
            "Init norm 134.42799377441406 | Delta norm 100.82099151611328 | Target norm 164.31103515625\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Pete Rose is a professional | Token:  Rose\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.775 = 5.775 + 0.0 + 0.0 avg prob of [ football] 0.0036832415498793125\n",
            "loss 0.705 = 0.699 + 0.005 + 0.001 avg prob of [ football] 0.5403277277946472\n",
            "loss 0.375 = 0.366 + 0.008 + 0.001 avg prob of [ football] 0.713447093963623\n",
            "loss 0.251 = 0.239 + 0.01 + 0.001 avg prob of [ football] 0.7962848544120789\n",
            "loss 0.169 = 0.155 + 0.012 + 0.002 avg prob of [ football] 0.8599005937576294\n",
            "loss 0.119 = 0.103 + 0.014 + 0.002 avg prob of [ football] 0.9034525752067566\n",
            "loss 0.09 = 0.072 + 0.016 + 0.002 avg prob of [ football] 0.9311623573303223\n",
            "loss 0.073 = 0.053 + 0.018 + 0.002 avg prob of [ football] 0.9486274719238281\n",
            "loss 0.063 = 0.041 + 0.019 + 0.003 avg prob of [ football] 0.9599597454071045\n",
            "loss 0.056 = 0.033 + 0.02 + 0.003 avg prob of [ football] 0.9676570296287537\n",
            "loss 0.051 = 0.027 + 0.021 + 0.003 avg prob of [ football] 0.9731547236442566\n",
            "loss 0.048 = 0.023 + 0.022 + 0.003 avg prob of [ football] 0.9770628213882446\n",
            "Init norm 125.1395492553711 | Delta norm 93.85465240478516 | Target norm 156.6085968017578\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: The Wire was originally aired on | Token:  Wire\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.162 = 10.162 + 0.0 + 0.0 avg prob of [ History] 0.00010255941742798313\n",
            "loss 7.97 = 7.967 + 0.003 + 0.0 avg prob of [ History] 0.0004030525160487741\n",
            "loss 6.856 = 6.852 + 0.003 + 0.001 avg prob of [ History] 0.0013658097013831139\n",
            "loss 5.576 = 5.571 + 0.004 + 0.001 avg prob of [ History] 0.005390755366533995\n",
            "loss 4.048 = 4.038 + 0.009 + 0.001 avg prob of [ History] 0.021326204761862755\n",
            "loss 2.65 = 2.635 + 0.014 + 0.002 avg prob of [ History] 0.07556763291358948\n",
            "loss 1.528 = 1.507 + 0.019 + 0.002 avg prob of [ History] 0.22403991222381592\n",
            "loss 0.708 = 0.684 + 0.022 + 0.002 avg prob of [ History] 0.5068120360374451\n",
            "loss 0.291 = 0.265 + 0.024 + 0.002 avg prob of [ History] 0.7691766619682312\n",
            "loss 0.143 = 0.116 + 0.024 + 0.003 avg prob of [ History] 0.8915206789970398\n",
            "loss 0.094 = 0.068 + 0.023 + 0.003 avg prob of [ History] 0.9345325231552124\n",
            "loss 0.067 = 0.042 + 0.022 + 0.003 avg prob of [ History] 0.9586817622184753\n",
            "loss 0.051 = 0.028 + 0.021 + 0.003 avg prob of [ History] 0.972565770149231\n",
            "loss 0.042 = 0.019 + 0.02 + 0.003 avg prob of [ History] 0.9808381795883179\n",
            "Init norm 145.02098083496094 | Delta norm 108.76573181152344 | Target norm 172.4778594970703\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Satoru Iwata works for | Token: ata\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.393 = 12.393 + 0.0 + 0.0 avg prob of [ BBC] 5.281364337861305e-06\n",
            "loss 9.008 = 8.997 + 0.01 + 0.001 avg prob of [ BBC] 0.00018345643184147775\n",
            "loss 6.264 = 6.248 + 0.014 + 0.001 avg prob of [ BBC] 0.004081283695995808\n",
            "loss 3.544 = 3.526 + 0.016 + 0.002 avg prob of [ BBC] 0.04017714783549309\n",
            "loss 1.768 = 1.743 + 0.023 + 0.002 avg prob of [ BBC] 0.18121302127838135\n",
            "loss 0.812 = 0.768 + 0.041 + 0.003 avg prob of [ BBC] 0.4784500300884247\n",
            "loss 0.338 = 0.262 + 0.073 + 0.003 avg prob of [ BBC] 0.7894037961959839\n",
            "loss 0.199 = 0.11 + 0.085 + 0.003 avg prob of [ BBC] 0.9027004241943359\n",
            "loss 0.138 = 0.059 + 0.076 + 0.003 avg prob of [ BBC] 0.9449496269226074\n",
            "loss 0.099 = 0.033 + 0.063 + 0.003 avg prob of [ BBC] 0.9681565165519714\n",
            "loss 0.076 = 0.019 + 0.054 + 0.003 avg prob of [ BBC] 0.9813069105148315\n",
            "loss 0.063 = 0.011 + 0.048 + 0.003 avg prob of [ BBC] 0.9888312220573425\n",
            "loss 0.054 = 0.007 + 0.044 + 0.003 avg prob of [ BBC] 0.9931559562683105\n",
            "loss 0.049 = 0.004 + 0.041 + 0.003 avg prob of [ BBC] 0.9956194758415222\n",
            "Init norm 116.61181640625 | Delta norm 87.4588623046875 | Target norm 142.2517547607422\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Chromecast is produced by | Token: ecast\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.148 = 10.148 + 0.0 + 0.0 avg prob of [ Honda] 5.195616540731862e-05\n",
            "loss 7.083 = 7.08 + 0.003 + 0.0 avg prob of [ Honda] 0.001020647119730711\n",
            "loss 6.166 = 6.156 + 0.009 + 0.001 avg prob of [ Honda] 0.002707197330892086\n",
            "loss 5.557 = 5.542 + 0.014 + 0.001 avg prob of [ Honda] 0.005522625055164099\n",
            "loss 4.92 = 4.902 + 0.017 + 0.001 avg prob of [ Honda] 0.011995242908596992\n",
            "loss 4.136 = 4.117 + 0.018 + 0.001 avg prob of [ Honda] 0.03025459311902523\n",
            "loss 3.155 = 3.134 + 0.019 + 0.002 avg prob of [ Honda] 0.08589323610067368\n",
            "loss 2.09 = 2.062 + 0.026 + 0.002 avg prob of [ Honda] 0.2056894600391388\n",
            "loss 1.251 = 1.213 + 0.036 + 0.002 avg prob of [ Honda] 0.3566986918449402\n",
            "loss 0.804 = 0.758 + 0.044 + 0.002 avg prob of [ Honda] 0.49738961458206177\n",
            "loss 0.577 = 0.523 + 0.051 + 0.002 avg prob of [ Honda] 0.6072505712509155\n",
            "loss 0.416 = 0.36 + 0.053 + 0.002 avg prob of [ Honda] 0.7056776881217957\n",
            "loss 0.287 = 0.231 + 0.054 + 0.002 avg prob of [ Honda] 0.7977651953697205\n",
            "loss 0.197 = 0.14 + 0.054 + 0.002 avg prob of [ Honda] 0.871167778968811\n",
            "loss 0.14 = 0.083 + 0.054 + 0.002 avg prob of [ Honda] 0.9211635589599609\n",
            "loss 0.106 = 0.05 + 0.054 + 0.002 avg prob of [ Honda] 0.951744794845581\n",
            "loss 0.087 = 0.031 + 0.053 + 0.002 avg prob of [ Honda] 0.9695383310317993\n",
            "loss 0.075 = 0.02 + 0.052 + 0.002 avg prob of [ Honda] 0.9798316955566406\n",
            "loss 0.067 = 0.014 + 0.051 + 0.002 avg prob of [ Honda] 0.9859115481376648\n",
            "loss 0.062 = 0.01 + 0.049 + 0.002 avg prob of [ Honda] 0.9896253347396851\n",
            "Init norm 150.76344299316406 | Delta norm 113.07258605957031 | Target norm 183.02725219726562\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Yoruba religion is a part of the continent of | Token:  religion\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.528 = 11.528 + 0.0 + 0.0 avg prob of [ Antarctica] 1.205193893838441e-05\n",
            "loss 10.245 = 10.239 + 0.005 + 0.001 avg prob of [ Antarctica] 4.129451554035768e-05\n",
            "loss 8.145 = 8.13 + 0.014 + 0.001 avg prob of [ Antarctica] 0.00037133152363821864\n",
            "loss 5.065 = 5.04 + 0.023 + 0.001 avg prob of [ Antarctica] 0.006998092867434025\n",
            "loss 3.581 = 3.548 + 0.032 + 0.002 avg prob of [ Antarctica] 0.030266117304563522\n",
            "loss 2.075 = 2.034 + 0.039 + 0.002 avg prob of [ Antarctica] 0.13790276646614075\n",
            "loss 0.583 = 0.529 + 0.052 + 0.002 avg prob of [ Antarctica] 0.6046105623245239\n",
            "loss 0.168 = 0.087 + 0.079 + 0.002 avg prob of [ Antarctica] 0.9172993898391724\n",
            "loss 0.099 = 0.024 + 0.073 + 0.003 avg prob of [ Antarctica] 0.9767955541610718\n",
            "loss 0.065 = 0.009 + 0.054 + 0.003 avg prob of [ Antarctica] 0.99104905128479\n",
            "loss 0.05 = 0.005 + 0.042 + 0.003 avg prob of [ Antarctica] 0.995090126991272\n",
            "Init norm 138.7223358154297 | Delta norm 104.04175567626953 | Target norm 167.76609802246094\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The native language of Adriaan Roland Holst is | Token: st\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.984 = 5.984 + 0.0 + 0.0 avg prob of [ French] 0.003019345924258232\n",
            "loss 3.637 = 3.618 + 0.019 + 0.001 avg prob of [ French] 0.0306922048330307\n",
            "loss 1.454 = 1.434 + 0.019 + 0.001 avg prob of [ French] 0.24917136132717133\n",
            "loss 0.891 = 0.863 + 0.027 + 0.001 avg prob of [ French] 0.43271708488464355\n",
            "loss 0.685 = 0.648 + 0.035 + 0.002 avg prob of [ French] 0.5318295955657959\n",
            "loss 0.463 = 0.423 + 0.038 + 0.002 avg prob of [ French] 0.6589450836181641\n",
            "loss 0.307 = 0.269 + 0.036 + 0.002 avg prob of [ French] 0.7655380964279175\n",
            "loss 0.218 = 0.181 + 0.034 + 0.003 avg prob of [ French] 0.8347002863883972\n",
            "loss 0.166 = 0.131 + 0.032 + 0.003 avg prob of [ French] 0.8775792121887207\n",
            "loss 0.135 = 0.101 + 0.031 + 0.003 avg prob of [ French] 0.904599666595459\n",
            "loss 0.115 = 0.081 + 0.03 + 0.003 avg prob of [ French] 0.9219986200332642\n",
            "loss 0.1 = 0.068 + 0.029 + 0.003 avg prob of [ French] 0.9345318675041199\n",
            "loss 0.088 = 0.057 + 0.028 + 0.003 avg prob of [ French] 0.944494903087616\n",
            "loss 0.079 = 0.049 + 0.027 + 0.003 avg prob of [ French] 0.9524914622306824\n",
            "loss 0.071 = 0.042 + 0.026 + 0.003 avg prob of [ French] 0.9589645862579346\n",
            "loss 0.065 = 0.036 + 0.025 + 0.003 avg prob of [ French] 0.964248776435852\n",
            "loss 0.059 = 0.032 + 0.024 + 0.003 avg prob of [ French] 0.9685983657836914\n",
            "loss 0.055 = 0.028 + 0.024 + 0.003 avg prob of [ French] 0.9722084999084473\n",
            "loss 0.051 = 0.025 + 0.023 + 0.003 avg prob of [ French] 0.9752295017242432\n",
            "loss 0.048 = 0.023 + 0.023 + 0.003 avg prob of [ French] 0.9777774214744568\n",
            "Init norm 121.89071655273438 | Delta norm 91.41803741455078 | Target norm 153.1302032470703\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Pontifical Catholic University of Chile's headquarters are in | Token:  Chile\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.907 = 9.907 + 0.0 + 0.0 avg prob of [ Toronto] 5.481901462189853e-05\n",
            "loss 7.018 = 7.017 + 0.0 + 0.0 avg prob of [ Toronto] 0.0013062743237242103\n",
            "loss 5.562 = 5.561 + 0.001 + 0.001 avg prob of [ Toronto] 0.006079702638089657\n",
            "loss 5.04 = 5.037 + 0.002 + 0.001 avg prob of [ Toronto] 0.00978097040206194\n",
            "loss 4.552 = 4.548 + 0.002 + 0.002 avg prob of [ Toronto] 0.01506683137267828\n",
            "loss 3.649 = 3.644 + 0.003 + 0.002 avg prob of [ Toronto] 0.0357365719974041\n",
            "loss 2.643 = 2.637 + 0.004 + 0.002 avg prob of [ Toronto] 0.09598177671432495\n",
            "loss 1.97 = 1.962 + 0.006 + 0.002 avg prob of [ Toronto] 0.18806812167167664\n",
            "loss 1.626 = 1.617 + 0.007 + 0.002 avg prob of [ Toronto] 0.2530314028263092\n",
            "loss 1.349 = 1.339 + 0.008 + 0.003 avg prob of [ Toronto] 0.3144603967666626\n",
            "loss 1.119 = 1.109 + 0.008 + 0.003 avg prob of [ Toronto] 0.3809056282043457\n",
            "loss 0.906 = 0.896 + 0.007 + 0.003 avg prob of [ Toronto] 0.45311039686203003\n",
            "loss 0.72 = 0.71 + 0.007 + 0.003 avg prob of [ Toronto] 0.5288251638412476\n",
            "loss 0.561 = 0.551 + 0.007 + 0.003 avg prob of [ Toronto] 0.605374813079834\n",
            "loss 0.43 = 0.42 + 0.007 + 0.003 avg prob of [ Toronto] 0.6793085932731628\n",
            "loss 0.324 = 0.314 + 0.007 + 0.003 avg prob of [ Toronto] 0.7471078634262085\n",
            "loss 0.241 = 0.23 + 0.008 + 0.003 avg prob of [ Toronto] 0.8061246871948242\n",
            "loss 0.177 = 0.166 + 0.008 + 0.003 avg prob of [ Toronto] 0.85509192943573\n",
            "loss 0.129 = 0.117 + 0.009 + 0.003 avg prob of [ Toronto] 0.8939945101737976\n",
            "loss 0.094 = 0.082 + 0.01 + 0.003 avg prob of [ Toronto] 0.9236509203910828\n",
            "Init norm 141.71400451660156 | Delta norm 106.28550720214844 | Target norm 169.45928955078125\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Morocco belongs to the continent of | Token: co\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.867 = 8.867 + 0.0 + 0.0 avg prob of [ Antarctica] 0.00015084641927387565\n",
            "loss 6.43 = 6.426 + 0.004 + 0.001 avg prob of [ Antarctica] 0.002143179066479206\n",
            "loss 4.896 = 4.887 + 0.007 + 0.001 avg prob of [ Antarctica] 0.01345043908804655\n",
            "loss 3.834 = 3.82 + 0.012 + 0.002 avg prob of [ Antarctica] 0.03681737184524536\n",
            "loss 2.835 = 2.817 + 0.016 + 0.002 avg prob of [ Antarctica] 0.08471798151731491\n",
            "loss 1.806 = 1.784 + 0.02 + 0.003 avg prob of [ Antarctica] 0.20764301717281342\n",
            "loss 0.895 = 0.866 + 0.026 + 0.003 avg prob of [ Antarctica] 0.4613841772079468\n",
            "loss 0.441 = 0.403 + 0.035 + 0.003 avg prob of [ Antarctica] 0.6900314092636108\n",
            "loss 0.282 = 0.237 + 0.041 + 0.003 avg prob of [ Antarctica] 0.7991132140159607\n",
            "loss 0.2 = 0.151 + 0.045 + 0.003 avg prob of [ Antarctica] 0.8643051981925964\n",
            "loss 0.137 = 0.088 + 0.045 + 0.003 avg prob of [ Antarctica] 0.9172329306602478\n",
            "loss 0.095 = 0.049 + 0.043 + 0.003 avg prob of [ Antarctica] 0.9531108736991882\n",
            "loss 0.07 = 0.027 + 0.039 + 0.003 avg prob of [ Antarctica] 0.9731205701828003\n",
            "loss 0.056 = 0.017 + 0.036 + 0.003 avg prob of [ Antarctica] 0.9834628105163574\n",
            "loss 0.048 = 0.011 + 0.034 + 0.003 avg prob of [ Antarctica] 0.9888860583305359\n",
            "Init norm 118.632080078125 | Delta norm 88.97406005859375 | Target norm 145.63491821289062\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Alain Marleix is | Token: ix\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.635 = 6.635 + 0.0 + 0.0 avg prob of [ Russian] 0.0013784023467451334\n",
            "loss 3.708 = 3.706 + 0.001 + 0.001 avg prob of [ Russian] 0.026475980877876282\n",
            "loss 0.767 = 0.762 + 0.003 + 0.002 avg prob of [ Russian] 0.47068068385124207\n",
            "loss 0.661 = 0.654 + 0.005 + 0.002 avg prob of [ Russian] 0.5220130681991577\n",
            "loss 0.567 = 0.558 + 0.007 + 0.002 avg prob of [ Russian] 0.5741119384765625\n",
            "loss 0.468 = 0.454 + 0.012 + 0.003 avg prob of [ Russian] 0.6367039084434509\n",
            "loss 0.374 = 0.354 + 0.017 + 0.003 avg prob of [ Russian] 0.7031151652336121\n",
            "loss 0.295 = 0.271 + 0.02 + 0.004 avg prob of [ Russian] 0.7636162638664246\n",
            "loss 0.234 = 0.209 + 0.022 + 0.004 avg prob of [ Russian] 0.8123385310173035\n",
            "loss 0.19 = 0.165 + 0.022 + 0.004 avg prob of [ Russian] 0.848554790019989\n",
            "loss 0.158 = 0.133 + 0.021 + 0.004 avg prob of [ Russian] 0.8754010200500488\n",
            "loss 0.135 = 0.111 + 0.02 + 0.004 avg prob of [ Russian] 0.8953906893730164\n",
            "loss 0.117 = 0.094 + 0.02 + 0.004 avg prob of [ Russian] 0.9105715751647949\n",
            "loss 0.103 = 0.081 + 0.018 + 0.004 avg prob of [ Russian] 0.9224910140037537\n",
            "loss 0.091 = 0.07 + 0.017 + 0.004 avg prob of [ Russian] 0.9322319030761719\n",
            "loss 0.081 = 0.062 + 0.016 + 0.004 avg prob of [ Russian] 0.9404763579368591\n",
            "loss 0.072 = 0.054 + 0.014 + 0.004 avg prob of [ Russian] 0.9476200938224792\n",
            "loss 0.064 = 0.047 + 0.013 + 0.004 avg prob of [ Russian] 0.953885555267334\n",
            "loss 0.057 = 0.042 + 0.012 + 0.004 avg prob of [ Russian] 0.9594041705131531\n",
            "loss 0.052 = 0.036 + 0.012 + 0.004 avg prob of [ Russian] 0.9642627239227295\n",
            "Init norm 103.73906707763672 | Delta norm 77.80430603027344 | Target norm 127.97216033935547\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The mother tongue of Pietro Mennea is | Token: nea\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.294 = 4.294 + 0.0 + 0.0 avg prob of [ French] 0.014226335100829601\n",
            "loss 1.427 = 1.423 + 0.003 + 0.001 avg prob of [ French] 0.25227078795433044\n",
            "loss 0.803 = 0.795 + 0.007 + 0.001 avg prob of [ French] 0.45777592062950134\n",
            "loss 0.582 = 0.569 + 0.011 + 0.002 avg prob of [ French] 0.570520281791687\n",
            "loss 0.399 = 0.381 + 0.016 + 0.002 avg prob of [ French] 0.6867231726646423\n",
            "loss 0.261 = 0.24 + 0.019 + 0.003 avg prob of [ French] 0.7897599935531616\n",
            "loss 0.175 = 0.149 + 0.022 + 0.003 avg prob of [ French] 0.8627407550811768\n",
            "loss 0.124 = 0.097 + 0.024 + 0.003 avg prob of [ French] 0.9082950353622437\n",
            "loss 0.098 = 0.071 + 0.024 + 0.003 avg prob of [ French] 0.9321843981742859\n",
            "loss 0.08 = 0.054 + 0.023 + 0.003 avg prob of [ French] 0.9480695724487305\n",
            "loss 0.067 = 0.042 + 0.022 + 0.003 avg prob of [ French] 0.9593602418899536\n",
            "loss 0.057 = 0.033 + 0.021 + 0.003 avg prob of [ French] 0.9675542116165161\n",
            "loss 0.05 = 0.027 + 0.02 + 0.003 avg prob of [ French] 0.9736483097076416\n",
            "loss 0.045 = 0.022 + 0.019 + 0.003 avg prob of [ French] 0.9782885313034058\n",
            "Init norm 109.26667785644531 | Delta norm 81.95001220703125 | Target norm 134.4869384765625\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The official language of Netherlands is | Token:  Netherlands\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.65 = 9.65 + 0.0 + 0.0 avg prob of [ Russian] 9.347870945930481e-05\n",
            "loss 6.951 = 6.949 + 0.001 + 0.0 avg prob of [ Russian] 0.0011806179536506534\n",
            "loss 4.226 = 4.222 + 0.004 + 0.001 avg prob of [ Russian] 0.016510475426912308\n",
            "loss 1.886 = 1.876 + 0.009 + 0.001 avg prob of [ Russian] 0.15823711454868317\n",
            "loss 0.971 = 0.956 + 0.014 + 0.001 avg prob of [ Russian] 0.39720630645751953\n",
            "loss 0.734 = 0.714 + 0.019 + 0.002 avg prob of [ Russian] 0.5022701621055603\n",
            "loss 0.638 = 0.611 + 0.024 + 0.002 avg prob of [ Russian] 0.5540667772293091\n",
            "loss 0.571 = 0.539 + 0.03 + 0.002 avg prob of [ Russian] 0.5938907861709595\n",
            "loss 0.507 = 0.472 + 0.033 + 0.002 avg prob of [ Russian] 0.6334239840507507\n",
            "loss 0.435 = 0.4 + 0.032 + 0.003 avg prob of [ Russian] 0.678191065788269\n",
            "loss 0.366 = 0.335 + 0.029 + 0.003 avg prob of [ Russian] 0.7218931913375854\n",
            "loss 0.308 = 0.279 + 0.026 + 0.003 avg prob of [ Russian] 0.7614954710006714\n",
            "loss 0.258 = 0.232 + 0.024 + 0.003 avg prob of [ Russian] 0.7965967059135437\n",
            "loss 0.218 = 0.193 + 0.023 + 0.003 avg prob of [ Russian] 0.8273388147354126\n",
            "loss 0.184 = 0.16 + 0.022 + 0.003 avg prob of [ Russian] 0.8541154861450195\n",
            "loss 0.157 = 0.132 + 0.022 + 0.003 avg prob of [ Russian] 0.8773800134658813\n",
            "loss 0.134 = 0.109 + 0.022 + 0.003 avg prob of [ Russian] 0.8975601196289062\n",
            "loss 0.114 = 0.089 + 0.022 + 0.003 avg prob of [ Russian] 0.9150130152702332\n",
            "loss 0.097 = 0.073 + 0.022 + 0.003 avg prob of [ Russian] 0.9300267100334167\n",
            "loss 0.083 = 0.059 + 0.022 + 0.003 avg prob of [ Russian] 0.9428223371505737\n",
            "Init norm 148.969482421875 | Delta norm 111.72711181640625 | Target norm 182.9053192138672\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Jean Dujardin is | Token: in\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.984 = 4.984 + 0.0 + 0.0 avg prob of [ Dutch] 0.007430225610733032\n",
            "loss 2.02 = 2.011 + 0.008 + 0.001 avg prob of [ Dutch] 0.1533437967300415\n",
            "loss 0.901 = 0.89 + 0.009 + 0.002 avg prob of [ Dutch] 0.4416341483592987\n",
            "loss 0.257 = 0.244 + 0.011 + 0.002 avg prob of [ Dutch] 0.7855037450790405\n",
            "loss 0.184 = 0.168 + 0.013 + 0.003 avg prob of [ Dutch] 0.8456327319145203\n",
            "loss 0.153 = 0.136 + 0.013 + 0.003 avg prob of [ Dutch] 0.8728487491607666\n",
            "loss 0.126 = 0.11 + 0.013 + 0.004 avg prob of [ Dutch] 0.8964128494262695\n",
            "loss 0.104 = 0.087 + 0.013 + 0.004 avg prob of [ Dutch] 0.9167636632919312\n",
            "loss 0.083 = 0.066 + 0.013 + 0.004 avg prob of [ Dutch] 0.9360523223876953\n",
            "loss 0.067 = 0.051 + 0.012 + 0.004 avg prob of [ Dutch] 0.9505847692489624\n",
            "loss 0.056 = 0.04 + 0.012 + 0.004 avg prob of [ Dutch] 0.9608869552612305\n",
            "loss 0.048 = 0.032 + 0.011 + 0.004 avg prob of [ Dutch] 0.9682366251945496\n",
            "Init norm 95.55245208740234 | Delta norm 71.66433715820312 | Target norm 119.52066802978516\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The headquarter of Nippon Cultural Broadcasting is in | Token:  Broadcasting\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.041 = 6.041 + 0.0 + 0.0 avg prob of [ London] 0.002775681670755148\n",
            "loss 4.654 = 4.65 + 0.003 + 0.001 avg prob of [ London] 0.010717276483774185\n",
            "loss 2.331 = 2.322 + 0.008 + 0.001 avg prob of [ London] 0.10098803043365479\n",
            "loss 0.805 = 0.787 + 0.017 + 0.001 avg prob of [ London] 0.4745561480522156\n",
            "loss 0.366 = 0.336 + 0.028 + 0.002 avg prob of [ London] 0.7224386930465698\n",
            "loss 0.238 = 0.198 + 0.037 + 0.002 avg prob of [ London] 0.8225753307342529\n",
            "loss 0.185 = 0.144 + 0.038 + 0.002 avg prob of [ London] 0.8671695590019226\n",
            "loss 0.142 = 0.105 + 0.034 + 0.003 avg prob of [ London] 0.9005589485168457\n",
            "loss 0.108 = 0.075 + 0.03 + 0.003 avg prob of [ London] 0.9280956983566284\n",
            "loss 0.084 = 0.053 + 0.028 + 0.003 avg prob of [ London] 0.9483978152275085\n",
            "loss 0.068 = 0.039 + 0.027 + 0.003 avg prob of [ London] 0.9622480273246765\n",
            "loss 0.058 = 0.029 + 0.026 + 0.003 avg prob of [ London] 0.9716100692749023\n",
            "loss 0.051 = 0.022 + 0.026 + 0.003 avg prob of [ London] 0.9779216647148132\n",
            "loss 0.047 = 0.018 + 0.026 + 0.003 avg prob of [ London] 0.9822549819946289\n",
            "Init norm 128.65846252441406 | Delta norm 96.49385070800781 | Target norm 153.42906188964844\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: .NET Framework is created by | Token:  Framework\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.213 = 7.213 + 0.0 + 0.0 avg prob of [ Google] 0.0014158188132569194\n",
            "loss 5.422 = 5.418 + 0.004 + 0.0 avg prob of [ Google] 0.009165316820144653\n",
            "loss 2.503 = 2.487 + 0.015 + 0.001 avg prob of [ Google] 0.1774727702140808\n",
            "loss 0.711 = 0.674 + 0.035 + 0.001 avg prob of [ Google] 0.7444089651107788\n",
            "loss 0.25 = 0.192 + 0.057 + 0.001 avg prob of [ Google] 0.860255241394043\n",
            "loss 0.133 = 0.055 + 0.076 + 0.002 avg prob of [ Google] 0.946967363357544\n",
            "loss 0.124 = 0.034 + 0.088 + 0.002 avg prob of [ Google] 0.9664998054504395\n",
            "loss 0.121 = 0.025 + 0.094 + 0.002 avg prob of [ Google] 0.9749290347099304\n",
            "loss 0.117 = 0.02 + 0.095 + 0.002 avg prob of [ Google] 0.9806302785873413\n",
            "loss 0.11 = 0.015 + 0.092 + 0.003 avg prob of [ Google] 0.9846569895744324\n",
            "loss 0.1 = 0.013 + 0.084 + 0.003 avg prob of [ Google] 0.9873772859573364\n",
            "loss 0.089 = 0.011 + 0.076 + 0.003 avg prob of [ Google] 0.9895144701004028\n",
            "loss 0.079 = 0.009 + 0.067 + 0.003 avg prob of [ Google] 0.9912389516830444\n",
            "loss 0.07 = 0.007 + 0.06 + 0.003 avg prob of [ Google] 0.9926287531852722\n",
            "loss 0.061 = 0.006 + 0.052 + 0.003 avg prob of [ Google] 0.9937481880187988\n",
            "loss 0.053 = 0.005 + 0.045 + 0.003 avg prob of [ Google] 0.994649350643158\n",
            "loss 0.046 = 0.005 + 0.039 + 0.003 avg prob of [ Google] 0.9953742027282715\n",
            "Init norm 144.85104370117188 | Delta norm 108.6382827758789 | Target norm 175.9524383544922\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: OneDrive, a product manufactured by | Token: Drive\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.933 = 14.933 + 0.0 + 0.0 avg prob of [ Sega] 5.668216545018367e-07\n",
            "loss 9.61 = 9.607 + 0.003 + 0.001 avg prob of [ Sega] 8.301066554849967e-05\n",
            "loss 6.67 = 6.659 + 0.01 + 0.001 avg prob of [ Sega] 0.001367142773233354\n",
            "loss 4.668 = 4.644 + 0.023 + 0.001 avg prob of [ Sega] 0.0102215725928545\n",
            "loss 3.317 = 3.28 + 0.036 + 0.002 avg prob of [ Sega] 0.040472231805324554\n",
            "loss 2.413 = 2.363 + 0.047 + 0.002 avg prob of [ Sega] 0.10136713087558746\n",
            "loss 1.795 = 1.736 + 0.057 + 0.002 avg prob of [ Sega] 0.18868204951286316\n",
            "loss 1.364 = 1.297 + 0.064 + 0.002 avg prob of [ Sega] 0.2889932692050934\n",
            "loss 1.055 = 0.983 + 0.07 + 0.003 avg prob of [ Sega] 0.39011114835739136\n",
            "loss 0.823 = 0.749 + 0.072 + 0.003 avg prob of [ Sega] 0.48697131872177124\n",
            "loss 0.638 = 0.563 + 0.072 + 0.003 avg prob of [ Sega] 0.5803537368774414\n",
            "loss 0.481 = 0.408 + 0.071 + 0.003 avg prob of [ Sega] 0.6732086539268494\n",
            "loss 0.356 = 0.283 + 0.07 + 0.003 avg prob of [ Sega] 0.7586652040481567\n",
            "loss 0.261 = 0.19 + 0.068 + 0.003 avg prob of [ Sega] 0.8302402496337891\n",
            "loss 0.194 = 0.124 + 0.067 + 0.003 avg prob of [ Sega] 0.8848304748535156\n",
            "loss 0.149 = 0.081 + 0.065 + 0.003 avg prob of [ Sega] 0.9232968091964722\n",
            "loss 0.12 = 0.053 + 0.064 + 0.003 avg prob of [ Sega] 0.9489049911499023\n",
            "loss 0.101 = 0.035 + 0.063 + 0.003 avg prob of [ Sega] 0.9654111862182617\n",
            "loss 0.089 = 0.024 + 0.061 + 0.003 avg prob of [ Sega] 0.9759410619735718\n",
            "loss 0.081 = 0.017 + 0.06 + 0.003 avg prob of [ Sega] 0.982705295085907\n",
            "Init norm 138.98712158203125 | Delta norm 104.24034118652344 | Target norm 163.5565185546875\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The native language of Willem Johan Kolff is | Token: ff\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.702 = 5.702 + 0.0 + 0.0 avg prob of [ French] 0.003699843306094408\n",
            "loss 3.885 = 3.882 + 0.002 + 0.001 avg prob of [ French] 0.022319313138723373\n",
            "loss 1.31 = 1.306 + 0.003 + 0.001 avg prob of [ French] 0.27913662791252136\n",
            "loss 0.845 = 0.838 + 0.005 + 0.002 avg prob of [ French] 0.4413701891899109\n",
            "loss 0.641 = 0.625 + 0.014 + 0.002 avg prob of [ French] 0.5435758829116821\n",
            "loss 0.424 = 0.394 + 0.027 + 0.003 avg prob of [ French] 0.679111123085022\n",
            "loss 0.279 = 0.253 + 0.024 + 0.003 avg prob of [ French] 0.7785167694091797\n",
            "loss 0.196 = 0.175 + 0.017 + 0.003 avg prob of [ French] 0.8401033282279968\n",
            "loss 0.149 = 0.132 + 0.014 + 0.003 avg prob of [ French] 0.8769445419311523\n",
            "loss 0.118 = 0.103 + 0.012 + 0.003 avg prob of [ French] 0.901948094367981\n",
            "loss 0.096 = 0.083 + 0.01 + 0.003 avg prob of [ French] 0.9206241965293884\n",
            "loss 0.08 = 0.067 + 0.009 + 0.003 avg prob of [ French] 0.9350454211235046\n",
            "loss 0.067 = 0.055 + 0.009 + 0.003 avg prob of [ French] 0.946479082107544\n",
            "loss 0.057 = 0.045 + 0.008 + 0.003 avg prob of [ French] 0.9557015299797058\n",
            "loss 0.049 = 0.038 + 0.008 + 0.003 avg prob of [ French] 0.9632047414779663\n",
            "Init norm 111.03750610351562 | Delta norm 83.27812957763672 | Target norm 136.52537536621094\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Mali belongs to the continent of | Token: ali\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.247 = 10.247 + 0.0 + 0.0 avg prob of [ Antarctica] 5.4152329539647326e-05\n",
            "loss 7.045 = 6.992 + 0.052 + 0.001 avg prob of [ Antarctica] 0.0011128670303151011\n",
            "loss 6.268 = 6.132 + 0.135 + 0.001 avg prob of [ Antarctica] 0.0033239549957215786\n",
            "loss 5.922 = 5.824 + 0.097 + 0.001 avg prob of [ Antarctica] 0.004781413823366165\n",
            "loss 5.603 = 5.517 + 0.084 + 0.002 avg prob of [ Antarctica] 0.006956073921173811\n",
            "loss 5.18 = 5.102 + 0.076 + 0.002 avg prob of [ Antarctica] 0.011550008319318295\n",
            "loss 4.615 = 4.543 + 0.07 + 0.002 avg prob of [ Antarctica] 0.021421192213892937\n",
            "loss 3.903 = 3.837 + 0.064 + 0.002 avg prob of [ Antarctica] 0.040688201785087585\n",
            "loss 3.067 = 3.005 + 0.059 + 0.003 avg prob of [ Antarctica] 0.07612939178943634\n",
            "loss 2.219 = 2.16 + 0.056 + 0.003 avg prob of [ Antarctica] 0.14113162457942963\n",
            "loss 1.555 = 1.498 + 0.054 + 0.003 avg prob of [ Antarctica] 0.24467264115810394\n",
            "loss 1.042 = 0.986 + 0.052 + 0.003 avg prob of [ Antarctica] 0.39555031061172485\n",
            "loss 0.724 = 0.67 + 0.051 + 0.003 avg prob of [ Antarctica] 0.5322617292404175\n",
            "loss 0.515 = 0.464 + 0.048 + 0.003 avg prob of [ Antarctica] 0.6427762508392334\n",
            "loss 0.365 = 0.316 + 0.046 + 0.003 avg prob of [ Antarctica] 0.7368412017822266\n",
            "loss 0.259 = 0.212 + 0.044 + 0.003 avg prob of [ Antarctica] 0.8133088946342468\n",
            "loss 0.185 = 0.14 + 0.042 + 0.003 avg prob of [ Antarctica] 0.8713233470916748\n",
            "loss 0.136 = 0.093 + 0.04 + 0.003 avg prob of [ Antarctica] 0.9123845100402832\n",
            "loss 0.103 = 0.062 + 0.038 + 0.003 avg prob of [ Antarctica] 0.9399067759513855\n",
            "loss 0.082 = 0.043 + 0.036 + 0.003 avg prob of [ Antarctica] 0.9578421115875244\n",
            "Init norm 133.40008544921875 | Delta norm 100.05006408691406 | Target norm 163.81314086914062\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The mother tongue of Jean-Pierre Thiollet is | Token: let\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.773 = 5.773 + 0.0 + 0.0 avg prob of [ Dutch] 0.0033275007735937834\n",
            "loss 2.573 = 2.571 + 0.001 + 0.001 avg prob of [ Dutch] 0.08735072612762451\n",
            "loss 1.323 = 1.318 + 0.004 + 0.001 avg prob of [ Dutch] 0.29288482666015625\n",
            "loss 0.546 = 0.539 + 0.005 + 0.002 avg prob of [ Dutch] 0.5928788185119629\n",
            "loss 0.382 = 0.372 + 0.008 + 0.002 avg prob of [ Dutch] 0.6913416385650635\n",
            "loss 0.33 = 0.315 + 0.012 + 0.003 avg prob of [ Dutch] 0.7308543920516968\n",
            "loss 0.285 = 0.266 + 0.016 + 0.003 avg prob of [ Dutch] 0.7674276232719421\n",
            "loss 0.237 = 0.214 + 0.02 + 0.003 avg prob of [ Dutch] 0.8079807758331299\n",
            "loss 0.191 = 0.165 + 0.023 + 0.004 avg prob of [ Dutch] 0.8486082553863525\n",
            "loss 0.155 = 0.129 + 0.023 + 0.004 avg prob of [ Dutch] 0.8793951869010925\n",
            "loss 0.128 = 0.102 + 0.023 + 0.004 avg prob of [ Dutch] 0.9031311869621277\n",
            "loss 0.108 = 0.082 + 0.022 + 0.004 avg prob of [ Dutch] 0.9213542342185974\n",
            "loss 0.092 = 0.067 + 0.021 + 0.004 avg prob of [ Dutch] 0.9355832934379578\n",
            "loss 0.078 = 0.055 + 0.02 + 0.004 avg prob of [ Dutch] 0.9468605518341064\n",
            "loss 0.067 = 0.045 + 0.019 + 0.004 avg prob of [ Dutch] 0.9558648467063904\n",
            "loss 0.058 = 0.038 + 0.017 + 0.004 avg prob of [ Dutch] 0.963089644908905\n",
            "loss 0.049 = 0.032 + 0.014 + 0.004 avg prob of [ Dutch] 0.9689251184463501\n",
            "Init norm 105.17405700683594 | Delta norm 78.88053894042969 | Target norm 132.32028198242188\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: The mother tongue of Erick van Egeraat is | Token: at\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 3.625 = 3.625 + 0.0 + 0.0 avg prob of [ English] 0.028467057272791862\n",
            "loss 2.766 = 2.761 + 0.004 + 0.001 avg prob of [ English] 0.068307064473629\n",
            "loss 1.307 = 1.293 + 0.013 + 0.002 avg prob of [ English] 0.2993555963039398\n",
            "loss 0.594 = 0.573 + 0.018 + 0.002 avg prob of [ English] 0.5930175185203552\n",
            "loss 0.104 = 0.078 + 0.023 + 0.003 avg prob of [ English] 0.9281251430511475\n",
            "loss 0.061 = 0.031 + 0.028 + 0.003 avg prob of [ English] 0.970545768737793\n",
            "loss 0.048 = 0.017 + 0.027 + 0.003 avg prob of [ English] 0.9831552505493164\n",
            "Init norm 100.05445098876953 | Delta norm 69.2737808227539 | Target norm 120.76825714111328\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Amiibo, developed by | Token: ibo\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.975 = 8.975 + 0.0 + 0.0 avg prob of [ Apple] 0.0001515610929345712\n",
            "loss 4.456 = 4.447 + 0.009 + 0.0 avg prob of [ Apple] 0.01353149302303791\n",
            "loss 2.091 = 2.054 + 0.036 + 0.001 avg prob of [ Apple] 0.14170344173908234\n",
            "loss 0.921 = 0.861 + 0.059 + 0.001 avg prob of [ Apple] 0.43508362770080566\n",
            "loss 0.351 = 0.279 + 0.071 + 0.001 avg prob of [ Apple] 0.7586154937744141\n",
            "loss 0.172 = 0.095 + 0.075 + 0.002 avg prob of [ Apple] 0.9091994166374207\n",
            "loss 0.12 = 0.044 + 0.074 + 0.002 avg prob of [ Apple] 0.9571939706802368\n",
            "loss 0.101 = 0.026 + 0.073 + 0.002 avg prob of [ Apple] 0.9745595455169678\n",
            "loss 0.093 = 0.018 + 0.073 + 0.002 avg prob of [ Apple] 0.9822644591331482\n",
            "loss 0.09 = 0.014 + 0.074 + 0.002 avg prob of [ Apple] 0.9862460494041443\n",
            "loss 0.089 = 0.012 + 0.075 + 0.003 avg prob of [ Apple] 0.9885051250457764\n",
            "loss 0.087 = 0.01 + 0.074 + 0.003 avg prob of [ Apple] 0.9896038770675659\n",
            "loss 0.085 = 0.01 + 0.073 + 0.003 avg prob of [ Apple] 0.9904279708862305\n",
            "loss 0.083 = 0.009 + 0.071 + 0.003 avg prob of [ Apple] 0.9910702705383301\n",
            "loss 0.081 = 0.008 + 0.07 + 0.003 avg prob of [ Apple] 0.9915868639945984\n",
            "loss 0.078 = 0.008 + 0.068 + 0.003 avg prob of [ Apple] 0.9920133352279663\n",
            "loss 0.076 = 0.008 + 0.066 + 0.003 avg prob of [ Apple] 0.9923729300498962\n",
            "loss 0.073 = 0.007 + 0.063 + 0.003 avg prob of [ Apple] 0.9926813840866089\n",
            "loss 0.071 = 0.007 + 0.061 + 0.003 avg prob of [ Apple] 0.9929496645927429\n",
            "loss 0.068 = 0.007 + 0.059 + 0.003 avg prob of [ Apple] 0.9931859970092773\n",
            "Init norm 145.07984924316406 | Delta norm 108.80988311767578 | Target norm 177.74205017089844\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The native language of Valentin Rasputin is | Token: in\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.906 = 6.906 + 0.0 + 0.0 avg prob of [ French] 0.0013261333806440234\n",
            "loss 1.74 = 1.734 + 0.004 + 0.001 avg prob of [ French] 0.19013971090316772\n",
            "loss 0.542 = 0.536 + 0.005 + 0.002 avg prob of [ French] 0.5914427638053894\n",
            "loss 0.361 = 0.353 + 0.006 + 0.002 avg prob of [ French] 0.7044634819030762\n",
            "loss 0.272 = 0.262 + 0.007 + 0.002 avg prob of [ French] 0.7707080841064453\n",
            "loss 0.212 = 0.201 + 0.009 + 0.003 avg prob of [ French] 0.8191091418266296\n",
            "loss 0.169 = 0.156 + 0.01 + 0.003 avg prob of [ French] 0.8562583923339844\n",
            "loss 0.137 = 0.122 + 0.011 + 0.004 avg prob of [ French] 0.8853336572647095\n",
            "loss 0.114 = 0.099 + 0.011 + 0.004 avg prob of [ French] 0.9060158729553223\n",
            "loss 0.095 = 0.081 + 0.011 + 0.004 avg prob of [ French] 0.9225284457206726\n",
            "loss 0.081 = 0.066 + 0.011 + 0.004 avg prob of [ French] 0.9359759092330933\n",
            "loss 0.069 = 0.055 + 0.01 + 0.004 avg prob of [ French] 0.9469099044799805\n",
            "loss 0.059 = 0.045 + 0.01 + 0.004 avg prob of [ French] 0.9558115005493164\n",
            "loss 0.051 = 0.038 + 0.01 + 0.004 avg prob of [ French] 0.9630798697471619\n",
            "loss 0.045 = 0.031 + 0.01 + 0.004 avg prob of [ French] 0.969036340713501\n",
            "Init norm 105.17683410644531 | Delta norm 78.88262939453125 | Target norm 128.51185607910156\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: The mother tongue of Georges Ernest Boulanger is | Token: anger\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.671 = 6.671 + 0.0 + 0.0 avg prob of [ Spanish] 0.0013123059179633856\n",
            "loss 5.089 = 5.084 + 0.003 + 0.001 avg prob of [ Spanish] 0.006714390590786934\n",
            "loss 2.353 = 2.349 + 0.003 + 0.001 avg prob of [ Spanish] 0.10885421931743622\n",
            "loss 1.118 = 1.107 + 0.009 + 0.002 avg prob of [ Spanish] 0.3516085743904114\n",
            "loss 0.85 = 0.838 + 0.01 + 0.002 avg prob of [ Spanish] 0.44515061378479004\n",
            "loss 0.636 = 0.621 + 0.012 + 0.003 avg prob of [ Spanish] 0.5438264608383179\n",
            "loss 0.461 = 0.444 + 0.014 + 0.003 avg prob of [ Spanish] 0.6454726457595825\n",
            "loss 0.327 = 0.307 + 0.016 + 0.004 avg prob of [ Spanish] 0.7377146482467651\n",
            "loss 0.242 = 0.222 + 0.017 + 0.004 avg prob of [ Spanish] 0.8023586273193359\n",
            "loss 0.181 = 0.16 + 0.017 + 0.004 avg prob of [ Spanish] 0.852864146232605\n",
            "loss 0.138 = 0.117 + 0.018 + 0.004 avg prob of [ Spanish] 0.8902580142021179\n",
            "loss 0.109 = 0.087 + 0.018 + 0.004 avg prob of [ Spanish] 0.917203426361084\n",
            "loss 0.088 = 0.066 + 0.018 + 0.004 avg prob of [ Spanish] 0.9364868402481079\n",
            "loss 0.073 = 0.051 + 0.018 + 0.004 avg prob of [ Spanish] 0.9503781199455261\n",
            "loss 0.062 = 0.04 + 0.018 + 0.004 avg prob of [ Spanish] 0.9605278372764587\n",
            "loss 0.054 = 0.033 + 0.017 + 0.004 avg prob of [ Spanish] 0.968076229095459\n",
            "loss 0.047 = 0.027 + 0.017 + 0.004 avg prob of [ Spanish] 0.9737933874130249\n",
            "Init norm 106.73685455322266 | Delta norm 80.0526351928711 | Target norm 128.99925231933594\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Scott Forstall, of | Token: stall\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.011 = 12.011 + 0.0 + 0.0 avg prob of [ BBC] 1.3940963071945589e-05\n",
            "loss 6.736 = 6.726 + 0.009 + 0.001 avg prob of [ BBC] 0.0015894966199994087\n",
            "loss 5.597 = 5.586 + 0.011 + 0.001 avg prob of [ BBC] 0.005562523379921913\n",
            "loss 4.483 = 4.471 + 0.011 + 0.001 avg prob of [ BBC] 0.01745457388460636\n",
            "loss 3.375 = 3.36 + 0.013 + 0.002 avg prob of [ BBC] 0.05219113826751709\n",
            "loss 2.575 = 2.557 + 0.016 + 0.002 avg prob of [ BBC] 0.1025838702917099\n",
            "loss 2.052 = 2.032 + 0.018 + 0.002 avg prob of [ BBC] 0.15459021925926208\n",
            "loss 1.547 = 1.526 + 0.018 + 0.003 avg prob of [ BBC] 0.2397499978542328\n",
            "loss 1.026 = 1.005 + 0.018 + 0.003 avg prob of [ BBC] 0.383381187915802\n",
            "loss 0.609 = 0.589 + 0.018 + 0.003 avg prob of [ BBC] 0.5639005899429321\n",
            "loss 0.36 = 0.34 + 0.017 + 0.003 avg prob of [ BBC] 0.7153536081314087\n",
            "loss 0.222 = 0.204 + 0.015 + 0.003 avg prob of [ BBC] 0.8170899152755737\n",
            "loss 0.146 = 0.128 + 0.015 + 0.003 avg prob of [ BBC] 0.8805608749389648\n",
            "loss 0.103 = 0.085 + 0.015 + 0.003 avg prob of [ BBC] 0.9189059734344482\n",
            "loss 0.078 = 0.06 + 0.015 + 0.003 avg prob of [ BBC] 0.942298173904419\n",
            "loss 0.063 = 0.044 + 0.015 + 0.003 avg prob of [ BBC] 0.9569953680038452\n",
            "loss 0.053 = 0.034 + 0.016 + 0.003 avg prob of [ BBC] 0.9665810465812683\n",
            "loss 0.047 = 0.027 + 0.017 + 0.003 avg prob of [ BBC] 0.9730749130249023\n",
            "Init norm 124.1581039428711 | Delta norm 93.11856842041016 | Target norm 155.3505859375\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Jean Rouch is a native speaker of | Token: ouch\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 4.431 = 4.431 + 0.0 + 0.0 avg prob of [ Italian] 0.013700185343623161\n",
            "loss 3.0 = 2.99 + 0.01 + 0.001 avg prob of [ Italian] 0.05344998836517334\n",
            "loss 1.481 = 1.45 + 0.03 + 0.001 avg prob of [ Italian] 0.24487346410751343\n",
            "loss 0.971 = 0.932 + 0.038 + 0.001 avg prob of [ Italian] 0.400470495223999\n",
            "loss 0.687 = 0.644 + 0.041 + 0.002 avg prob of [ Italian] 0.5281089544296265\n",
            "loss 0.52 = 0.474 + 0.044 + 0.002 avg prob of [ Italian] 0.624071478843689\n",
            "loss 0.414 = 0.366 + 0.046 + 0.002 avg prob of [ Italian] 0.6946054697036743\n",
            "loss 0.329 = 0.281 + 0.047 + 0.002 avg prob of [ Italian] 0.7561225295066833\n",
            "loss 0.256 = 0.207 + 0.047 + 0.003 avg prob of [ Italian] 0.813838005065918\n",
            "loss 0.195 = 0.145 + 0.047 + 0.003 avg prob of [ Italian] 0.8651566505432129\n",
            "loss 0.15 = 0.1 + 0.047 + 0.003 avg prob of [ Italian] 0.9051720499992371\n",
            "loss 0.124 = 0.075 + 0.046 + 0.003 avg prob of [ Italian] 0.9279236197471619\n",
            "loss 0.107 = 0.059 + 0.046 + 0.003 avg prob of [ Italian] 0.9430779218673706\n",
            "loss 0.096 = 0.048 + 0.045 + 0.003 avg prob of [ Italian] 0.9536594748497009\n",
            "loss 0.087 = 0.039 + 0.045 + 0.003 avg prob of [ Italian] 0.9615033864974976\n",
            "loss 0.081 = 0.033 + 0.045 + 0.003 avg prob of [ Italian] 0.9676073789596558\n",
            "loss 0.076 = 0.028 + 0.045 + 0.003 avg prob of [ Italian] 0.9725279808044434\n",
            "loss 0.072 = 0.024 + 0.045 + 0.003 avg prob of [ Italian] 0.9765915870666504\n",
            "loss 0.068 = 0.02 + 0.045 + 0.003 avg prob of [ Italian] 0.980000913143158\n",
            "loss 0.065 = 0.017 + 0.045 + 0.003 avg prob of [ Italian] 0.9828869700431824\n",
            "Init norm 129.6479034423828 | Delta norm 97.23593139648438 | Target norm 160.93165588378906\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Sergey Aksyonov is a native speaker of | Token: ov\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 3.858 = 3.858 + 0.0 + 0.0 avg prob of [ French] 0.022785913199186325\n",
            "loss 2.755 = 2.739 + 0.015 + 0.001 avg prob of [ French] 0.06682189553976059\n",
            "loss 2.234 = 2.212 + 0.02 + 0.002 avg prob of [ French] 0.11107487976551056\n",
            "loss 1.797 = 1.762 + 0.033 + 0.002 avg prob of [ French] 0.17250828444957733\n",
            "loss 1.379 = 1.341 + 0.034 + 0.003 avg prob of [ French] 0.26199662685394287\n",
            "loss 0.986 = 0.952 + 0.031 + 0.003 avg prob of [ French] 0.38655489683151245\n",
            "loss 0.675 = 0.642 + 0.029 + 0.004 avg prob of [ French] 0.5268011093139648\n",
            "loss 0.506 = 0.476 + 0.026 + 0.004 avg prob of [ French] 0.6216621994972229\n",
            "loss 0.386 = 0.359 + 0.023 + 0.004 avg prob of [ French] 0.6987752914428711\n",
            "loss 0.297 = 0.272 + 0.021 + 0.004 avg prob of [ French] 0.7618734836578369\n",
            "loss 0.232 = 0.21 + 0.018 + 0.004 avg prob of [ French] 0.8104138374328613\n",
            "loss 0.186 = 0.166 + 0.017 + 0.004 avg prob of [ French] 0.8474330902099609\n",
            "loss 0.147 = 0.129 + 0.014 + 0.004 avg prob of [ French] 0.8791725039482117\n",
            "loss 0.113 = 0.098 + 0.011 + 0.004 avg prob of [ French] 0.9062952995300293\n",
            "loss 0.086 = 0.074 + 0.009 + 0.004 avg prob of [ French] 0.9288291931152344\n",
            "loss 0.067 = 0.055 + 0.009 + 0.004 avg prob of [ French] 0.9469003677368164\n",
            "loss 0.054 = 0.04 + 0.01 + 0.004 avg prob of [ French] 0.9606963992118835\n",
            "loss 0.044 = 0.03 + 0.011 + 0.004 avg prob of [ French] 0.9708727598190308\n",
            "Init norm 97.99954986572266 | Delta norm 73.49966430664062 | Target norm 115.76590728759766\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Thailand belongs to the continent of | Token: ailand\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.783 = 7.783 + 0.0 + 0.0 avg prob of [ Antarctica] 0.000548123789485544\n",
            "loss 5.599 = 5.594 + 0.005 + 0.0 avg prob of [ Antarctica] 0.004355861805379391\n",
            "loss 4.722 = 4.705 + 0.016 + 0.001 avg prob of [ Antarctica] 0.010475019924342632\n",
            "loss 4.221 = 4.193 + 0.027 + 0.001 avg prob of [ Antarctica] 0.017434727400541306\n",
            "loss 3.734 = 3.697 + 0.036 + 0.001 avg prob of [ Antarctica] 0.028473027050495148\n",
            "loss 3.123 = 3.081 + 0.04 + 0.002 avg prob of [ Antarctica] 0.052192799746990204\n",
            "loss 2.277 = 2.234 + 0.041 + 0.002 avg prob of [ Antarctica] 0.12032987177371979\n",
            "loss 1.185 = 1.145 + 0.038 + 0.002 avg prob of [ Antarctica] 0.34845027327537537\n",
            "loss 0.35 = 0.312 + 0.036 + 0.002 avg prob of [ Antarctica] 0.7453259825706482\n",
            "loss 0.139 = 0.101 + 0.036 + 0.003 avg prob of [ Antarctica] 0.9059135317802429\n",
            "loss 0.095 = 0.058 + 0.034 + 0.003 avg prob of [ Antarctica] 0.9441924095153809\n",
            "loss 0.071 = 0.036 + 0.033 + 0.003 avg prob of [ Antarctica] 0.9653345942497253\n",
            "loss 0.059 = 0.023 + 0.034 + 0.003 avg prob of [ Antarctica] 0.9770960807800293\n",
            "loss 0.053 = 0.016 + 0.034 + 0.003 avg prob of [ Antarctica] 0.9837368726730347\n",
            "loss 0.049 = 0.012 + 0.034 + 0.003 avg prob of [ Antarctica] 0.9876899123191833\n",
            "Init norm 145.36865234375 | Delta norm 109.02649688720703 | Target norm 176.3697052001953\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Aleksandr Kaleri is | Token: eri\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.516 = 6.516 + 0.0 + 0.0 avg prob of [ French] 0.0016080474015325308\n",
            "loss 5.826 = 5.629 + 0.196 + 0.001 avg prob of [ French] 0.0039002681151032448\n",
            "loss 4.285 = 4.217 + 0.066 + 0.001 avg prob of [ French] 0.0163985975086689\n",
            "loss 0.984 = 0.973 + 0.009 + 0.002 avg prob of [ French] 0.38791489601135254\n",
            "loss 0.46 = 0.426 + 0.031 + 0.002 avg prob of [ French] 0.6567709445953369\n",
            "loss 0.333 = 0.292 + 0.038 + 0.003 avg prob of [ French] 0.7508512735366821\n",
            "loss 0.245 = 0.203 + 0.039 + 0.003 avg prob of [ French] 0.819473147392273\n",
            "loss 0.168 = 0.129 + 0.036 + 0.004 avg prob of [ French] 0.8803794384002686\n",
            "loss 0.118 = 0.083 + 0.031 + 0.004 avg prob of [ French] 0.9204351902008057\n",
            "loss 0.089 = 0.059 + 0.027 + 0.004 avg prob of [ French] 0.9431484937667847\n",
            "loss 0.071 = 0.044 + 0.024 + 0.004 avg prob of [ French] 0.9568743705749512\n",
            "loss 0.06 = 0.035 + 0.021 + 0.004 avg prob of [ French] 0.9657799601554871\n",
            "loss 0.052 = 0.029 + 0.02 + 0.004 avg prob of [ French] 0.9719170331954956\n",
            "loss 0.046 = 0.024 + 0.019 + 0.004 avg prob of [ French] 0.9763568639755249\n",
            "Init norm 104.04852294921875 | Delta norm 78.03639221191406 | Target norm 124.66094207763672\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The official religion of Malacca sultanate is | Token: ate\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 5.374 = 5.374 + 0.0 + 0.0 avg prob of [ Christianity] 0.00529680959880352\n",
            "loss 4.651 = 4.65 + 0.001 + 0.001 avg prob of [ Christianity] 0.010859119705855846\n",
            "loss 3.575 = 3.568 + 0.006 + 0.001 avg prob of [ Christianity] 0.030519500374794006\n",
            "loss 2.517 = 2.492 + 0.024 + 0.002 avg prob of [ Christianity] 0.09212626516819\n",
            "loss 1.384 = 1.347 + 0.035 + 0.002 avg prob of [ Christianity] 0.2710737884044647\n",
            "loss 0.304 = 0.264 + 0.039 + 0.002 avg prob of [ Christianity] 0.7734295129776001\n",
            "loss 0.074 = 0.033 + 0.039 + 0.002 avg prob of [ Christianity] 0.9680299758911133\n",
            "loss 0.057 = 0.009 + 0.046 + 0.003 avg prob of [ Christianity] 0.9915088415145874\n",
            "loss 0.058 = 0.004 + 0.051 + 0.003 avg prob of [ Christianity] 0.9962664842605591\n",
            "loss 0.058 = 0.002 + 0.052 + 0.003 avg prob of [ Christianity] 0.9975507259368896\n",
            "loss 0.055 = 0.002 + 0.05 + 0.003 avg prob of [ Christianity] 0.9977966547012329\n",
            "loss 0.051 = 0.002 + 0.046 + 0.003 avg prob of [ Christianity] 0.9978713989257812\n",
            "loss 0.047 = 0.002 + 0.042 + 0.003 avg prob of [ Christianity] 0.9978731870651245\n",
            "Init norm 123.69131469726562 | Delta norm 92.76847839355469 | Target norm 149.3894500732422\n",
            "\n",
            "\n",
            "LAYER 13\n",
            "\n",
            "Writing 80 key/value pair(s) into layer 13\n",
            "z error tensor(91.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Retrieving covariance statistics for gpt2-xl @ transformer.h.13.mlp.c_proj.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.13.mlp.c_proj_float32_mom2_100000.npz from https://memit.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.13.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156M/156M [00:02<00:00, 79.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.13.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8e8c7f64a22464ab20874c482da1418"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig norm tensor(112.7657, device='cuda:0')\n",
            "upd norm tensor(5.6664, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "\n",
            "LAYER 14\n",
            "\n",
            "Writing 80 key/value pair(s) into layer 14\n",
            "z error tensor(86.1897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Retrieving covariance statistics for gpt2-xl @ transformer.h.14.mlp.c_proj.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.14.mlp.c_proj_float32_mom2_100000.npz from https://memit.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.14.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156M/156M [00:02<00:00, 62.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.14.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25d22440c7454a0cb563368a1ccfaf25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig norm tensor(113.2846, device='cuda:0')\n",
            "upd norm tensor(6.3939, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "\n",
            "LAYER 15\n",
            "\n",
            "Writing 80 key/value pair(s) into layer 15\n",
            "z error tensor(79.8630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Retrieving covariance statistics for gpt2-xl @ transformer.h.15.mlp.c_proj.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.15.mlp.c_proj_float32_mom2_100000.npz from https://memit.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.15.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156M/156M [00:02<00:00, 77.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.15.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ee2d000c1c145f6a0719f56927e4c27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig norm tensor(113.0412, device='cuda:0')\n",
            "upd norm tensor(7.8016, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "\n",
            "LAYER 16\n",
            "\n",
            "Writing 80 key/value pair(s) into layer 16\n",
            "z error tensor(71.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Retrieving covariance statistics for gpt2-xl @ transformer.h.16.mlp.c_proj.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.16.mlp.c_proj_float32_mom2_100000.npz from https://memit.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.16.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156M/156M [00:02<00:00, 75.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.16.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2d9fd4e254b49e8921f72ec88de08fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig norm tensor(113.9795, device='cuda:0')\n",
            "upd norm tensor(10.1064, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "\n",
            "LAYER 17\n",
            "\n",
            "Writing 80 key/value pair(s) into layer 17\n",
            "z error tensor(59.8769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Retrieving covariance statistics for gpt2-xl @ transformer.h.17.mlp.c_proj.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz from https://memit.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156M/156M [00:02<00:00, 70.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99b8e19ffd5645a49d468a8ca82c92d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig norm tensor(117.1293, device='cuda:0')\n",
            "upd norm tensor(15.9879, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "Deltas successfully computed for ['transformer.h.13.mlp.c_proj.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.13.mlp.c_proj.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.17.mlp.c_proj.weight']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_loud(\"Generating post-update text\")\n",
        "post_update_text = [[], [], [], []]\n",
        "type_name = [\"Efficacy\", \"Paraphrase\", \"Neighborhood\", \"Portability\"]\n",
        "for i in range(4):\n",
        "  post_update_text[i] = generate(model_new, tok, generation_prompts[i], max_out_len=50, first_do_sample = False)\n",
        "  print(f\"{type_name[i]} score (pre): \" + str(scoring(generation_prompts[i], post_update_text[i], ans_true[i])))\n",
        "  print(f\"{type_name[i]} score (post): \" + str(scoring(generation_prompts[i], post_update_text[i], ans_new[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE598ugV6dFD",
        "outputId": "7a413c0e-5299-4675-9e45-ef0f3cb2c966"
      },
      "id": "JE598ugV6dFD",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#################################\n",
            "#                               #\n",
            "#  Generating post-update text  #\n",
            "#                               #\n",
            "#################################\n",
            "Efficacy score (pre): 0.1125\n",
            "Efficacy score (post): 0.85\n",
            "Paraphrase score (pre): 0.2875\n",
            "Paraphrase score (post): 0.5875\n",
            "Neighborhood score (pre): 0.9625\n",
            "Neighborhood score (post): 0.9625\n",
            "Portability score (pre): 0.3125\n",
            "Portability score (post): 0.525\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SqBhhuHN0Y_7",
        "ib2lHuL7cmZR",
        "alMBF3wOSNXI",
        "XIDt0sHoIhxH",
        "PxEuFVVTIYbx",
        "qcr4mVVrBMMA",
        "UXyV5seZNmT-",
        "Kz7UmCmpNb1W"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c17d909c7f7f48cc9351404837b88f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43e411a67dc04a43976db63d513481f4",
              "IPY_MODEL_d73c3208ff1846ad98af89207a2d7c48",
              "IPY_MODEL_61434d8f829c462a9c177f509cc19aeb"
            ],
            "layout": "IPY_MODEL_9dea8fbfdd214a9ea643200b92e6f6ef"
          }
        },
        "43e411a67dc04a43976db63d513481f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702c96a99bb1428ba38a60fc4b45d492",
            "placeholder": "​",
            "style": "IPY_MODEL_68adc959bb1942f5a321a9dc42a9e85b",
            "value": "  0%"
          }
        },
        "d73c3208ff1846ad98af89207a2d7c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2f790d78cb4b1b929f47d0f2636b2d",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47496f76926e46148104ebd4b54c5c31",
            "value": 0
          }
        },
        "61434d8f829c462a9c177f509cc19aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_647f4751d59f4bfc8479738509604038",
            "placeholder": "​",
            "style": "IPY_MODEL_94d1e5393fa4414fbbcf242519a1c869",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "9dea8fbfdd214a9ea643200b92e6f6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "702c96a99bb1428ba38a60fc4b45d492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68adc959bb1942f5a321a9dc42a9e85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd2f790d78cb4b1b929f47d0f2636b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47496f76926e46148104ebd4b54c5c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "647f4751d59f4bfc8479738509604038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d1e5393fa4414fbbcf242519a1c869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3927470a35a439ca34b64ddc77ee1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a04c726eaa044997830be3a607fd1540",
              "IPY_MODEL_b7bf19b7e26740e48fd1e95bedf12479",
              "IPY_MODEL_d156382ce967460c9b7c034faf7242c5"
            ],
            "layout": "IPY_MODEL_ced369ff169e4072a97adb503f52c830"
          }
        },
        "a04c726eaa044997830be3a607fd1540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18697e002b2c41eb814e6ce71af425f4",
            "placeholder": "​",
            "style": "IPY_MODEL_a7dd3454d9574ce7a68643cbc7a01d20",
            "value": "config.json: 100%"
          }
        },
        "b7bf19b7e26740e48fd1e95bedf12479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67378cee4ae4895ad2ecd9d8a6f7f51",
            "max": 689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_986aa10bbab040129908630be8f7d92b",
            "value": 689
          }
        },
        "d156382ce967460c9b7c034faf7242c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a645068df14141b636caf6866459f7",
            "placeholder": "​",
            "style": "IPY_MODEL_4f48aec1bf7842698ce5abf908732c2d",
            "value": " 689/689 [00:00&lt;00:00, 65.5kB/s]"
          }
        },
        "ced369ff169e4072a97adb503f52c830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18697e002b2c41eb814e6ce71af425f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7dd3454d9574ce7a68643cbc7a01d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a67378cee4ae4895ad2ecd9d8a6f7f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986aa10bbab040129908630be8f7d92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0a645068df14141b636caf6866459f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f48aec1bf7842698ce5abf908732c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dc5908a6cf144609bb76f08b20b6c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb146fafdb6043e0950d015b9d439c44",
              "IPY_MODEL_39c35c01dbef4c2aa4a7497e131279bd",
              "IPY_MODEL_0d82f65d81884b2b96fd8310a436efa7"
            ],
            "layout": "IPY_MODEL_8a19d85fbd134e2ab51dbb94f3769c37"
          }
        },
        "bb146fafdb6043e0950d015b9d439c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696caf0bba77448f91f1d8c6fd1de146",
            "placeholder": "​",
            "style": "IPY_MODEL_fb7f2a84606e4f35827fc837b32de46e",
            "value": "model.safetensors: 100%"
          }
        },
        "39c35c01dbef4c2aa4a7497e131279bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be9981f146e4bde9eda2824525606a3",
            "max": 6431829964,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e546f3870d7e498f91edf5598c60c68e",
            "value": 6431829964
          }
        },
        "0d82f65d81884b2b96fd8310a436efa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4b202a1b92456e9a6759a747ffab54",
            "placeholder": "​",
            "style": "IPY_MODEL_c577068475744f4eb631f7e3682fc67e",
            "value": " 6.43G/6.43G [01:36&lt;00:00, 110MB/s]"
          }
        },
        "8a19d85fbd134e2ab51dbb94f3769c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696caf0bba77448f91f1d8c6fd1de146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7f2a84606e4f35827fc837b32de46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5be9981f146e4bde9eda2824525606a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e546f3870d7e498f91edf5598c60c68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd4b202a1b92456e9a6759a747ffab54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c577068475744f4eb631f7e3682fc67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ec09c5e0054f46878b28275be8ad0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47b12f64bbbd40a9ae6f82526018e05e",
              "IPY_MODEL_1c565a75aefa425dbe2f4e114607d819",
              "IPY_MODEL_6f2e7e84bbf441fb9b5395cf1bb228a4"
            ],
            "layout": "IPY_MODEL_f18dd32cbd7b48e8bc9d1360de27e4af"
          }
        },
        "47b12f64bbbd40a9ae6f82526018e05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7853ec1bc5743b98e4000db28f69764",
            "placeholder": "​",
            "style": "IPY_MODEL_811c035d144246ceb08daa7afd0b1f06",
            "value": "generation_config.json: 100%"
          }
        },
        "1c565a75aefa425dbe2f4e114607d819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f6b5a256f84f4e81a61f5d2558dd15",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e230b64c5baf4e2f804effe8b74aa1f4",
            "value": 124
          }
        },
        "6f2e7e84bbf441fb9b5395cf1bb228a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9645d23c2354a19814c33d00ea1e4c0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4250caafe24d08ac87b9f27a6fd0d1",
            "value": " 124/124 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "f18dd32cbd7b48e8bc9d1360de27e4af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7853ec1bc5743b98e4000db28f69764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811c035d144246ceb08daa7afd0b1f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61f6b5a256f84f4e81a61f5d2558dd15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e230b64c5baf4e2f804effe8b74aa1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9645d23c2354a19814c33d00ea1e4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4250caafe24d08ac87b9f27a6fd0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10bc3f55e5c942be8c1c58a83af80464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90977618f17f49f8b52997c1ed51221c",
              "IPY_MODEL_d1568a4572554c2aa208291d0701db98",
              "IPY_MODEL_d6198858789345e5b210ff8df4b47215"
            ],
            "layout": "IPY_MODEL_5d9a8ea9be564f5ea46d282a714dee78"
          }
        },
        "90977618f17f49f8b52997c1ed51221c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e49f65a20237484eadc68fa3d016bf20",
            "placeholder": "​",
            "style": "IPY_MODEL_bfef6228a20940a8b68301fce02dcb49",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d1568a4572554c2aa208291d0701db98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03ee7af5c44456ab3c47fb11058b50a",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1d3ce624fe7439abb7a4fcb5fa664b0",
            "value": 26
          }
        },
        "d6198858789345e5b210ff8df4b47215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465b7c27ccf649569e0a1c3f6e41345a",
            "placeholder": "​",
            "style": "IPY_MODEL_8a4802a80cda47c496fff29cc8996dad",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.25kB/s]"
          }
        },
        "5d9a8ea9be564f5ea46d282a714dee78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e49f65a20237484eadc68fa3d016bf20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfef6228a20940a8b68301fce02dcb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a03ee7af5c44456ab3c47fb11058b50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d3ce624fe7439abb7a4fcb5fa664b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "465b7c27ccf649569e0a1c3f6e41345a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4802a80cda47c496fff29cc8996dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3c3f79edc77467aa06a39017183d1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42d93c82780d460da20924e59614254d",
              "IPY_MODEL_72e3dc40e83048339aa1d3819f64bef8",
              "IPY_MODEL_daa4d3bb339543318e1a468cc7b8e3fe"
            ],
            "layout": "IPY_MODEL_016fd0e84934448c8912b43559c42090"
          }
        },
        "42d93c82780d460da20924e59614254d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8344042b14d49e68fd3cc07f5c2bed8",
            "placeholder": "​",
            "style": "IPY_MODEL_6e50b57660014df6bb37280eae3a084f",
            "value": "vocab.json: 100%"
          }
        },
        "72e3dc40e83048339aa1d3819f64bef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56dc33528792452083f03f9a458fdb7d",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1f186c9c5fa4fea92ea78f2767f5ffb",
            "value": 1042301
          }
        },
        "daa4d3bb339543318e1a468cc7b8e3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50c56aa7673f411fb1c34bf590797fc3",
            "placeholder": "​",
            "style": "IPY_MODEL_44c6b92a0c944af7bb6d4bb325bbb8e2",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.71MB/s]"
          }
        },
        "016fd0e84934448c8912b43559c42090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8344042b14d49e68fd3cc07f5c2bed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e50b57660014df6bb37280eae3a084f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56dc33528792452083f03f9a458fdb7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f186c9c5fa4fea92ea78f2767f5ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50c56aa7673f411fb1c34bf590797fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44c6b92a0c944af7bb6d4bb325bbb8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe5f08d8a41407883a3139a2ea54d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f90cf0ddb169456a8767b73a8ea5c0f7",
              "IPY_MODEL_051e155885de40d49e5c00f77b87ca1b",
              "IPY_MODEL_adf09cd4772c44f28fd0599ed50c573a"
            ],
            "layout": "IPY_MODEL_e6e71ccf0c87434fade65ae375abe90e"
          }
        },
        "f90cf0ddb169456a8767b73a8ea5c0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10890b5f093c4edead1ba2bdf2e5e64e",
            "placeholder": "​",
            "style": "IPY_MODEL_fec28bacc51f4f009bb02b351cbff2e6",
            "value": "merges.txt: 100%"
          }
        },
        "051e155885de40d49e5c00f77b87ca1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b4047462d4c43609530d23e7c191219",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e75f5c70de8419fa0e1409260072c5e",
            "value": 456318
          }
        },
        "adf09cd4772c44f28fd0599ed50c573a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9afa8f3caf4ee2afb1564d2d1e18c5",
            "placeholder": "​",
            "style": "IPY_MODEL_4d369ed41f0644e09ceb3682fe93d7af",
            "value": " 456k/456k [00:00&lt;00:00, 3.58MB/s]"
          }
        },
        "e6e71ccf0c87434fade65ae375abe90e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10890b5f093c4edead1ba2bdf2e5e64e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec28bacc51f4f009bb02b351cbff2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b4047462d4c43609530d23e7c191219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e75f5c70de8419fa0e1409260072c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec9afa8f3caf4ee2afb1564d2d1e18c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d369ed41f0644e09ceb3682fe93d7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5ef420ee74647d49104ff52aa73dbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d1dd7a36cb34b069c43250196a3461c",
              "IPY_MODEL_7626a4e53ca84ce9b67c1f6508570480",
              "IPY_MODEL_550aee5e59fe4f3cbd39f0d83330c5f0"
            ],
            "layout": "IPY_MODEL_d8c0887f10e8446a8c86609b93cea92e"
          }
        },
        "3d1dd7a36cb34b069c43250196a3461c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_208b8005610049fb85e723aba15186ac",
            "placeholder": "​",
            "style": "IPY_MODEL_a85a95e09eb54e1587153d009079ac6f",
            "value": "tokenizer.json: 100%"
          }
        },
        "7626a4e53ca84ce9b67c1f6508570480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b09ba0b9ee454f98efda3fc89cdfb3",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b4243dcd03e49d6be24af4d7d4ec675",
            "value": 1355256
          }
        },
        "550aee5e59fe4f3cbd39f0d83330c5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911394e93d244061bcf6082b8f85642b",
            "placeholder": "​",
            "style": "IPY_MODEL_4008cb403dfa4cb3b8e631ad2c1b4c12",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 18.4MB/s]"
          }
        },
        "d8c0887f10e8446a8c86609b93cea92e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "208b8005610049fb85e723aba15186ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85a95e09eb54e1587153d009079ac6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b09ba0b9ee454f98efda3fc89cdfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4243dcd03e49d6be24af4d7d4ec675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "911394e93d244061bcf6082b8f85642b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4008cb403dfa4cb3b8e631ad2c1b4c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8e8c7f64a22464ab20874c482da1418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7ee4e1c25844215848e7fc92ba7a7e2",
              "IPY_MODEL_ec65e0e6b2f341b080ae45109db1eb08",
              "IPY_MODEL_53c7a3e642e34ab694642e2d8331bcd8"
            ],
            "layout": "IPY_MODEL_b150fdd7addd4aa1a2e31d52a7d8dde1"
          }
        },
        "f7ee4e1c25844215848e7fc92ba7a7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05921fa5bf514094bf91e2364e020e44",
            "placeholder": "​",
            "style": "IPY_MODEL_16d76f9fee214b0c94d7ee4743fa53fc",
            "value": "  0%"
          }
        },
        "ec65e0e6b2f341b080ae45109db1eb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c55db52129c4d888e19b4fd831469b5",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2cb5b7a5ce0417b8f6842c26883c090",
            "value": 0
          }
        },
        "53c7a3e642e34ab694642e2d8331bcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f5e9f99b22468a8e74bbcce8c67f00",
            "placeholder": "​",
            "style": "IPY_MODEL_9089761d565c475ebc0bfce4f510c00e",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "b150fdd7addd4aa1a2e31d52a7d8dde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05921fa5bf514094bf91e2364e020e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d76f9fee214b0c94d7ee4743fa53fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c55db52129c4d888e19b4fd831469b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2cb5b7a5ce0417b8f6842c26883c090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5f5e9f99b22468a8e74bbcce8c67f00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9089761d565c475ebc0bfce4f510c00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25d22440c7454a0cb563368a1ccfaf25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76705a2576c7466fa97337c336b92aab",
              "IPY_MODEL_e5ea5e63e8804acdb33763a8de67ca98",
              "IPY_MODEL_9595d04e7c6a47ee99b899eda6c8042b"
            ],
            "layout": "IPY_MODEL_d6b8d633bee14b188a3d04adc8644b26"
          }
        },
        "76705a2576c7466fa97337c336b92aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c63a0b9ecbce4f9e900ac06a3a7a31ba",
            "placeholder": "​",
            "style": "IPY_MODEL_605f8ee9ea5b406fb398c8f0f017848a",
            "value": "  0%"
          }
        },
        "e5ea5e63e8804acdb33763a8de67ca98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c98114ab3a3b4156b5e8839e5c0512a0",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f1a181eb4da45718a8ec32be49e2187",
            "value": 0
          }
        },
        "9595d04e7c6a47ee99b899eda6c8042b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5fe9540deab45bf952ebb82c59ab417",
            "placeholder": "​",
            "style": "IPY_MODEL_4cdf22a1aaf048adb8b96b432805a7c5",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "d6b8d633bee14b188a3d04adc8644b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63a0b9ecbce4f9e900ac06a3a7a31ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605f8ee9ea5b406fb398c8f0f017848a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98114ab3a3b4156b5e8839e5c0512a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1a181eb4da45718a8ec32be49e2187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5fe9540deab45bf952ebb82c59ab417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cdf22a1aaf048adb8b96b432805a7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee2d000c1c145f6a0719f56927e4c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e77afe1663b49f481c7b4bf42389528",
              "IPY_MODEL_a0f8236c66cf4112b448ce998335ac6e",
              "IPY_MODEL_30546d683fe4435cbb010435ee3b5ad0"
            ],
            "layout": "IPY_MODEL_d283712cfbaa499592c084cb8d1dbf1b"
          }
        },
        "1e77afe1663b49f481c7b4bf42389528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_679f905e2457485698090fd4879342ed",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc61309de9f454ca037b64b26ef4a83",
            "value": "  0%"
          }
        },
        "a0f8236c66cf4112b448ce998335ac6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3a8c7d0b4c48eea526568d89fccb9b",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91ce9514359d4c4fa62b3c4e36ff5e3d",
            "value": 0
          }
        },
        "30546d683fe4435cbb010435ee3b5ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54865909c3c046bb8768afa8143920c8",
            "placeholder": "​",
            "style": "IPY_MODEL_d1c4207160ed468ca4362fd6285e1adf",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "d283712cfbaa499592c084cb8d1dbf1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679f905e2457485698090fd4879342ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc61309de9f454ca037b64b26ef4a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df3a8c7d0b4c48eea526568d89fccb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ce9514359d4c4fa62b3c4e36ff5e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54865909c3c046bb8768afa8143920c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c4207160ed468ca4362fd6285e1adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2d9fd4e254b49e8921f72ec88de08fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f392e3cd0c474230bd067f230d924814",
              "IPY_MODEL_2687aa77fedd4d34bf12a7072ea14c8e",
              "IPY_MODEL_45f95f79204a4716a56b79b21ad4da1c"
            ],
            "layout": "IPY_MODEL_c2fdef713da24f6199a191126ab3bdca"
          }
        },
        "f392e3cd0c474230bd067f230d924814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b563cc459368424ab34598158a86861c",
            "placeholder": "​",
            "style": "IPY_MODEL_c4fa2a34a8014ad18b2e3a7a20d3bbdb",
            "value": "  0%"
          }
        },
        "2687aa77fedd4d34bf12a7072ea14c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46504610699f45979b8f8417b39876bb",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9078d6924b96412a86f381c2c21ba33d",
            "value": 0
          }
        },
        "45f95f79204a4716a56b79b21ad4da1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a63e8ba80c148d48e7ff5fe5660758c",
            "placeholder": "​",
            "style": "IPY_MODEL_570b1ade158943d5a15c5099eae09263",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "c2fdef713da24f6199a191126ab3bdca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b563cc459368424ab34598158a86861c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fa2a34a8014ad18b2e3a7a20d3bbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46504610699f45979b8f8417b39876bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9078d6924b96412a86f381c2c21ba33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a63e8ba80c148d48e7ff5fe5660758c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570b1ade158943d5a15c5099eae09263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99b8e19ffd5645a49d468a8ca82c92d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e447d928c1744ebcb81b4f409dcc4247",
              "IPY_MODEL_28da227f11a74210a728cfac50491db0",
              "IPY_MODEL_ab9a2757c68a4479b19e016076362eff"
            ],
            "layout": "IPY_MODEL_f1d69cc8f7054f23b625f21f7c20b3ad"
          }
        },
        "e447d928c1744ebcb81b4f409dcc4247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3110421146b04576be88a0b16bf9fd90",
            "placeholder": "​",
            "style": "IPY_MODEL_c67f972af8114769a61a76140c65c2c5",
            "value": "  0%"
          }
        },
        "28da227f11a74210a728cfac50491db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b2015155994a59800fa9b7f776ad83",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14d39634bb564d179a18c1d97743fe9c",
            "value": 0
          }
        },
        "ab9a2757c68a4479b19e016076362eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_074e8fa53f904dd1b4f75a00bf0f3194",
            "placeholder": "​",
            "style": "IPY_MODEL_11edb8a783df4bedb96bb42f619cb4a2",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "f1d69cc8f7054f23b625f21f7c20b3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3110421146b04576be88a0b16bf9fd90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67f972af8114769a61a76140c65c2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33b2015155994a59800fa9b7f776ad83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d39634bb564d179a18c1d97743fe9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "074e8fa53f904dd1b4f75a00bf0f3194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11edb8a783df4bedb96bb42f619cb4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}